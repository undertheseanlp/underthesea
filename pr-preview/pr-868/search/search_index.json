{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Underthesea","text":"<p>Underthesea is a suite of open source Python modules, datasets, and tutorials supporting research and development in Vietnamese Natural Language Processing.</p> <p>We provide an extremely easy API to quickly apply pretrained NLP models to your Vietnamese text.</p> <p>New in v9.0.0</p> <p>Vietnamese-English translation is here! Use <code>translate(\"Xin ch\u00e0o Vi\u1ec7t Nam\")</code> to translate Vietnamese text to English.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install underthesea, simply:</p> <pre><code>pip install underthesea\n</code></pre> <p>Install with extras (note: use quotes in zsh):</p> <pre><code>pip install \"underthesea[deep]\"    # Deep learning support\npip install \"underthesea[voice]\"   # Text-to-Speech support\npip install \"underthesea[prompt]\"  # OpenAI-based classification\npip install \"underthesea[langdetect]\"  # Language detection\n</code></pre>"},{"location":"#tutorials","title":"Tutorials","text":"Sentence Segmentation - Breaking text into individual sentences <pre><code>&gt;&gt;&gt; from underthesea import sent_tokenize\n&gt;&gt;&gt; text = 'Taylor cho bi\u1ebft l\u00fac \u0111\u1ea7u c\u00f4 c\u1ea3m th\u1ea5y ng\u1ea1i v\u1edbi c\u00f4 b\u1ea1n th\u00e2n Amanda nh\u01b0ng r\u1ed3i m\u1ecdi th\u1ee9 tr\u00f4i qua nhanh ch\u00f3ng. Amanda c\u0169ng tho\u1ea3i m\u00e1i v\u1edbi m\u1ed1i quan h\u1ec7 n\u00e0y.'\n\n&gt;&gt;&gt; sent_tokenize(text)\n[\n  \"Taylor cho bi\u1ebft l\u00fac \u0111\u1ea7u c\u00f4 c\u1ea3m th\u1ea5y ng\u1ea1i v\u1edbi c\u00f4 b\u1ea1n th\u00e2n Amanda nh\u01b0ng r\u1ed3i m\u1ecdi th\u1ee9 tr\u00f4i qua nhanh ch\u00f3ng.\",\n  \"Amanda c\u0169ng tho\u1ea3i m\u00e1i v\u1edbi m\u1ed1i quan h\u1ec7 n\u00e0y.\"\n]\n</code></pre> Text Normalization - Standardizing textual data representation <pre><code>&gt;&gt;&gt; from underthesea import text_normalize\n&gt;&gt;&gt; text_normalize(\"\u00d0\u1ea3m ba\u1ecf ch\u1ea5t l\u1ef1\u01a1ng ph\u00f2ng th\u00ed ngh\u1ecb\u00eam ho\u00e1 h\u1ecdc\")\n\"\u0110\u1ea3m b\u1ea3o ch\u1ea5t l\u01b0\u1ee3ng ph\u00f2ng th\u00ed nghi\u1ec7m h\u00f3a h\u1ecdc\"\n</code></pre> Word Segmentation - Dividing text into individual words <pre><code>&gt;&gt;&gt; from underthesea import word_tokenize\n&gt;&gt;&gt; text = \"Ch\u00e0ng trai 9X Qu\u1ea3ng Tr\u1ecb kh\u1edfi nghi\u1ec7p t\u1eeb n\u1ea5m s\u00f2\"\n\n&gt;&gt;&gt; word_tokenize(text)\n[\"Ch\u00e0ng trai\", \"9X\", \"Qu\u1ea3ng Tr\u1ecb\", \"kh\u1edfi nghi\u1ec7p\", \"t\u1eeb\", \"n\u1ea5m\", \"s\u00f2\"]\n\n&gt;&gt;&gt; word_tokenize(text, format=\"text\")\n\"Ch\u00e0ng_trai 9X Qu\u1ea3ng_Tr\u1ecb kh\u1edfi_nghi\u1ec7p t\u1eeb n\u1ea5m s\u00f2\"\n\n&gt;&gt;&gt; text = \"Vi\u1ec7n Nghi\u00ean C\u1ee9u chi\u1ebfn l\u01b0\u1ee3c qu\u1ed1c gia v\u1ec1 h\u1ecdc m\u00e1y\"\n&gt;&gt;&gt; fixed_words = [\"Vi\u1ec7n Nghi\u00ean C\u1ee9u\", \"h\u1ecdc m\u00e1y\"]\n&gt;&gt;&gt; word_tokenize(text, fixed_words=fixed_words)\n\"Vi\u1ec7n_Nghi\u00ean_C\u1ee9u chi\u1ebfn_l\u01b0\u1ee3c qu\u1ed1c_gia v\u1ec1 h\u1ecdc_m\u00e1y\"\n</code></pre> POS Tagging - Labeling words with their part-of-speech <pre><code>&gt;&gt;&gt; from underthesea import pos_tag\n&gt;&gt;&gt; pos_tag('Ch\u1ee3 th\u1ecbt ch\u00f3 n\u1ed5i ti\u1ebfng \u1edf S\u00e0i G\u00f2n b\u1ecb truy qu\u00e9t')\n[('Ch\u1ee3', 'N'),\n ('th\u1ecbt', 'N'),\n ('ch\u00f3', 'N'),\n ('n\u1ed5i ti\u1ebfng', 'A'),\n ('\u1edf', 'E'),\n ('S\u00e0i G\u00f2n', 'Np'),\n ('b\u1ecb', 'V'),\n ('truy qu\u00e9t', 'V')]\n</code></pre> Chunking - Grouping words into meaningful phrases <pre><code>&gt;&gt;&gt; from underthesea import chunk\n&gt;&gt;&gt; text = 'B\u00e1c s\u0129 b\u00e2y gi\u1edd c\u00f3 th\u1ec3 th\u1ea3n nhi\u00ean b\u00e1o tin b\u1ec7nh nh\u00e2n b\u1ecb ung th\u01b0?'\n&gt;&gt;&gt; chunk(text)\n[('B\u00e1c s\u0129', 'N', 'B-NP'),\n ('b\u00e2y gi\u1edd', 'P', 'B-NP'),\n ('c\u00f3 th\u1ec3', 'R', 'O'),\n ('th\u1ea3n nhi\u00ean', 'A', 'B-AP'),\n ('b\u00e1o', 'V', 'B-VP'),\n ('tin', 'N', 'B-NP'),\n ('b\u1ec7nh nh\u00e2n', 'N', 'B-NP'),\n ('b\u1ecb', 'V', 'B-VP'),\n ('ung th\u01b0', 'N', 'B-NP'),\n ('?', 'CH', 'O')]\n</code></pre> Dependency Parsing - Analyzing grammatical structure (requires <code>[deep]</code>) <pre><code>pip install \"underthesea[deep]\"\n</code></pre> <pre><code>&gt;&gt;&gt; from underthesea import dependency_parse\n&gt;&gt;&gt; text = 'T\u1ed1i 29/11, Vi\u1ec7t Nam th\u00eam 2 ca m\u1eafc Covid-19'\n&gt;&gt;&gt; dependency_parse(text)\n[('T\u1ed1i', 5, 'obl:tmod'),\n ('29/11', 1, 'flat:date'),\n (',', 1, 'punct'),\n ('Vi\u1ec7t Nam', 5, 'nsubj'),\n ('th\u00eam', 0, 'root'),\n ('2', 7, 'nummod'),\n ('ca', 5, 'obj'),\n ('m\u1eafc', 7, 'nmod'),\n ('Covid-19', 8, 'nummod')]\n</code></pre> Named Entity Recognition - Identifying named entities <p>CRF Model (Default)</p> <pre><code>&gt;&gt;&gt; from underthesea import ner\n&gt;&gt;&gt; text = 'Ch\u01b0a ti\u1ebft l\u1ed9 l\u1ecbch tr\u00ecnh t\u1edbi Vi\u1ec7t Nam c\u1ee7a T\u1ed5ng th\u1ed1ng M\u1ef9 Donald Trump'\n&gt;&gt;&gt; ner(text)\n[('Ch\u01b0a', 'R', 'O', 'O'),\n ('ti\u1ebft l\u1ed9', 'V', 'B-VP', 'O'),\n ('l\u1ecbch tr\u00ecnh', 'V', 'B-VP', 'O'),\n ('t\u1edbi', 'E', 'B-PP', 'O'),\n ('Vi\u1ec7t Nam', 'Np', 'B-NP', 'B-LOC'),\n ('c\u1ee7a', 'E', 'B-PP', 'O'),\n ('T\u1ed5ng th\u1ed1ng', 'N', 'B-NP', 'O'),\n ('M\u1ef9', 'Np', 'B-NP', 'B-LOC'),\n ('Donald', 'Np', 'B-NP', 'B-PER'),\n ('Trump', 'Np', 'B-NP', 'I-PER')]\n</code></pre> <p>Deep Learning Model (requires <code>[deep]</code>)</p> <pre><code>pip install \"underthesea[deep]\"\n</code></pre> <pre><code>&gt;&gt;&gt; from underthesea import ner\n&gt;&gt;&gt; text = \"B\u1ed9 C\u00f4ng Th\u01b0\u01a1ng x\u00f3a m\u1ed9t t\u1ed5ng c\u1ee5c, gi\u1ea3m nhi\u1ec1u \u0111\u1ea7u m\u1ed1i\"\n&gt;&gt;&gt; ner(text, deep=True)\n[\n  {'entity': 'B-ORG', 'word': 'B\u1ed9'},\n  {'entity': 'I-ORG', 'word': 'C\u00f4ng'},\n  {'entity': 'I-ORG', 'word': 'Th\u01b0\u01a1ng'}\n]\n</code></pre> Text Classification - Categorizing text into predefined groups <p>CRF Model (Default)</p> <pre><code>&gt;&gt;&gt; from underthesea import classify\n\n&gt;&gt;&gt; classify('HLV \u0111\u1ea7u ti\u00ean \u1edf Premier League b\u1ecb sa th\u1ea3i sau 4 v\u00f2ng \u0111\u1ea5u')\n['The thao']\n\n&gt;&gt;&gt; classify('H\u1ed9i \u0111\u1ed3ng t\u01b0 v\u1ea5n kinh doanh Asean vinh danh gi\u1ea3i th\u01b0\u1edfng qu\u1ed1c t\u1ebf')\n['Kinh doanh']\n\n&gt;&gt;&gt; classify('L\u00e3i su\u1ea5t t\u1eeb BIDV r\u1ea5t \u01b0u \u0111\u00e3i', domain='bank')\n['INTEREST_RATE']\n</code></pre> <p>Prompt-based Model (requires <code>[prompt]</code>)</p> <pre><code>pip install \"underthesea[prompt]\"\nexport OPENAI_API_KEY=YOUR_KEY\n</code></pre> <pre><code>&gt;&gt;&gt; from underthesea import classify\n&gt;&gt;&gt; text = \"HLV ngo\u1ea1i \u0111\u00f2i g\u1ea7n t\u1ef7 m\u1ed7i th\u00e1ng d\u1eabn d\u1eaft tuy\u1ec3n Vi\u1ec7t Nam\"\n&gt;&gt;&gt; classify(text, model='prompt')\n'Th\u1ec3 thao'\n</code></pre> Sentiment Analysis - Determining text's emotional tone <pre><code>&gt;&gt;&gt; from underthesea import sentiment\n\n&gt;&gt;&gt; sentiment('h\u00e0ng k\u00e9m ch\u1ea5t lg,ch\u0103n \u0111\u1eafp l\u00ean d\u00ednh l\u00f4ng l\u00e1 kh\u1eafp ng\u01b0\u1eddi. th\u1ea5t v\u1ecdng')\n'negative'\n&gt;&gt;&gt; sentiment('S\u1ea3n ph\u1ea9m h\u01a1i nh\u1ecf so v\u1edbi t\u01b0\u1edfng t\u01b0\u1ee3ng nh\u01b0ng ch\u1ea5t l\u01b0\u1ee3ng t\u1ed1t, \u0111\u00f3ng g\u00f3i c\u1ea9n th\u1eadn.')\n'positive'\n\n&gt;&gt;&gt; sentiment('\u0110ky qua \u0111\u01b0\u1eddng link \u1edf b\u00e0i vi\u1ebft n\u00e0y t\u1eeb th\u1ee9 6 m\u00e0 gi\u1edd ch\u01b0a th\u1ea5y ai lhe h\u1ebft', domain='bank')\n['CUSTOMER_SUPPORT#negative']\n&gt;&gt;&gt; sentiment('Xem l\u1ea1i v\u1eabn th\u1ea5y x\u00fac \u0111\u1ed9ng v\u00e0 t\u1ef1 h\u00e0o v\u1ec1 BIDV c\u1ee7a m\u00ecnh', domain='bank')\n['TRADEMARK#positive']\n</code></pre> Translation - Translating Vietnamese to English (requires <code>[deep]</code>) <pre><code>pip install \"underthesea[deep]\"\n</code></pre> <pre><code>&gt;&gt;&gt; from underthesea import translate\n\n&gt;&gt;&gt; translate(\"H\u00e0 N\u1ed9i l\u00e0 th\u1ee7 \u0111\u00f4 c\u1ee7a Vi\u1ec7t Nam\")\n'Hanoi is the capital of Vietnam'\n\n&gt;&gt;&gt; translate(\"\u1ea8m th\u1ef1c Vi\u1ec7t Nam n\u1ed5i ti\u1ebfng tr\u00ean th\u1ebf gi\u1edbi\")\n'Vietnamese cuisine is famous around the world'\n\n&gt;&gt;&gt; translate(\"I love Vietnamese food\", source_lang='en', target_lang='vi')\n'T\u00f4i y\u00eau \u1ea9m th\u1ef1c Vi\u1ec7t Nam'\n</code></pre> Language Detection - Identifying the language of text (requires <code>[langdetect]</code>) <pre><code>pip install \"underthesea[langdetect]\"\n</code></pre> <pre><code>&gt;&gt;&gt; from underthesea import lang_detect\n\n&gt;&gt;&gt; lang_detect(\"C\u1ef1u binh M\u1ef9 tr\u1ea3 nh\u1eadt k\u00fd nh\u1eb9 l\u00f2ng khi th\u1ea5y cu\u1ed9c s\u1ed1ng h\u00f2a b\u00ecnh t\u1ea1i Vi\u1ec7t Nam\")\n'vi'\n</code></pre> Text-to-Speech - Converting text into spoken audio (requires <code>[voice]</code>) <pre><code>pip install \"underthesea[voice]\"\nunderthesea download-model VIET_TTS_V0_4_1\n</code></pre> <pre><code>&gt;&gt;&gt; from underthesea.pipeline.tts import tts\n\n&gt;&gt;&gt; tts(\"C\u1ef1u binh M\u1ef9 tr\u1ea3 nh\u1eadt k\u00fd nh\u1eb9 l\u00f2ng khi th\u1ea5y cu\u1ed9c s\u1ed1ng h\u00f2a b\u00ecnh t\u1ea1i Vi\u1ec7t Nam\")\n# A new audio file named `sound.wav` will be generated.\n</code></pre> <p>Command line usage:</p> <pre><code>underthesea tts \"C\u1ef1u binh M\u1ef9 tr\u1ea3 nh\u1eadt k\u00fd nh\u1eb9 l\u00f2ng khi th\u1ea5y cu\u1ed9c s\u1ed1ng h\u00f2a b\u00ecnh t\u1ea1i Vi\u1ec7t Nam\"\n</code></pre>"},{"location":"#vietnamese-nlp-resources","title":"Vietnamese NLP Resources","text":"<p>List available resources:</p> <pre><code>underthesea list-data\n</code></pre> Name Type License Year CP_Vietnamese_VLC_v2_2022 Plaintext Open 2023 UIT_ABSA_RESTAURANT Sentiment Open 2021 UIT_ABSA_HOTEL Sentiment Open 2021 SE_Vietnamese-UBS Sentiment Open 2020 DI_Vietnamese-UVD Dictionary Open 2020 UTS2017-BANK Categorized Open 2017 VNTC Categorized Open 2007 <p>Download resources:</p> <pre><code>underthesea download-data CP_Vietnamese_VLC_v2_2022\n</code></pre>"},{"location":"#up-coming-features","title":"Up Coming Features","text":"<ul> <li>Automatic Speech Recognition</li> <li>Chatbot Agent</li> </ul>"},{"location":"#community","title":"Community","text":"<ul> <li>GitHub Repository</li> <li>Facebook Page</li> <li>YouTube Channel</li> <li>Google Colab Notebook</li> </ul>"},{"location":"#support","title":"Support","text":"<p>If you found this project helpful, please consider supporting us.</p>"},{"location":"history/","title":"Changelog","text":"<p>All notable changes to Underthesea are documented here.</p>"},{"location":"history/#912-2025-01-24","title":"9.1.2 (2025-01-24)","text":""},{"location":"history/#new-features","title":"New Features","text":"<ul> <li>Add <code>labels</code> property to <code>classify</code> and <code>sentiment</code> functions (#865)</li> <li><code>classify.labels</code> - Get all available classification labels</li> <li><code>classify.bank.labels</code> - Get bank domain classification labels</li> <li><code>sentiment.labels</code> - Get all available sentiment labels</li> <li><code>sentiment.bank.labels</code> - Get bank domain sentiment labels</li> </ul>"},{"location":"history/#900-2025-01-xx","title":"9.0.0 (2025-01-XX)","text":""},{"location":"history/#new-features_1","title":"New Features","text":"<ul> <li>Vietnamese-English translation module (#856)</li> <li><code>translate()</code> function for VI\u2192EN and EN\u2192VI translation</li> <li>Requires <code>[deep]</code> installation</li> </ul>"},{"location":"history/#improvements","title":"Improvements","text":"<ul> <li>Migrated from Flake8/Pylint to Ruff for linting (#857)</li> </ul>"},{"location":"history/#830-2025-09-28","title":"8.3.0 (2025-09-28)","text":"<ul> <li>Remove flake8 as runtime dependency by @BLKSerene in #818</li> <li>Train text classification model for dataset VNTC2017_BANK by @rain1024 in #819</li> <li>Build wheels for macOS x86-64 by @BLKSerene in #820</li> <li>Add datasets UTS2017_Bank by @rain1024 in #822</li> <li>Add bank model by @rain1024 in #824</li> </ul>"},{"location":"history/#820-2025-09-21","title":"8.2.0 (2025-09-21)","text":"<ul> <li>Update project structure, create extensions/lab folder by @rain1024 in #812</li> <li>Create Sonar Core 1 - System Card by @rain1024 in #813</li> <li>Update output format of model sonar_core_1 by @rain1024 in #815</li> </ul>"},{"location":"history/#810-2025-09-21","title":"8.1.0 (2025-09-21)","text":"<ul> <li>Fix missing .pkl files by @rain1024 in #809</li> </ul>"},{"location":"history/#801-2025-09-21","title":"8.0.1 (2025-09-21)","text":"<ul> <li>Security updates for dependencies</li> <li>Update publish distribution to Pypi workflow by @rain1024 in #805</li> <li>Fix missing .txt files by @rain1024 in #806</li> </ul>"},{"location":"history/#800-2025-09-20","title":"8.0.0 (2025-09-20)","text":""},{"location":"history/#new-features_2","title":"New Features","text":"<ul> <li>Underthesea Languages v2 by @rain1024 in #748</li> <li>Interactive Page for Most Frequently Used Vietnamese Words by @rain1024 in #756</li> </ul>"},{"location":"history/#improvements_1","title":"Improvements","text":"<ul> <li>Support Python 3.12, 3.13 by @rain1024 in #777</li> <li>Update PyO3 API usage by @trunghieu0207 in #768</li> <li>Update project structure by @rain1024 in #790</li> </ul>"},{"location":"history/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Fix wrong global var in sent_tokenize by @Darejkal in #764</li> <li>Minor fix (Logo in Readme.rst) by @ichxorya in #761</li> </ul>"},{"location":"history/#684-2024-06-22","title":"6.8.4 (2024-06-22)","text":"<ul> <li>Optimize imports by @rain1024 in #741</li> <li>Remove issue-manager workflow by @rain1024 in #726</li> <li>Add lang_detect module by @rain1024 in #733</li> </ul>"},{"location":"history/#680-2023-09-23","title":"6.8.0 (2023-09-23)","text":"<ul> <li>Release Source Distribution for underthesea_core by @rain1024 in #708</li> <li>Create docker image for underthesea by @rain1024 in #711</li> <li>Code refactoring by @tosemml in #713</li> <li>Fix permission errors on removing downloaded models by @BLKSerene in #715</li> </ul>"},{"location":"history/#670-2023-07-28","title":"6.7.0 (2023-07-28)","text":"<ul> <li>Zero shot classification with OpenAI API by @rain1024 in #700</li> </ul>"},{"location":"history/#660-2023-07-27","title":"6.6.0 (2023-07-27)","text":"<ul> <li>Fix bug word_tokenize by @rain1024 in #697</li> </ul>"},{"location":"history/#650-2023-07-14","title":"6.5.0 (2023-07-14)","text":"<ul> <li>Fix text_normalizer token rules</li> </ul>"},{"location":"history/#640-2023-07-14","title":"6.4.0 (2023-07-14)","text":"<ul> <li>Fix fixed_words regex</li> </ul>"},{"location":"history/#630-2023-06-28","title":"6.3.0 (2023-06-28)","text":"<ul> <li>Support MacOS ARM</li> </ul>"},{"location":"history/#620-2023-03-04","title":"6.2.0 (2023-03-04)","text":"<ul> <li>Add Text to Speech API by @rain1024 in #668</li> <li>Provide training script for word segmentation, pos tagging, and NER by @rain1024 in #666</li> <li>Create UTS_Dictionary v1.0 datasets by @rain1024 in #663</li> </ul>"},{"location":"history/#614-2023-02-26","title":"6.1.4 (2023-02-26)","text":"<ul> <li>Support underthesea_core with Python 3.11 by @rain1024 in #659</li> </ul>"},{"location":"history/#612-2023-02-15","title":"6.1.2 (2023-02-15)","text":"<ul> <li>Add option fixed_words to tokenize and word_tokenize API by @rain1024 in #649</li> </ul>"},{"location":"history/#600-2023-01-01","title":"6.0.0 (2023-01-01)","text":"<ul> <li>Happy New Year 2023! Version bump!</li> </ul>"},{"location":"history/#141-2022-12-17","title":"1.4.1 (2022-12-17)","text":"<ul> <li>Create underthesea app</li> <li>Add viet2ipa module</li> <li>Training NER model with VLSP2016 dataset using BERT</li> <li>Remove unidecode as a dependency</li> </ul>"},{"location":"history/#135-2022-10-31","title":"1.3.5 (2022-10-31)","text":"<ul> <li>Add Text Normalization module</li> <li>Release underthesea_core version 0.0.5a2</li> <li>Support GLIBC_2.17</li> <li>Update resources path</li> <li>Fix function word_tokenize</li> </ul>"},{"location":"history/#134-2022-01-08","title":"1.3.4 (2022-01-08)","text":"<ul> <li>Demo chatbot with rasa</li> <li>Lite version of underthesea</li> <li>Increase word_tokenize speed 1.5 times</li> <li>Add build for Windows</li> </ul>"},{"location":"history/#133-2021-09-02","title":"1.3.3 (2021-09-02)","text":"<ul> <li>Update torch and transformer dependency</li> </ul>"},{"location":"history/#132-2021-08-04","title":"1.3.2 (2021-08-04)","text":"<ul> <li>Publish two ABSA open datasets</li> <li>Migrate from travis-ci to github actions</li> <li>Update ParserTrainer</li> <li>Add pipeline folder</li> </ul>"},{"location":"history/#131-2021-01-11","title":"1.3.1 (2021-01-11)","text":"<ul> <li>Compatible with newer version of scikit-learn</li> <li>Retrain classification and sentiment models</li> <li>Add ClassifierTrainer</li> <li>Add 3 new datasets</li> </ul>"},{"location":"history/#130-2020-12-11","title":"1.3.0 (2020-12-11)","text":"<ul> <li>Remove languageflow dependency</li> <li>Remove tabulate dependency</li> <li>Dependency Parsing</li> </ul>"},{"location":"history/#100-2017-03-01","title":"1.0.0 (2017-03-01)","text":"<ul> <li>First release on PyPI</li> <li>First release on ReadTheDocs</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section provides complete API documentation for all Underthesea functions.</p>"},{"location":"api/#core-functions","title":"Core Functions","text":"Function Description Install <code>sent_tokenize</code> Sentence segmentation Core <code>text_normalize</code> Text normalization Core <code>word_tokenize</code> Word segmentation Core <code>pos_tag</code> Part-of-speech tagging Core <code>chunk</code> Phrase chunking Core <code>ner</code> Named entity recognition Core <code>classify</code> Text classification Core <code>sentiment</code> Sentiment analysis Core"},{"location":"api/#deep-learning-functions","title":"Deep Learning Functions","text":"Function Description Install <code>dependency_parse</code> Dependency parsing <code>[deep]</code> <code>translate</code> Vietnamese-English translation <code>[deep]</code>"},{"location":"api/#additional-functions","title":"Additional Functions","text":"Function Description Install <code>lang_detect</code> Language detection <code>[langdetect]</code> <code>tts</code> Text-to-speech <code>[voice]</code>"},{"location":"api/#quick-import","title":"Quick Import","text":"<p>All main functions can be imported directly from <code>underthesea</code>:</p> <pre><code>from underthesea import (\n    sent_tokenize,\n    text_normalize,\n    word_tokenize,\n    pos_tag,\n    chunk,\n    ner,\n    classify,\n    sentiment,\n    dependency_parse,  # requires [deep]\n    translate,         # requires [deep]\n    lang_detect,       # requires [langdetect]\n)\n</code></pre>"},{"location":"api/#common-parameters","title":"Common Parameters","text":"<p>Many functions share common parameters:</p>"},{"location":"api/#format","title":"<code>format</code>","text":"<p>Controls output format:</p> <ul> <li><code>None</code> (default): Returns a list</li> <li><code>\"text\"</code>: Returns a string with underscores joining multi-word tokens</li> </ul> <pre><code>word_tokenize(\"Vi\u1ec7t Nam\", format=None)   # ['Vi\u1ec7t Nam']\nword_tokenize(\"Vi\u1ec7t Nam\", format=\"text\") # 'Vi\u1ec7t_Nam'\n</code></pre>"},{"location":"api/#model","title":"<code>model</code>","text":"<p>Specifies which model to use:</p> <pre><code># Use default model\nner(\"text\")\n\n# Use specific model\nner(\"text\", deep=True)  # Use deep learning model\nclassify(\"text\", model='prompt')  # Use OpenAI model\n</code></pre>"},{"location":"api/#domain","title":"<code>domain</code>","text":"<p>Specifies the domain for domain-specific models:</p> <pre><code>classify(\"text\", domain='bank')\nsentiment(\"text\", domain='bank')\n</code></pre>"},{"location":"api/chunk/","title":"chunk","text":"<p>Group words into meaningful phrases (chunking/shallow parsing).</p>"},{"location":"api/chunk/#usage","title":"Usage","text":"<pre><code>from underthesea import chunk\n\ntext = \"B\u00e1c s\u0129 b\u00e2y gi\u1edd c\u00f3 th\u1ec3 th\u1ea3n nhi\u00ean b\u00e1o tin b\u1ec7nh nh\u00e2n b\u1ecb ung th\u01b0?\"\nchunks = chunk(text)\nprint(chunks)\n# [('B\u00e1c s\u0129', 'N', 'B-NP'),\n#  ('b\u00e2y gi\u1edd', 'P', 'B-NP'),\n#  ('c\u00f3 th\u1ec3', 'R', 'O'),\n#  ('th\u1ea3n nhi\u00ean', 'A', 'B-AP'),\n#  ('b\u00e1o', 'V', 'B-VP'),\n#  ('tin', 'N', 'B-NP'),\n#  ('b\u1ec7nh nh\u00e2n', 'N', 'B-NP'),\n#  ('b\u1ecb', 'V', 'B-VP'),\n#  ('ung th\u01b0', 'N', 'B-NP'),\n#  ('?', 'CH', 'O')]\n</code></pre>"},{"location":"api/chunk/#function-signature","title":"Function Signature","text":"<pre><code>def chunk(\n    sentence: str,\n    format: str = None\n) -&gt; list[tuple[str, str, str]]\n</code></pre>"},{"location":"api/chunk/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>sentence</code> <code>str</code> The input text to chunk <code>format</code> <code>str</code> <code>None</code> Output format (currently only <code>None</code> supported)"},{"location":"api/chunk/#returns","title":"Returns","text":"Type Description <code>list[tuple[str, str, str]]</code> List of (word, POS tag, chunk tag) tuples"},{"location":"api/chunk/#chunk-tags","title":"Chunk Tags","text":"Tag Description <code>B-NP</code> Beginning of Noun Phrase <code>I-NP</code> Inside Noun Phrase <code>B-VP</code> Beginning of Verb Phrase <code>I-VP</code> Inside Verb Phrase <code>B-AP</code> Beginning of Adjective Phrase <code>I-AP</code> Inside Adjective Phrase <code>B-PP</code> Beginning of Prepositional Phrase <code>I-PP</code> Inside Prepositional Phrase <code>O</code> Outside any chunk"},{"location":"api/chunk/#examples","title":"Examples","text":""},{"location":"api/chunk/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import chunk\n\ntext = \"B\u00e1c s\u0129 b\u00e2y gi\u1edd c\u00f3 th\u1ec3 th\u1ea3n nhi\u00ean b\u00e1o tin b\u1ec7nh nh\u00e2n b\u1ecb ung th\u01b0?\"\nchunks = chunk(text)\nfor word, pos, chunk_tag in chunks:\n    print(f\"{word:15} {pos:5} {chunk_tag}\")\n</code></pre>"},{"location":"api/chunk/#extracting-noun-phrases","title":"Extracting Noun Phrases","text":"<pre><code>text = \"Sinh vi\u00ean \u0110\u1ea1i h\u1ecdc B\u00e1ch Khoa H\u00e0 N\u1ed9i \u0111\u1ea1t gi\u1ea3i nh\u1ea5t\"\nchunks = chunk(text)\n\n# Extract noun phrases\ncurrent_np = []\nnoun_phrases = []\n\nfor word, pos, chunk_tag in chunks:\n    if chunk_tag == 'B-NP':\n        if current_np:\n            noun_phrases.append(' '.join(current_np))\n        current_np = [word]\n    elif chunk_tag == 'I-NP':\n        current_np.append(word)\n    else:\n        if current_np:\n            noun_phrases.append(' '.join(current_np))\n            current_np = []\n\nif current_np:\n    noun_phrases.append(' '.join(current_np))\n\nprint(noun_phrases)\n</code></pre>"},{"location":"api/chunk/#extracting-verb-phrases","title":"Extracting Verb Phrases","text":"<pre><code>text = \"T\u00f4i \u0111ang h\u1ecdc ti\u1ebfng Vi\u1ec7t v\u00e0 s\u1ebd \u0111i du l\u1ecbch\"\nchunks = chunk(text)\n\nverb_phrases = [word for word, pos, tag in chunks if tag.endswith('VP')]\nprint(verb_phrases)\n</code></pre>"},{"location":"api/chunk/#notes","title":"Notes","text":"<ul> <li>Chunking is performed on top of word segmentation and POS tagging</li> <li>It provides shallow syntactic structure without full parsing</li> <li>Useful for extracting noun phrases, verb phrases, etc.</li> </ul>"},{"location":"api/classify/","title":"classify","text":"<p>Categorize text into predefined categories.</p>"},{"location":"api/classify/#usage","title":"Usage","text":"<pre><code>from underthesea import classify\n\ntext = \"HLV \u0111\u1ea7u ti\u00ean \u1edf Premier League b\u1ecb sa th\u1ea3i sau 4 v\u00f2ng \u0111\u1ea5u\"\ncategory = classify(text)\nprint(category)\n# ['The thao']\n</code></pre>"},{"location":"api/classify/#function-signature","title":"Function Signature","text":"<pre><code>def classify(\n    X: str,\n    domain: str = None,\n    model: str = None\n) -&gt; list[str] | str\n</code></pre>"},{"location":"api/classify/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>X</code> <code>str</code> The input text to classify <code>domain</code> <code>str</code> <code>None</code> Domain for classification (<code>'bank'</code>) <code>model</code> <code>str</code> <code>None</code> Model type (<code>'prompt'</code> for OpenAI)"},{"location":"api/classify/#returns","title":"Returns","text":"Type Description <code>list[str]</code> List of predicted categories"},{"location":"api/classify/#available-domains","title":"Available Domains","text":""},{"location":"api/classify/#general-default","title":"General (Default)","text":"<p>News topic classification:</p> Category Description <code>The thao</code> Sports <code>Kinh doanh</code> Business <code>Chinh tri Xa hoi</code> Politics &amp; Society <code>Van hoa</code> Culture <code>Khoa hoc</code> Science <code>Phap luat</code> Law <code>Suc khoe</code> Health <code>Doi song</code> Lifestyle <code>The gioi</code> World <code>Vi tinh</code> Technology"},{"location":"api/classify/#bank-domain","title":"Bank Domain","text":"<p>Bank-related topic classification:</p> <pre><code>classify(text, domain='bank')\n</code></pre> Category Description <code>INTEREST_RATE</code> Interest rate related <code>CUSTOMER_SUPPORT</code> Customer service <code>PRODUCT</code> Bank products <code>TRADEMARK</code> Brand/trademark"},{"location":"api/classify/#examples","title":"Examples","text":""},{"location":"api/classify/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import classify\n\n# Sports\nclassify(\"HLV \u0111\u1ea7u ti\u00ean \u1edf Premier League b\u1ecb sa th\u1ea3i sau 4 v\u00f2ng \u0111\u1ea5u\")\n# ['The thao']\n\n# Business\nclassify(\"H\u1ed9i \u0111\u1ed3ng t\u01b0 v\u1ea5n kinh doanh Asean vinh danh gi\u1ea3i th\u01b0\u1edfng qu\u1ed1c t\u1ebf\")\n# ['Kinh doanh']\n</code></pre>"},{"location":"api/classify/#bank-domain_1","title":"Bank Domain","text":"<pre><code>from underthesea import classify\n\nclassify(\"L\u00e3i su\u1ea5t t\u1eeb BIDV r\u1ea5t \u01b0u \u0111\u00e3i\", domain='bank')\n# ['INTEREST_RATE']\n\nclassify(\"Nh\u00e2n vi\u00ean h\u1ed7 tr\u1ee3 r\u1ea5t nhi\u1ec7t t\u00ecnh\", domain='bank')\n# ['CUSTOMER_SUPPORT']\n</code></pre>"},{"location":"api/classify/#prompt-based-model","title":"Prompt-based Model","text":"<p>Requires Installation</p> <pre><code>pip install \"underthesea[prompt]\"\nexport OPENAI_API_KEY=your_api_key\n</code></pre> <pre><code>from underthesea import classify\n\ntext = \"HLV ngo\u1ea1i \u0111\u00f2i g\u1ea7n t\u1ef7 m\u1ed7i th\u00e1ng d\u1eabn d\u1eaft tuy\u1ec3n Vi\u1ec7t Nam\"\nresult = classify(text, model='prompt')\nprint(result)\n# 'Th\u1ec3 thao'\n</code></pre>"},{"location":"api/classify/#processing-multiple-documents","title":"Processing Multiple Documents","text":"<pre><code>from underthesea import classify\n\ndocuments = [\n    \"\u0110\u1ed9i tuy\u1ec3n Vi\u1ec7t Nam th\u1eafng \u0111\u1eadm trong tr\u1eadn \u0111\u1ea5u\",\n    \"Gi\u00e1 v\u00e0ng t\u0103ng m\u1ea1nh trong tu\u1ea7n qua\",\n    \"Ph\u00e1t hi\u1ec7n virus m\u1edbi g\u00e2y b\u1ec7nh \u1edf ch\u00e2u Phi\"\n]\n\nfor doc in documents:\n    category = classify(doc)\n    print(f\"{doc[:30]}... -&gt; {category}\")\n</code></pre>"},{"location":"api/classify/#accessing-available-labels","title":"Accessing Available Labels","text":"<p>You can access all available category labels using the <code>labels</code> property:</p> <pre><code>from underthesea import classify\n\n# Get labels for general domain\nclassify.labels\n# ['chinh_tri_xa_hoi', 'doi_song', 'khoa_hoc', 'kinh_doanh', 'phap_luat',\n#  'suc_khoe', 'the_gioi', 'the_thao', 'van_hoa', 'vi_tinh']\n\n# Get labels for bank domain\nclassify.bank.labels\n# ['ACCOUNT', 'CARD', 'CUSTOMER_SUPPORT', 'DISCOUNT', 'INTEREST_RATE',\n#  'INTERNET_BANKING', 'LOAN', 'MONEY_TRANSFER', 'OTHER', 'PAYMENT',\n#  'PROMOTION', 'SAVING', 'SECURITY', 'TRADEMARK']\n</code></pre>"},{"location":"api/classify/#notes","title":"Notes","text":"<ul> <li>The default model is trained on Vietnamese news data</li> <li>The bank domain model is specialized for banking feedback</li> <li>Prompt-based model uses OpenAI API and requires an API key</li> <li>First call may take longer due to model loading</li> <li>Use <code>classify.labels</code> to get all available categories for the default domain</li> <li>Use <code>classify.bank.labels</code> to get all available categories for the bank domain</li> </ul>"},{"location":"api/dependency_parse/","title":"dependency_parse","text":"<p>Analyze the grammatical structure and dependencies between words.</p> <p>Requires Deep Learning</p> <p>This function requires the deep learning dependencies: <pre><code>pip install \"underthesea[deep]\"\n</code></pre></p>"},{"location":"api/dependency_parse/#usage","title":"Usage","text":"<pre><code>from underthesea import dependency_parse\n\ntext = \"T\u1ed1i 29/11, Vi\u1ec7t Nam th\u00eam 2 ca m\u1eafc Covid-19\"\nresult = dependency_parse(text)\nprint(result)\n# [('T\u1ed1i', 5, 'obl:tmod'),\n#  ('29/11', 1, 'flat:date'),\n#  (',', 1, 'punct'),\n#  ('Vi\u1ec7t Nam', 5, 'nsubj'),\n#  ('th\u00eam', 0, 'root'),\n#  ('2', 7, 'nummod'),\n#  ('ca', 5, 'obj'),\n#  ('m\u1eafc', 7, 'nmod'),\n#  ('Covid-19', 8, 'nummod')]\n</code></pre>"},{"location":"api/dependency_parse/#function-signature","title":"Function Signature","text":"<pre><code>def dependency_parse(sentence: str) -&gt; list[tuple[str, int, str]]\n</code></pre>"},{"location":"api/dependency_parse/#parameters","title":"Parameters","text":"Parameter Type Description <code>sentence</code> <code>str</code> The input text to parse"},{"location":"api/dependency_parse/#returns","title":"Returns","text":"Type Description <code>list[tuple[str, int, str]]</code> List of (word, head_index, relation) tuples <p>Each tuple contains:</p> <ul> <li><code>word</code>: The word token</li> <li><code>head_index</code>: Index of the head word (0 = root)</li> <li><code>relation</code>: The dependency relation type</li> </ul>"},{"location":"api/dependency_parse/#dependency-relations","title":"Dependency Relations","text":"Relation Description <code>root</code> Root of the sentence <code>nsubj</code> Nominal subject <code>obj</code> Object <code>obl</code> Oblique nominal <code>obl:tmod</code> Temporal modifier <code>amod</code> Adjectival modifier <code>nmod</code> Nominal modifier <code>nummod</code> Numeric modifier <code>punct</code> Punctuation <code>flat:date</code> Flat date expression <code>compound</code> Compound word"},{"location":"api/dependency_parse/#examples","title":"Examples","text":""},{"location":"api/dependency_parse/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import dependency_parse\n\ntext = \"T\u1ed1i 29/11, Vi\u1ec7t Nam th\u00eam 2 ca m\u1eafc Covid-19\"\nresult = dependency_parse(text)\n\nfor i, (word, head, rel) in enumerate(result, 1):\n    print(f\"{i}\\t{word}\\t{head}\\t{rel}\")\n# 1    T\u1ed1i         5    obl:tmod\n# 2    29/11       1    flat:date\n# 3    ,           1    punct\n# 4    Vi\u1ec7t Nam    5    nsubj\n# 5    th\u00eam        0    root\n# 6    2           7    nummod\n# 7    ca          5    obj\n# 8    m\u1eafc         7    nmod\n# 9    Covid-19    8    nummod\n</code></pre>"},{"location":"api/dependency_parse/#finding-the-root","title":"Finding the Root","text":"<pre><code>text = \"T\u00f4i y\u00eau Vi\u1ec7t Nam\"\nresult = dependency_parse(text)\n\nroot = [(i, word) for i, (word, head, rel) in enumerate(result, 1) if rel == 'root']\nprint(f\"Root: {root}\")\n# Root: [(2, 'y\u00eau')]\n</code></pre>"},{"location":"api/dependency_parse/#finding-subjects-and-objects","title":"Finding Subjects and Objects","text":"<pre><code>text = \"Sinh vi\u00ean \u0111\u1ecdc s\u00e1ch \u1edf th\u01b0 vi\u1ec7n\"\nresult = dependency_parse(text)\n\nsubjects = [word for word, head, rel in result if rel == 'nsubj']\nobjects = [word for word, head, rel in result if rel == 'obj']\n\nprint(f\"Subjects: {subjects}\")\nprint(f\"Objects: {objects}\")\n</code></pre>"},{"location":"api/dependency_parse/#notes","title":"Notes","text":"<ul> <li>This function uses a transformer-based model</li> <li>First call may take longer due to model loading</li> <li>Requires significant memory for the deep learning model</li> </ul>"},{"location":"api/lang_detect/","title":"lang_detect","text":"<p>Identify the language of text.</p> <p>Requires Language Detection</p> <p>This function requires the langdetect dependencies: <pre><code>pip install \"underthesea[langdetect]\"\n</code></pre></p>"},{"location":"api/lang_detect/#usage","title":"Usage","text":"<pre><code>from underthesea import lang_detect\n\ntext = \"C\u1ef1u binh M\u1ef9 tr\u1ea3 nh\u1eadt k\u00fd nh\u1eb9 l\u00f2ng khi th\u1ea5y cu\u1ed9c s\u1ed1ng h\u00f2a b\u00ecnh t\u1ea1i Vi\u1ec7t Nam\"\nlang = lang_detect(text)\nprint(lang)\n# 'vi'\n</code></pre>"},{"location":"api/lang_detect/#function-signature","title":"Function Signature","text":"<pre><code>def lang_detect(text: str) -&gt; str\n</code></pre>"},{"location":"api/lang_detect/#parameters","title":"Parameters","text":"Parameter Type Description <code>text</code> <code>str</code> The input text to analyze"},{"location":"api/lang_detect/#returns","title":"Returns","text":"Type Description <code>str</code> ISO 639-1 language code"},{"location":"api/lang_detect/#supported-languages","title":"Supported Languages","text":"<p>The function can detect 176 languages. Common codes:</p> Code Language <code>vi</code> Vietnamese <code>en</code> English <code>zh</code> Chinese <code>ja</code> Japanese <code>ko</code> Korean <code>fr</code> French <code>de</code> German <code>es</code> Spanish <code>ru</code> Russian <code>th</code> Thai"},{"location":"api/lang_detect/#examples","title":"Examples","text":""},{"location":"api/lang_detect/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import lang_detect\n\n# Vietnamese\nlang_detect(\"C\u1ef1u binh M\u1ef9 tr\u1ea3 nh\u1eadt k\u00fd nh\u1eb9 l\u00f2ng\")\n# 'vi'\n\n# English\nlang_detect(\"Hello, how are you today?\")\n# 'en'\n\n# Chinese\nlang_detect(\"\u4f60\u597d\uff0c\u4eca\u5929\u600e\u4e48\u6837\uff1f\")\n# 'zh'\n\n# Japanese\nlang_detect(\"\u3053\u3093\u306b\u3061\u306f\u3001\u5143\u6c17\u3067\u3059\u304b\uff1f\")\n# 'ja'\n</code></pre>"},{"location":"api/lang_detect/#detecting-multiple-texts","title":"Detecting Multiple Texts","text":"<pre><code>from underthesea import lang_detect\n\ntexts = [\n    \"Xin ch\u00e0o Vi\u1ec7t Nam\",\n    \"Hello World\",\n    \"Bonjour le monde\",\n    \"Hallo Welt\"\n]\n\nfor text in texts:\n    lang = lang_detect(text)\n    print(f\"{text} -&gt; {lang}\")\n# Xin ch\u00e0o Vi\u1ec7t Nam -&gt; vi\n# Hello World -&gt; en\n# Bonjour le monde -&gt; fr\n# Hallo Welt -&gt; de\n</code></pre>"},{"location":"api/lang_detect/#filtering-by-language","title":"Filtering by Language","text":"<pre><code>from underthesea import lang_detect\n\ndocuments = [\n    \"Vi\u1ec7t Nam l\u00e0 m\u1ed9t \u0111\u1ea5t n\u01b0\u1edbc xinh \u0111\u1eb9p\",\n    \"This is an English sentence\",\n    \"H\u00f4m nay tr\u1eddi \u0111\u1eb9p qu\u00e1\",\n    \"The weather is nice today\"\n]\n\n# Filter Vietnamese documents\nvietnamese_docs = [doc for doc in documents if lang_detect(doc) == 'vi']\nprint(vietnamese_docs)\n# ['Vi\u1ec7t Nam l\u00e0 m\u1ed9t \u0111\u1ea5t n\u01b0\u1edbc xinh \u0111\u1eb9p', 'H\u00f4m nay tr\u1eddi \u0111\u1eb9p qu\u00e1']\n</code></pre>"},{"location":"api/lang_detect/#language-statistics","title":"Language Statistics","text":"<pre><code>from collections import Counter\nfrom underthesea import lang_detect\n\ndocuments = [\n    \"Xin ch\u00e0o\",\n    \"Hello\",\n    \"T\u1ea1m bi\u1ec7t\",\n    \"Goodbye\",\n    \"C\u1ea3m \u01a1n\",\n    \"Merci\"\n]\n\nlangs = [lang_detect(doc) for doc in documents]\ndistribution = Counter(langs)\nprint(distribution)\n# Counter({'vi': 3, 'en': 2, 'fr': 1})\n</code></pre>"},{"location":"api/lang_detect/#notes","title":"Notes","text":"<ul> <li>Uses FastText's language identification model</li> <li>Works best with longer text (at least a few words)</li> <li>Very short text may be less accurate</li> <li>First call may take longer due to model loading</li> </ul>"},{"location":"api/ner/","title":"ner","text":"<p>Identify and classify named entities in text.</p>"},{"location":"api/ner/#usage","title":"Usage","text":"<pre><code>from underthesea import ner\n\ntext = \"Ch\u01b0a ti\u1ebft l\u1ed9 l\u1ecbch tr\u00ecnh t\u1edbi Vi\u1ec7t Nam c\u1ee7a T\u1ed5ng th\u1ed1ng M\u1ef9 Donald Trump\"\nentities = ner(text)\nprint(entities)\n# [('Ch\u01b0a', 'R', 'O', 'O'),\n#  ('ti\u1ebft l\u1ed9', 'V', 'B-VP', 'O'),\n#  ('l\u1ecbch tr\u00ecnh', 'V', 'B-VP', 'O'),\n#  ('t\u1edbi', 'E', 'B-PP', 'O'),\n#  ('Vi\u1ec7t Nam', 'Np', 'B-NP', 'B-LOC'),\n#  ('c\u1ee7a', 'E', 'B-PP', 'O'),\n#  ('T\u1ed5ng th\u1ed1ng', 'N', 'B-NP', 'O'),\n#  ('M\u1ef9', 'Np', 'B-NP', 'B-LOC'),\n#  ('Donald', 'Np', 'B-NP', 'B-PER'),\n#  ('Trump', 'Np', 'B-NP', 'I-PER')]\n</code></pre>"},{"location":"api/ner/#function-signature","title":"Function Signature","text":"<pre><code>def ner(\n    sentence: str,\n    format: str = None,\n    deep: bool = False\n) -&gt; list[tuple] | list[dict]\n</code></pre>"},{"location":"api/ner/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>sentence</code> <code>str</code> The input text <code>format</code> <code>str</code> <code>None</code> Output format <code>deep</code> <code>bool</code> <code>False</code> Use deep learning model (requires <code>[deep]</code> install)"},{"location":"api/ner/#returns","title":"Returns","text":""},{"location":"api/ner/#crf-model-default","title":"CRF Model (default)","text":"Type Description <code>list[tuple[str, str, str, str]]</code> List of (word, POS, chunk, entity) tuples"},{"location":"api/ner/#deep-learning-model-deeptrue","title":"Deep Learning Model (<code>deep=True</code>)","text":"Type Description <code>list[dict]</code> List of dictionaries with <code>entity</code> and <code>word</code> keys"},{"location":"api/ner/#entity-types","title":"Entity Types","text":"Tag Description <code>PER</code> Person <code>LOC</code> Location <code>ORG</code> Organization <code>O</code> Not an entity <p>Tags use BIO format:</p> <ul> <li><code>B-XXX</code>: Beginning of entity</li> <li><code>I-XXX</code>: Inside entity</li> <li><code>O</code>: Outside (not an entity)</li> </ul>"},{"location":"api/ner/#examples","title":"Examples","text":""},{"location":"api/ner/#basic-usage-crf-model","title":"Basic Usage (CRF Model)","text":"<pre><code>from underthesea import ner\n\ntext = \"Ch\u01b0a ti\u1ebft l\u1ed9 l\u1ecbch tr\u00ecnh t\u1edbi Vi\u1ec7t Nam c\u1ee7a T\u1ed5ng th\u1ed1ng M\u1ef9 Donald Trump\"\nentities = ner(text)\n\n# Extract only named entities\nfor word, pos, chunk, entity in entities:\n    if entity != 'O':\n        print(f\"{word}: {entity}\")\n# Vi\u1ec7t Nam: B-LOC\n# M\u1ef9: B-LOC\n# Donald: B-PER\n# Trump: I-PER\n</code></pre>"},{"location":"api/ner/#deep-learning-model","title":"Deep Learning Model","text":"<p>Requires Installation</p> <pre><code>pip install \"underthesea[deep]\"\n</code></pre> <pre><code>from underthesea import ner\n\ntext = \"B\u1ed9 C\u00f4ng Th\u01b0\u01a1ng x\u00f3a m\u1ed9t t\u1ed5ng c\u1ee5c, gi\u1ea3m nhi\u1ec1u \u0111\u1ea7u m\u1ed1i\"\nentities = ner(text, deep=True)\nprint(entities)\n# [\n#   {'entity': 'B-ORG', 'word': 'B\u1ed9'},\n#   {'entity': 'I-ORG', 'word': 'C\u00f4ng'},\n#   {'entity': 'I-ORG', 'word': 'Th\u01b0\u01a1ng'}\n# ]\n</code></pre>"},{"location":"api/ner/#extracting-entities-by-type","title":"Extracting Entities by Type","text":"<pre><code>text = \"\u00d4ng Nguy\u1ec5n V\u0103n A t\u1eeb H\u00e0 N\u1ed9i \u0111\u1ebfn c\u00f4ng ty ABC\"\nentities = ner(text)\n\npersons = []\nlocations = []\norgs = []\n\nfor word, pos, chunk, entity in entities:\n    if entity.endswith('PER'):\n        persons.append(word)\n    elif entity.endswith('LOC'):\n        locations.append(word)\n    elif entity.endswith('ORG'):\n        orgs.append(word)\n\nprint(f\"Persons: {persons}\")\nprint(f\"Locations: {locations}\")\nprint(f\"Organizations: {orgs}\")\n</code></pre>"},{"location":"api/ner/#combining-multi-word-entities","title":"Combining Multi-word Entities","text":"<pre><code>text = \"T\u1ed5ng th\u1ed1ng M\u1ef9 Donald Trump th\u0103m Vi\u1ec7t Nam\"\nentities = ner(text)\n\n# Combine B-/I- tags into full entities\ncurrent_entity = []\ncurrent_type = None\nfull_entities = []\n\nfor word, pos, chunk, entity in entities:\n    if entity.startswith('B-'):\n        if current_entity:\n            full_entities.append((' '.join(current_entity), current_type))\n        current_entity = [word]\n        current_type = entity[2:]\n    elif entity.startswith('I-'):\n        current_entity.append(word)\n    else:\n        if current_entity:\n            full_entities.append((' '.join(current_entity), current_type))\n            current_entity = []\n            current_type = None\n\nif current_entity:\n    full_entities.append((' '.join(current_entity), current_type))\n\nprint(full_entities)\n# [('Donald Trump', 'PER'), ('Vi\u1ec7t Nam', 'LOC')]\n</code></pre>"},{"location":"api/ner/#notes","title":"Notes","text":"<ul> <li>The CRF model is fast and lightweight</li> <li>The deep learning model provides better accuracy but requires more resources</li> <li>First call with <code>deep=True</code> may take longer due to model loading</li> </ul>"},{"location":"api/pos_tag/","title":"pos_tag","text":"<p>Label words with their part-of-speech tags.</p>"},{"location":"api/pos_tag/#usage","title":"Usage","text":"<pre><code>from underthesea import pos_tag\n\ntext = \"Ch\u1ee3 th\u1ecbt ch\u00f3 n\u1ed5i ti\u1ebfng \u1edf S\u00e0i G\u00f2n b\u1ecb truy qu\u00e9t\"\ntagged = pos_tag(text)\nprint(tagged)\n# [('Ch\u1ee3', 'N'), ('th\u1ecbt', 'N'), ('ch\u00f3', 'N'), ('n\u1ed5i ti\u1ebfng', 'A'),\n#  ('\u1edf', 'E'), ('S\u00e0i G\u00f2n', 'Np'), ('b\u1ecb', 'V'), ('truy qu\u00e9t', 'V')]\n</code></pre>"},{"location":"api/pos_tag/#function-signature","title":"Function Signature","text":"<pre><code>def pos_tag(\n    sentence: str,\n    format: str = None,\n    model: str = None\n) -&gt; list[tuple[str, str]]\n</code></pre>"},{"location":"api/pos_tag/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>sentence</code> <code>str</code> The input text to tag <code>format</code> <code>str</code> <code>None</code> Output format (currently only <code>None</code> supported) <code>model</code> <code>str</code> <code>None</code> Path to custom model"},{"location":"api/pos_tag/#returns","title":"Returns","text":"Type Description <code>list[tuple[str, str]]</code> List of (word, POS tag) tuples"},{"location":"api/pos_tag/#pos-tags","title":"POS Tags","text":"Tag Description Example <code>N</code> Noun ch\u1ee3, th\u1ecbt, ch\u00f3 <code>Np</code> Proper noun S\u00e0i G\u00f2n, Vi\u1ec7t Nam <code>V</code> Verb b\u1ecb, truy qu\u00e9t <code>A</code> Adjective n\u1ed5i ti\u1ebfng, \u0111\u1eb9p <code>P</code> Pronoun t\u00f4i, b\u1ea1n, n\u00f3 <code>R</code> Adverb r\u1ea5t, \u0111ang, s\u1ebd <code>E</code> Preposition \u1edf, trong, tr\u00ean <code>C</code> Conjunction v\u00e0, ho\u1eb7c, nh\u01b0ng <code>M</code> Number m\u1ed9t, hai, ba <code>L</code> Determiner c\u00e1c, nh\u1eefng, m\u1ecdi <code>X</code> Unknown - <code>CH</code> Punctuation . , ? !"},{"location":"api/pos_tag/#examples","title":"Examples","text":""},{"location":"api/pos_tag/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import pos_tag\n\ntext = \"Ch\u1ee3 th\u1ecbt ch\u00f3 n\u1ed5i ti\u1ebfng \u1edf S\u00e0i G\u00f2n b\u1ecb truy qu\u00e9t\"\ntagged = pos_tag(text)\nfor word, tag in tagged:\n    print(f\"{word}: {tag}\")\n# Ch\u1ee3: N\n# th\u1ecbt: N\n# ch\u00f3: N\n# n\u1ed5i ti\u1ebfng: A\n# \u1edf: E\n# S\u00e0i G\u00f2n: Np\n# b\u1ecb: V\n# truy qu\u00e9t: V\n</code></pre>"},{"location":"api/pos_tag/#filtering-by-pos-tag","title":"Filtering by POS Tag","text":"<pre><code>text = \"T\u00f4i y\u00eau Vi\u1ec7t Nam v\u00ec Vi\u1ec7t Nam r\u1ea5t \u0111\u1eb9p\"\ntagged = pos_tag(text)\n\n# Get all nouns\nnouns = [word for word, tag in tagged if tag in ('N', 'Np')]\nprint(nouns)\n# ['Vi\u1ec7t Nam', 'Vi\u1ec7t Nam']\n\n# Get all verbs\nverbs = [word for word, tag in tagged if tag == 'V']\nprint(verbs)\n# ['y\u00eau']\n</code></pre>"},{"location":"api/pos_tag/#processing-multiple-sentences","title":"Processing Multiple Sentences","text":"<pre><code>sentences = [\n    \"H\u00e0 N\u1ed9i l\u00e0 th\u1ee7 \u0111\u00f4 c\u1ee7a Vi\u1ec7t Nam\",\n    \"Th\u00e0nh ph\u1ed1 H\u1ed3 Ch\u00ed Minh l\u00e0 th\u00e0nh ph\u1ed1 l\u1edbn nh\u1ea5t\"\n]\n\nfor sentence in sentences:\n    tagged = pos_tag(sentence)\n    print(tagged)\n</code></pre>"},{"location":"api/pos_tag/#notes","title":"Notes","text":"<ul> <li>Word segmentation is performed automatically before POS tagging</li> <li>The model is trained on Vietnamese treebank data</li> <li>Proper nouns (Np) include names, locations, organizations</li> </ul>"},{"location":"api/sent_tokenize/","title":"sent_tokenize","text":"<p>Segment text into sentences.</p>"},{"location":"api/sent_tokenize/#usage","title":"Usage","text":"<pre><code>from underthesea import sent_tokenize\n\ntext = 'Taylor cho bi\u1ebft l\u00fac \u0111\u1ea7u c\u00f4 c\u1ea3m th\u1ea5y ng\u1ea1i v\u1edbi c\u00f4 b\u1ea1n th\u00e2n Amanda nh\u01b0ng r\u1ed3i m\u1ecdi th\u1ee9 tr\u00f4i qua nhanh ch\u00f3ng. Amanda c\u0169ng tho\u1ea3i m\u00e1i v\u1edbi m\u1ed1i quan h\u1ec7 n\u00e0y.'\n\nsentences = sent_tokenize(text)\nprint(sentences)\n# [\n#   \"Taylor cho bi\u1ebft l\u00fac \u0111\u1ea7u c\u00f4 c\u1ea3m th\u1ea5y ng\u1ea1i v\u1edbi c\u00f4 b\u1ea1n th\u00e2n Amanda nh\u01b0ng r\u1ed3i m\u1ecdi th\u1ee9 tr\u00f4i qua nhanh ch\u00f3ng.\",\n#   \"Amanda c\u0169ng tho\u1ea3i m\u00e1i v\u1edbi m\u1ed1i quan h\u1ec7 n\u00e0y.\"\n# ]\n</code></pre>"},{"location":"api/sent_tokenize/#function-signature","title":"Function Signature","text":"<pre><code>def sent_tokenize(text: str) -&gt; list[str]\n</code></pre>"},{"location":"api/sent_tokenize/#parameters","title":"Parameters","text":"Parameter Type Description <code>text</code> <code>str</code> The input text to segment into sentences"},{"location":"api/sent_tokenize/#returns","title":"Returns","text":"Type Description <code>list[str]</code> A list of sentences"},{"location":"api/sent_tokenize/#examples","title":"Examples","text":""},{"location":"api/sent_tokenize/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import sent_tokenize\n\ntext = \"Xin ch\u00e0o. T\u00f4i l\u00e0 sinh vi\u00ean. T\u00f4i h\u1ecdc \u1edf H\u00e0 N\u1ed9i.\"\nsentences = sent_tokenize(text)\nprint(sentences)\n# ['Xin ch\u00e0o.', 'T\u00f4i l\u00e0 sinh vi\u00ean.', 'T\u00f4i h\u1ecdc \u1edf H\u00e0 N\u1ed9i.']\n</code></pre>"},{"location":"api/sent_tokenize/#multiple-sentences","title":"Multiple Sentences","text":"<pre><code>text = \"\"\"Vi\u1ec7t Nam l\u00e0 m\u1ed9t qu\u1ed1c gia. Th\u1ee7 \u0111\u00f4 l\u00e0 H\u00e0 N\u1ed9i. Th\u00e0nh ph\u1ed1 l\u1edbn nh\u1ea5t l\u00e0 TP. H\u1ed3 Ch\u00ed Minh.\"\"\"\nsentences = sent_tokenize(text)\nprint(len(sentences))  # 3\n</code></pre>"},{"location":"api/sent_tokenize/#handling-abbreviations","title":"Handling Abbreviations","text":"<p>The function handles common Vietnamese abbreviations:</p> <pre><code>text = \"TP. H\u1ed3 Ch\u00ed Minh l\u00e0 th\u00e0nh ph\u1ed1 l\u1edbn nh\u1ea5t Vi\u1ec7t Nam. D\u00e2n s\u1ed1 kho\u1ea3ng 9 tri\u1ec7u ng\u01b0\u1eddi.\"\nsentences = sent_tokenize(text)\nprint(sentences)\n# ['TP. H\u1ed3 Ch\u00ed Minh l\u00e0 th\u00e0nh ph\u1ed1 l\u1edbn nh\u1ea5t Vi\u1ec7t Nam.', 'D\u00e2n s\u1ed1 kho\u1ea3ng 9 tri\u1ec7u ng\u01b0\u1eddi.']\n</code></pre>"},{"location":"api/sent_tokenize/#notes","title":"Notes","text":"<ul> <li>The function uses rule-based sentence boundary detection</li> <li>It handles common Vietnamese punctuation patterns</li> <li>Abbreviations like \"TP.\" (th\u00e0nh ph\u1ed1) are handled correctly</li> </ul>"},{"location":"api/sentiment/","title":"sentiment","text":"<p>Analyze the sentiment of text.</p>"},{"location":"api/sentiment/#usage","title":"Usage","text":"<pre><code>from underthesea import sentiment\n\ntext = \"S\u1ea3n ph\u1ea9m h\u01a1i nh\u1ecf so v\u1edbi t\u01b0\u1edfng t\u01b0\u1ee3ng nh\u01b0ng ch\u1ea5t l\u01b0\u1ee3ng t\u1ed1t\"\nresult = sentiment(text)\nprint(result)\n# 'positive'\n</code></pre>"},{"location":"api/sentiment/#function-signature","title":"Function Signature","text":"<pre><code>def sentiment(\n    X: str,\n    domain: str = 'general'\n) -&gt; str | list[str]\n</code></pre>"},{"location":"api/sentiment/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>X</code> <code>str</code> The input text to analyze <code>domain</code> <code>str</code> <code>'general'</code> Domain for analysis (<code>'general'</code> or <code>'bank'</code>)"},{"location":"api/sentiment/#returns","title":"Returns","text":""},{"location":"api/sentiment/#general-domain","title":"General Domain","text":"Type Description <code>str</code> Sentiment label: <code>'positive'</code>, <code>'negative'</code>, or <code>'neutral'</code>"},{"location":"api/sentiment/#bank-domain","title":"Bank Domain","text":"Type Description <code>list[str]</code> List of aspect-sentiment pairs (e.g., <code>['ASPECT#sentiment']</code>)"},{"location":"api/sentiment/#examples","title":"Examples","text":""},{"location":"api/sentiment/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import sentiment\n\n# Positive sentiment\nsentiment(\"S\u1ea3n ph\u1ea9m ch\u1ea5t l\u01b0\u1ee3ng t\u1ed1t, \u0111\u00f3ng g\u00f3i c\u1ea9n th\u1eadn\")\n# 'positive'\n\n# Negative sentiment\nsentiment(\"h\u00e0ng k\u00e9m ch\u1ea5t lg, ch\u0103n \u0111\u1eafp l\u00ean d\u00ednh l\u00f4ng l\u00e1 kh\u1eafp ng\u01b0\u1eddi. th\u1ea5t v\u1ecdng\")\n# 'negative'\n</code></pre>"},{"location":"api/sentiment/#bank-domain_1","title":"Bank Domain","text":"<p>The bank domain provides aspect-based sentiment analysis:</p> <pre><code>from underthesea import sentiment\n\n# Customer support aspect\nsentiment(\"\u0110ky qua \u0111\u01b0\u1eddng link \u1edf b\u00e0i vi\u1ebft n\u00e0y t\u1eeb th\u1ee9 6 m\u00e0 gi\u1edd ch\u01b0a th\u1ea5y ai lhe h\u1ebft\", domain='bank')\n# ['CUSTOMER_SUPPORT#negative']\n\n# Trademark aspect\nsentiment(\"Xem l\u1ea1i v\u1eabn th\u1ea5y x\u00fac \u0111\u1ed9ng v\u00e0 t\u1ef1 h\u00e0o v\u1ec1 BIDV c\u1ee7a m\u00ecnh\", domain='bank')\n# ['TRADEMARK#positive']\n</code></pre>"},{"location":"api/sentiment/#bank-domain-aspects","title":"Bank Domain Aspects","text":"Aspect Description <code>INTEREST_RATE</code> Interest rate related <code>CUSTOMER_SUPPORT</code> Customer service quality <code>PRODUCT</code> Product/service quality <code>TRADEMARK</code> Brand perception"},{"location":"api/sentiment/#processing-reviews","title":"Processing Reviews","text":"<pre><code>from underthesea import sentiment\n\nreviews = [\n    \"D\u1ecbch v\u1ee5 tuy\u1ec7t v\u1eddi, nh\u00e2n vi\u00ean nhi\u1ec7t t\u00ecnh\",\n    \"Giao h\u00e0ng ch\u1eadm, \u0111\u00f3ng g\u00f3i kh\u00f4ng c\u1ea9n th\u1eadn\",\n    \"S\u1ea3n ph\u1ea9m b\u00ecnh th\u01b0\u1eddng, kh\u00f4ng c\u00f3 g\u00ec \u0111\u1eb7c bi\u1ec7t\"\n]\n\nfor review in reviews:\n    result = sentiment(review)\n    print(f\"{review[:30]}... -&gt; {result}\")\n# D\u1ecbch v\u1ee5 tuy\u1ec7t v\u1eddi, nh\u00e2n vi\u00ean n... -&gt; positive\n# Giao h\u00e0ng ch\u1eadm, \u0111\u00f3ng g\u00f3i kh\u00f4ng... -&gt; negative\n# S\u1ea3n ph\u1ea9m b\u00ecnh th\u01b0\u1eddng, kh\u00f4ng c\u00f3... -&gt; neutral\n</code></pre>"},{"location":"api/sentiment/#counting-sentiment-distribution","title":"Counting Sentiment Distribution","text":"<pre><code>from collections import Counter\nfrom underthesea import sentiment\n\nreviews = [\n    \"S\u1ea3n ph\u1ea9m t\u1ed1t\",\n    \"Kh\u00f4ng h\u00e0i l\u00f2ng\",\n    \"R\u1ea5t th\u00edch\",\n    \"T\u1ec7 qu\u00e1\",\n    \"B\u00ecnh th\u01b0\u1eddng\"\n]\n\nsentiments = [sentiment(r) for r in reviews]\ndistribution = Counter(sentiments)\nprint(distribution)\n# Counter({'positive': 2, 'negative': 2, 'neutral': 1})\n</code></pre>"},{"location":"api/sentiment/#accessing-available-labels","title":"Accessing Available Labels","text":"<p>You can access all available sentiment labels using the <code>labels</code> property:</p> <pre><code>from underthesea import sentiment\n\n# Get labels for general domain\nsentiment.labels\n# ['positive', 'negative']\n\n# Get labels for bank domain\nsentiment.bank.labels\n# ['ACCOUNT#negative', 'CARD#negative', 'CARD#neutral', 'CARD#positive',\n#  'CUSTOMER_SUPPORT#negative', 'CUSTOMER_SUPPORT#neutral', 'CUSTOMER_SUPPORT#positive',\n#  'DISCOUNT#negative', 'DISCOUNT#neutral', 'DISCOUNT#positive', ...]\n</code></pre>"},{"location":"api/sentiment/#notes","title":"Notes","text":"<ul> <li>The general domain model classifies into positive/negative</li> <li>The bank domain model provides aspect-based sentiment</li> <li>First call may take longer due to model loading</li> <li>Use <code>sentiment.labels</code> to get all available labels for the general domain</li> <li>Use <code>sentiment.bank.labels</code> to get all available labels for the bank domain</li> </ul>"},{"location":"api/text_normalize/","title":"text_normalize","text":"<p>Normalize Vietnamese text by fixing common encoding and diacritic issues.</p>"},{"location":"api/text_normalize/#usage","title":"Usage","text":"<pre><code>from underthesea import text_normalize\n\ntext = \"\u00d0\u1ea3m ba\u1ecf ch\u1ea5t l\u1ef1\u01a1ng ph\u00f2ng th\u00ed ngh\u1ecb\u00eam ho\u00e1 h\u1ecdc\"\nnormalized = text_normalize(text)\nprint(normalized)\n# \"\u0110\u1ea3m b\u1ea3o ch\u1ea5t l\u01b0\u1ee3ng ph\u00f2ng th\u00ed nghi\u1ec7m h\u00f3a h\u1ecdc\"\n</code></pre>"},{"location":"api/text_normalize/#function-signature","title":"Function Signature","text":"<pre><code>def text_normalize(text: str, tokenizer: str = 'underthesea') -&gt; str\n</code></pre>"},{"location":"api/text_normalize/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>text</code> <code>str</code> The input text to normalize <code>tokenizer</code> <code>str</code> <code>'underthesea'</code> The tokenizer to use"},{"location":"api/text_normalize/#returns","title":"Returns","text":"Type Description <code>str</code> The normalized text"},{"location":"api/text_normalize/#examples","title":"Examples","text":""},{"location":"api/text_normalize/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import text_normalize\n\n# Fix diacritic issues\ntext_normalize(\"\u00d0\u1ea3m ba\u1ecf ch\u1ea5t l\u1ef1\u01a1ng\")\n# \"\u0110\u1ea3m b\u1ea3o ch\u1ea5t l\u01b0\u1ee3ng\"\n</code></pre>"},{"location":"api/text_normalize/#common-fixes","title":"Common Fixes","text":"<pre><code># Fix \u0110/\u00d0 confusion\ntext_normalize(\"\u00d0\u1ea1i h\u1ecdc\")\n# \"\u0110\u1ea1i h\u1ecdc\"\n\n# Fix vowel diacritics\ntext_normalize(\"ho\u00e1 h\u1ecdc\")\n# \"h\u00f3a h\u1ecdc\"\n\n# Fix tone marks\ntext_normalize(\"ngh\u1ecb\u00eam\")\n# \"nghi\u1ec7m\"\n</code></pre>"},{"location":"api/text_normalize/#full-text-normalization","title":"Full Text Normalization","text":"<pre><code>text = \"\u00d0\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 v\u1ec1 vi\u1ec7c chu\u1ea9n ho\u00e1 v\u0103n b\u1ea3n ti\u1ebfng Vi\u1ec7t\"\nnormalized = text_normalize(text)\nprint(normalized)\n# \"\u0110\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5 v\u1ec1 vi\u1ec7c chu\u1ea9n h\u00f3a v\u0103n b\u1ea3n ti\u1ebfng Vi\u1ec7t\"\n</code></pre>"},{"location":"api/text_normalize/#common-issues-fixed","title":"Common Issues Fixed","text":"Issue Example Fixed \u0110/\u00d0 confusion <code>\u00d0\u1ea1i</code> <code>\u0110\u1ea1i</code> Old-style diacritics <code>ho\u00e1</code> <code>h\u00f3a</code> Incorrect vowel composition <code>l\u1ef1\u01a1ng</code> <code>l\u01b0\u1ee3ng</code> Unicode normalization Various NFC form"},{"location":"api/text_normalize/#notes","title":"Notes","text":"<ul> <li>This function is useful for preprocessing Vietnamese text</li> <li>It handles common encoding issues from legacy systems</li> <li>The output is in Unicode NFC normalized form</li> </ul>"},{"location":"api/translate/","title":"translate","text":"<p>Translate text between Vietnamese and English.</p> <p>Requires Deep Learning</p> <p>This function requires the deep learning dependencies: <pre><code>pip install \"underthesea[deep]\"\n</code></pre></p>"},{"location":"api/translate/#usage","title":"Usage","text":"<pre><code>from underthesea import translate\n\n# Vietnamese to English (default)\ntext = \"H\u00e0 N\u1ed9i l\u00e0 th\u1ee7 \u0111\u00f4 c\u1ee7a Vi\u1ec7t Nam\"\nenglish = translate(text)\nprint(english)\n# 'Hanoi is the capital of Vietnam'\n</code></pre>"},{"location":"api/translate/#function-signature","title":"Function Signature","text":"<pre><code>def translate(\n    text: str,\n    source_lang: str = 'vi',\n    target_lang: str = 'en'\n) -&gt; str\n</code></pre>"},{"location":"api/translate/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>text</code> <code>str</code> The input text to translate <code>source_lang</code> <code>str</code> <code>'vi'</code> Source language code <code>target_lang</code> <code>str</code> <code>'en'</code> Target language code"},{"location":"api/translate/#returns","title":"Returns","text":"Type Description <code>str</code> The translated text"},{"location":"api/translate/#supported-languages","title":"Supported Languages","text":"Code Language <code>vi</code> Vietnamese <code>en</code> English"},{"location":"api/translate/#examples","title":"Examples","text":""},{"location":"api/translate/#vietnamese-to-english","title":"Vietnamese to English","text":"<pre><code>from underthesea import translate\n\n# Basic translation\ntranslate(\"H\u00e0 N\u1ed9i l\u00e0 th\u1ee7 \u0111\u00f4 c\u1ee7a Vi\u1ec7t Nam\")\n# 'Hanoi is the capital of Vietnam'\n\ntranslate(\"\u1ea8m th\u1ef1c Vi\u1ec7t Nam n\u1ed5i ti\u1ebfng tr\u00ean th\u1ebf gi\u1edbi\")\n# 'Vietnamese cuisine is famous around the world'\n\ntranslate(\"Xin ch\u00e0o, t\u00f4i l\u00e0 sinh vi\u00ean\")\n# 'Hello, I am a student'\n</code></pre>"},{"location":"api/translate/#english-to-vietnamese","title":"English to Vietnamese","text":"<pre><code>from underthesea import translate\n\ntranslate(\"I love Vietnamese food\", source_lang='en', target_lang='vi')\n# 'T\u00f4i y\u00eau \u1ea9m th\u1ef1c Vi\u1ec7t Nam'\n\ntranslate(\"Vietnam is a beautiful country\", source_lang='en', target_lang='vi')\n# 'Vi\u1ec7t Nam l\u00e0 m\u1ed9t \u0111\u1ea5t n\u01b0\u1edbc xinh \u0111\u1eb9p'\n</code></pre>"},{"location":"api/translate/#translating-multiple-sentences","title":"Translating Multiple Sentences","text":"<pre><code>from underthesea import translate\n\nsentences = [\n    \"H\u00e0 N\u1ed9i l\u00e0 th\u1ee7 \u0111\u00f4 c\u1ee7a Vi\u1ec7t Nam\",\n    \"Vi\u1ec7t Nam c\u00f3 nhi\u1ec1u \u0111\u1ecba \u0111i\u1ec3m du l\u1ecbch \u0111\u1eb9p\",\n    \"\u1ea8m th\u1ef1c Vi\u1ec7t Nam r\u1ea5t phong ph\u00fa\"\n]\n\nfor sentence in sentences:\n    english = translate(sentence)\n    print(f\"{sentence}\")\n    print(f\"-&gt; {english}\\n\")\n</code></pre>"},{"location":"api/translate/#handling-long-text","title":"Handling Long Text","text":"<p>For long documents, consider splitting into sentences first:</p> <pre><code>from underthesea import sent_tokenize, translate\n\ntext = \"\"\"Vi\u1ec7t Nam l\u00e0 m\u1ed9t qu\u1ed1c gia. Th\u1ee7 \u0111\u00f4 l\u00e0 H\u00e0 N\u1ed9i.\nTh\u00e0nh ph\u1ed1 l\u1edbn nh\u1ea5t l\u00e0 TP. H\u1ed3 Ch\u00ed Minh.\"\"\"\n\nsentences = sent_tokenize(text)\ntranslations = [translate(s) for s in sentences]\n\nfor vi, en in zip(sentences, translations):\n    print(f\"VI: {vi}\")\n    print(f\"EN: {en}\\n\")\n</code></pre>"},{"location":"api/translate/#notes","title":"Notes","text":"<ul> <li>Uses a transformer-based neural machine translation model</li> <li>First call may take longer due to model loading</li> <li>Works best with well-formed sentences</li> <li>Long texts should be split into sentences for better results</li> </ul>"},{"location":"api/tts/","title":"tts","text":"<p>Convert Vietnamese text to speech.</p> <p>Requires Additional Setup</p> <p>This function requires extra dependencies and model download: <pre><code>pip install \"underthesea[voice]\"\nunderthesea download-model VIET_TTS_V0_4_1\n</code></pre></p>"},{"location":"api/tts/#usage","title":"Usage","text":"<pre><code>from underthesea.pipeline.tts import tts\n\ntext = \"Xin ch\u00e0o Vi\u1ec7t Nam\"\ntts(text)\n# Generates sound.wav in current directory\n</code></pre>"},{"location":"api/tts/#function-signature","title":"Function Signature","text":"<pre><code>def tts(text: str, outfile: str = \"sound.wav\", play: bool = False) -&gt; tuple[int, np.ndarray]\n</code></pre>"},{"location":"api/tts/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>text</code> <code>str</code> The Vietnamese text to convert to speech <code>outfile</code> <code>str</code> <code>\"sound.wav\"</code> Output audio file path <code>play</code> <code>bool</code> <code>False</code> Whether to play audio after generation"},{"location":"api/tts/#returns","title":"Returns","text":"Type Description <code>tuple[int, np.ndarray]</code> Sample rate (16000) and audio waveform array"},{"location":"api/tts/#examples","title":"Examples","text":""},{"location":"api/tts/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea.pipeline.tts import tts\n\n# Generate speech\ntts(\"Xin ch\u00e0o Vi\u1ec7t Nam\")\n# Creates sound.wav\n\n# Custom output file\ntts(\"H\u00e0 N\u1ed9i l\u00e0 th\u1ee7 \u0111\u00f4 c\u1ee7a Vi\u1ec7t Nam\", outfile=\"hanoi.wav\")\n\n# Generate and play immediately\ntts(\"Xin ch\u00e0o\", play=True)\n</code></pre>"},{"location":"api/tts/#command-line-usage","title":"Command Line Usage","text":"<pre><code>underthesea tts \"Xin ch\u00e0o Vi\u1ec7t Nam\"\n# Creates sound.wav and plays it\n</code></pre>"},{"location":"api/tts/#generating-multiple-audio-files","title":"Generating Multiple Audio Files","text":"<pre><code>from underthesea.pipeline.tts import tts\n\nsentences = [\n    (\"Xin ch\u00e0o\", \"hello.wav\"),\n    (\"T\u1ea1m bi\u1ec7t\", \"goodbye.wav\"),\n    (\"C\u1ea3m \u01a1n\", \"thanks.wav\")\n]\n\nfor text, filename in sentences:\n    tts(text, outfile=filename)\n    print(f\"Generated: {filename}\")\n</code></pre>"},{"location":"api/tts/#playing-audio-with-external-library","title":"Playing Audio (with external library)","text":"<pre><code>from underthesea.pipeline.tts import tts\nimport subprocess\n\n# Generate audio\ntts(\"Xin ch\u00e0o Vi\u1ec7t Nam\")\n\n# Play audio (macOS)\nsubprocess.run([\"afplay\", \"sound.wav\"])\n\n# Play audio (Linux with aplay)\n# subprocess.run([\"aplay\", \"sound.wav\"])\n</code></pre>"},{"location":"api/tts/#notes","title":"Notes","text":"<ul> <li>Uses the VietTTS model for high-quality Vietnamese speech synthesis</li> <li>Output format is WAV audio at 16kHz sample rate</li> <li>First call may take longer due to model loading</li> <li>Requires downloading the TTS model before first use</li> <li>Credits: Based on NTT123/vietTTS</li> </ul>"},{"location":"api/tts/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api/tts/#model-not-found","title":"Model Not Found","text":"<p>If you get a model not found error:</p> <pre><code>underthesea download-model VIET_TTS_V0_4_1\n</code></pre>"},{"location":"api/tts/#audio-quality-issues","title":"Audio Quality Issues","text":"<ul> <li>Ensure input text is in Vietnamese</li> <li>Longer sentences produce smoother audio</li> <li>Punctuation affects prosody</li> </ul>"},{"location":"api/word_tokenize/","title":"word_tokenize","text":"<p>Segment Vietnamese text into words.</p>"},{"location":"api/word_tokenize/#usage","title":"Usage","text":"<pre><code>from underthesea import word_tokenize\n\ntext = \"Ch\u00e0ng trai 9X Qu\u1ea3ng Tr\u1ecb kh\u1edfi nghi\u1ec7p t\u1eeb n\u1ea5m s\u00f2\"\nwords = word_tokenize(text)\nprint(words)\n# [\"Ch\u00e0ng trai\", \"9X\", \"Qu\u1ea3ng Tr\u1ecb\", \"kh\u1edfi nghi\u1ec7p\", \"t\u1eeb\", \"n\u1ea5m\", \"s\u00f2\"]\n</code></pre>"},{"location":"api/word_tokenize/#function-signature","title":"Function Signature","text":"<pre><code>def word_tokenize(\n    sentence: str,\n    format: str = None,\n    use_token_normalize: bool = True,\n    fixed_words: list = None\n) -&gt; list[str] | str\n</code></pre>"},{"location":"api/word_tokenize/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>sentence</code> <code>str</code> The input text to tokenize <code>format</code> <code>str</code> <code>None</code> Output format: <code>None</code> for list, <code>\"text\"</code> for string <code>use_token_normalize</code> <code>bool</code> <code>True</code> Whether to normalize tokens <code>fixed_words</code> <code>list</code> <code>None</code> List of words that should not be split"},{"location":"api/word_tokenize/#returns","title":"Returns","text":"Type Description <code>list[str]</code> List of words (when <code>format=None</code>) <code>str</code> Space-separated string with underscores (when <code>format=\"text\"</code>)"},{"location":"api/word_tokenize/#examples","title":"Examples","text":""},{"location":"api/word_tokenize/#basic-usage","title":"Basic Usage","text":"<pre><code>from underthesea import word_tokenize\n\ntext = \"Ch\u00e0ng trai 9X Qu\u1ea3ng Tr\u1ecb kh\u1edfi nghi\u1ec7p t\u1eeb n\u1ea5m s\u00f2\"\nwords = word_tokenize(text)\nprint(words)\n# [\"Ch\u00e0ng trai\", \"9X\", \"Qu\u1ea3ng Tr\u1ecb\", \"kh\u1edfi nghi\u1ec7p\", \"t\u1eeb\", \"n\u1ea5m\", \"s\u00f2\"]\n</code></pre>"},{"location":"api/word_tokenize/#text-format","title":"Text Format","text":"<pre><code>text = \"Ch\u00e0ng trai 9X Qu\u1ea3ng Tr\u1ecb kh\u1edfi nghi\u1ec7p t\u1eeb n\u1ea5m s\u00f2\"\nresult = word_tokenize(text, format=\"text\")\nprint(result)\n# \"Ch\u00e0ng_trai 9X Qu\u1ea3ng_Tr\u1ecb kh\u1edfi_nghi\u1ec7p t\u1eeb n\u1ea5m s\u00f2\"\n</code></pre>"},{"location":"api/word_tokenize/#fixed-words","title":"Fixed Words","text":"<p>Use <code>fixed_words</code> to ensure certain words are kept together:</p> <pre><code>text = \"Vi\u1ec7n Nghi\u00ean C\u1ee9u chi\u1ebfn l\u01b0\u1ee3c qu\u1ed1c gia v\u1ec1 h\u1ecdc m\u00e1y\"\nfixed_words = [\"Vi\u1ec7n Nghi\u00ean C\u1ee9u\", \"h\u1ecdc m\u00e1y\"]\nresult = word_tokenize(text, fixed_words=fixed_words, format=\"text\")\nprint(result)\n# \"Vi\u1ec7n_Nghi\u00ean_C\u1ee9u chi\u1ebfn_l\u01b0\u1ee3c qu\u1ed1c_gia v\u1ec1 h\u1ecdc_m\u00e1y\"\n</code></pre>"},{"location":"api/word_tokenize/#processing-multiple-sentences","title":"Processing Multiple Sentences","text":"<pre><code>sentences = [\n    \"T\u00f4i y\u00eau Vi\u1ec7t Nam\",\n    \"H\u00e0 N\u1ed9i l\u00e0 th\u1ee7 \u0111\u00f4 c\u1ee7a Vi\u1ec7t Nam\"\n]\n\nfor sentence in sentences:\n    words = word_tokenize(sentence)\n    print(words)\n# ['T\u00f4i', 'y\u00eau', 'Vi\u1ec7t Nam']\n# ['H\u00e0 N\u1ed9i', 'l\u00e0', 'th\u1ee7 \u0111\u00f4', 'c\u1ee7a', 'Vi\u1ec7t Nam']\n</code></pre>"},{"location":"api/word_tokenize/#notes","title":"Notes","text":"<ul> <li>Vietnamese word segmentation is challenging because spaces don't always indicate word boundaries</li> <li>The function uses a CRF model trained on Vietnamese text</li> <li>Multi-syllable words are joined (e.g., \"Vi\u1ec7t Nam\" is one word, not two)</li> <li>Use <code>fixed_words</code> parameter for domain-specific terminology</li> </ul>"},{"location":"contribute/SPONSORS/","title":"Sponsors","text":"<p>\ud83d\udc4b If you are a fan of the project or a company that relies on Underthesea, you might want to consider sponsoring \ud83d\udcb0. This will help us devote more time to answering questions \ud83e\udd14 and doing feature development \ud83d\ude80. </p> <p>We thank those who support \ud83d\udc9d Underthesea! </p>"},{"location":"contribute/SPONSORS/#corporate","title":"Corporate \ud83c\udfe2","text":"<p>\ud83c\udf0a Underthesea has been dedicatedly working on Open Source Vietnamese Natural Lanugage Processing for the past six years. Our team of developers and researchers have been exploring various AI techniques to create tools that can simplify and automate complex tasks, thereby empowering businesses to thrive in the AI age.</p> <p>\ud83d\udcaa As we continue to build and refine our projects, we need support from corporate sponsors to help us achieve our goals. Sponsorship is an essential part of our growth strategy, and it will allow us to accelerate our research and development efforts, expand our team, and bring our technology to market.</p> <p>Join us in Advancing Vietnamese AI Technology:   \ud83e\udd1d Become a Corporate Sponsor Today </p>"},{"location":"contribute/SPONSORS/#individuals","title":"Individuals \ud83e\uddb8\u200d\u2642\ufe0f\ud83e\uddb8\u200d\u2640\ufe0f","text":"<ul> <li>Nguyen Xuan Duc </li> <li>Nguyen Huu Thanh</li> <li>Nguyen Thanh Duc</li> <li>Pham Hong Quang</li> <li>Thang Pham Ngoc</li> <li>Hoai-Thu Vuong</li> </ul>"},{"location":"contribute/SUPPORT_US/","title":"\ud83d\udc9d Support Us","text":"<p>\ud83c\udf0a Underthesea has been dedicatedly working on Open Source Vietnamese Natural Lanugage Processing for the past six years. Our team of developers and researchers have been exploring various AI techniques to create tools that can simplify and automate complex tasks, thereby empowering businesses to thrive in the AI age.</p> <p>If you found this project helpful and would like to support our work, you can just buy us a coffee \u2615.</p> <p>Your support is our biggest encouragement \ud83c\udf81!</p> <p></p>"},{"location":"developer/architecture/","title":"Architecture","text":"<p>This document describes the internal architecture of Underthesea.</p>"},{"location":"developer/architecture/#overview","title":"Overview","text":"<p>Underthesea is organized as a collection of NLP pipelines, each handling a specific task.</p> <pre><code>underthesea/\n\u251c\u2500\u2500 pipeline/              # Main NLP modules\n\u2502   \u251c\u2500\u2500 sent_tokenize/     # Sentence segmentation\n\u2502   \u251c\u2500\u2500 text_normalize/    # Text normalization\n\u2502   \u251c\u2500\u2500 word_tokenize/     # Word segmentation\n\u2502   \u251c\u2500\u2500 pos_tag/           # POS tagging\n\u2502   \u251c\u2500\u2500 chunking/          # Phrase chunking\n\u2502   \u251c\u2500\u2500 dependency_parse/  # Dependency parsing\n\u2502   \u251c\u2500\u2500 ner/               # Named entity recognition\n\u2502   \u251c\u2500\u2500 classification/    # Text classification\n\u2502   \u251c\u2500\u2500 sentiment/         # Sentiment analysis\n\u2502   \u251c\u2500\u2500 translate/         # Translation\n\u2502   \u251c\u2500\u2500 lang_detect/       # Language detection\n\u2502   \u2514\u2500\u2500 tts/               # Text-to-speech\n\u251c\u2500\u2500 models/                # Model implementations\n\u251c\u2500\u2500 datasets/              # Built-in datasets\n\u251c\u2500\u2500 corpus/                # Corpus handling\n\u251c\u2500\u2500 resources/             # Static resources\n\u2514\u2500\u2500 cli.py                 # CLI interface\n</code></pre>"},{"location":"developer/architecture/#pipeline-module-structure","title":"Pipeline Module Structure","text":"<p>Each pipeline module follows a consistent pattern:</p> <pre><code>pipeline/word_tokenize/\n\u251c\u2500\u2500 __init__.py            # Main API function\n\u251c\u2500\u2500 model.py               # Model implementation\n\u251c\u2500\u2500 feature.py             # Feature extraction\n\u2514\u2500\u2500 default_model/         # Default model files\n</code></pre>"},{"location":"developer/architecture/#main-api-__init__py","title":"Main API (<code>__init__.py</code>)","text":"<pre><code># Lazy loading pattern\n_model = None\n\ndef word_tokenize(sentence, format=None):\n    global _model\n    if _model is None:\n        _model = load_model()\n    return _model.predict(sentence, format)\n</code></pre>"},{"location":"developer/architecture/#model-implementation","title":"Model Implementation","text":"<pre><code>class CRFModel:\n    def __init__(self, model_path):\n        self.model = load_crf(model_path)\n\n    def predict(self, text):\n        features = extract_features(text)\n        return self.model.tag(features)\n</code></pre>"},{"location":"developer/architecture/#lazy-loading","title":"Lazy Loading","text":"<p>Models are loaded on first use to minimize startup time:</p> <pre><code># At import time - no model loaded\nfrom underthesea import word_tokenize\n\n# First call - model loaded and cached\nresult = word_tokenize(\"text\")\n\n# Subsequent calls - uses cached model\nresult = word_tokenize(\"more text\")\n</code></pre> <p>Benefits: - Fast import time - Memory efficiency (only used models loaded) - Simple API</p>"},{"location":"developer/architecture/#model-types","title":"Model Types","text":""},{"location":"developer/architecture/#crf-models","title":"CRF Models","text":"<p>Used for: word segmentation, POS tagging, chunking, NER, classification, sentiment</p> <pre><code># Uses python-crfsuite\nimport pycrfsuite\n\nclass CRFTagger:\n    def __init__(self, model_path):\n        self.tagger = pycrfsuite.Tagger()\n        self.tagger.open(model_path)\n\n    def tag(self, features):\n        return self.tagger.tag(features)\n</code></pre>"},{"location":"developer/architecture/#deep-learning-models","title":"Deep Learning Models","text":"<p>Used for: dependency parsing, deep NER, translation</p> <pre><code># Uses transformers\nfrom transformers import AutoModel, AutoTokenizer\n\nclass TransformerModel:\n    def __init__(self, model_name):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name)\n</code></pre>"},{"location":"developer/architecture/#fasttext-models","title":"FastText Models","text":"<p>Used for: language detection</p> <pre><code>import fasttext\n\nclass LangDetector:\n    def __init__(self, model_path):\n        self.model = fasttext.load_model(model_path)\n\n    def detect(self, text):\n        prediction = self.model.predict(text)\n        return prediction[0][0].replace('__label__', '')\n</code></pre>"},{"location":"developer/architecture/#feature-extraction","title":"Feature Extraction","text":"<p>Features are extracted for CRF models:</p> <pre><code>def extract_features(sentence):\n    features = []\n    for i, word in enumerate(sentence):\n        word_features = {\n            'word': word,\n            'is_upper': word.isupper(),\n            'is_title': word.istitle(),\n            'prev_word': sentence[i-1] if i &gt; 0 else 'BOS',\n            'next_word': sentence[i+1] if i &lt; len(sentence)-1 else 'EOS',\n        }\n        features.append(word_features)\n    return features\n</code></pre>"},{"location":"developer/architecture/#resource-management","title":"Resource Management","text":""},{"location":"developer/architecture/#model-storage","title":"Model Storage","text":"<p>Models are stored in <code>~/.underthesea/models/</code>:</p> <pre><code>~/.underthesea/\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 WS_VLSP2013_CRF/\n\u2502   \u251c\u2500\u2500 POS_VLSP2013_CRF/\n\u2502   \u2514\u2500\u2500 NER_VLSP2016_BERT/\n\u2514\u2500\u2500 datasets/\n    \u251c\u2500\u2500 VNTC/\n    \u2514\u2500\u2500 UTS2017-BANK/\n</code></pre>"},{"location":"developer/architecture/#model-download","title":"Model Download","text":"<pre><code>def download_model(model_name):\n    url = get_model_url(model_name)\n    local_path = get_local_path(model_name)\n\n    if not os.path.exists(local_path):\n        download_file(url, local_path)\n        extract_archive(local_path)\n\n    return local_path\n</code></pre>"},{"location":"developer/architecture/#rust-extension","title":"Rust Extension","text":"<p>Performance-critical code uses the Rust extension:</p> <pre><code>extensions/underthesea_core/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 lib.rs             # Rust implementation\n\u251c\u2500\u2500 Cargo.toml             # Rust dependencies\n\u2514\u2500\u2500 pyproject.toml         # Python binding config\n</code></pre> <p>Built with maturin:</p> <pre><code>cd extensions/underthesea_core\nmaturin develop\n</code></pre>"},{"location":"developer/architecture/#cli-architecture","title":"CLI Architecture","text":"<p>The CLI uses Click:</p> <pre><code># cli.py\nimport click\n\n@click.group()\ndef cli():\n    pass\n\n@cli.command()\ndef list_data():\n    \"\"\"List available datasets.\"\"\"\n    for dataset in get_datasets():\n        print(dataset)\n\n@cli.command()\n@click.argument('text')\ndef tts(text):\n    \"\"\"Convert text to speech.\"\"\"\n    from underthesea.pipeline.tts import tts\n    tts(text)\n</code></pre>"},{"location":"developer/architecture/#optional-dependencies","title":"Optional Dependencies","text":"<p>Optional features are guarded:</p> <pre><code>def translate(text):\n    try:\n        from transformers import AutoModel\n    except ImportError:\n        raise ImportError(\n            \"Translation requires deep learning dependencies. \"\n            \"Install with: pip install 'underthesea[deep]'\"\n        )\n    # ... translation logic\n</code></pre>"},{"location":"developer/architecture/#testing-architecture","title":"Testing Architecture","text":"<pre><code>tests/\n\u251c\u2500\u2500 pipeline/\n\u2502   \u251c\u2500\u2500 word_tokenize/\n\u2502   \u2502   \u2514\u2500\u2500 test_word_tokenize.py\n\u2502   \u251c\u2500\u2500 pos_tag/\n\u2502   \u2502   \u2514\u2500\u2500 test_pos_tag.py\n\u2502   \u2514\u2500\u2500 ner/\n\u2502       \u2514\u2500\u2500 test_ner.py\n\u2514\u2500\u2500 conftest.py            # Pytest fixtures\n</code></pre>"},{"location":"developer/architecture/#extending-underthesea","title":"Extending Underthesea","text":""},{"location":"developer/architecture/#adding-a-new-pipeline","title":"Adding a New Pipeline","text":"<ol> <li>Create directory: <code>underthesea/pipeline/new_task/</code></li> <li>Implement <code>__init__.py</code> with main API</li> <li>Add model implementation</li> <li>Export from <code>underthesea/__init__.py</code></li> <li>Add tests in <code>tests/pipeline/new_task/</code></li> <li>Add documentation</li> </ol>"},{"location":"developer/architecture/#adding-a-new-model","title":"Adding a New Model","text":"<ol> <li>Train the model using appropriate toolkit</li> <li>Save model files</li> <li>Update model registry</li> <li>Add download logic</li> <li>Test with existing pipeline</li> </ol>"},{"location":"developer/contributing/","title":"Contributing Guide","text":"<p>Thank you for your interest in contributing to Underthesea! This guide will help you get started.</p>"},{"location":"developer/contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"developer/contributing/#bug-reports","title":"Bug Reports","text":"<ul> <li>Check existing GitHub Issues first</li> <li>Include Python version, OS, and Underthesea version</li> <li>Provide minimal code to reproduce the issue</li> <li>Include full error traceback</li> </ul>"},{"location":"developer/contributing/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>Reference the issue number in your PR</li> <li>Include tests that demonstrate the fix</li> <li>Update documentation if needed</li> </ul>"},{"location":"developer/contributing/#new-features","title":"New Features","text":"<ul> <li>Open an issue to discuss the feature first</li> <li>Follow the existing code style</li> <li>Add tests and documentation</li> </ul>"},{"location":"developer/contributing/#documentation","title":"Documentation","text":"<ul> <li>Fix typos and improve clarity</li> <li>Add examples and tutorials</li> <li>Translate documentation</li> </ul>"},{"location":"developer/contributing/#development-setup","title":"Development Setup","text":""},{"location":"developer/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9 or higher</li> <li>Git</li> <li>uv (recommended) or pip</li> </ul>"},{"location":"developer/contributing/#clone-and-install","title":"Clone and Install","text":"<pre><code># Clone the repository\ngit clone https://github.com/undertheseanlp/underthesea.git\ncd underthesea\n\n# Create virtual environment with uv\nuv venv\nsource .venv/bin/activate\n\n# Install in development mode\nuv pip install -e \".[dev]\"\n</code></pre>"},{"location":"developer/contributing/#macos-arm64-apple-silicon","title":"macOS ARM64 (Apple Silicon)","text":"<p>Build the Rust extension:</p> <pre><code>cd extensions/underthesea_core\nuv pip install maturin\nmaturin develop\ncd ../..\n</code></pre>"},{"location":"developer/contributing/#code-style","title":"Code Style","text":""},{"location":"developer/contributing/#linting","title":"Linting","text":"<p>We use Ruff for linting:</p> <pre><code># Check for issues\nruff check underthesea/\n\n# Auto-fix issues\nruff check underthesea/ --fix\n</code></pre>"},{"location":"developer/contributing/#configuration","title":"Configuration","text":"<p>Ruff configuration is in <code>pyproject.toml</code>.</p>"},{"location":"developer/contributing/#testing","title":"Testing","text":""},{"location":"developer/contributing/#test-categories","title":"Test Categories","text":"Command Description <code>tox -e lint</code> Linting with Ruff <code>tox -e core</code> Core module tests <code>tox -e deep</code> Deep learning tests <code>tox -e prompt</code> Prompt model tests <code>tox -e langdetect</code> Language detection tests"},{"location":"developer/contributing/#running-specific-tests","title":"Running Specific Tests","text":"<pre><code># Word tokenization tests\nuv run python -m unittest discover tests.pipeline.word_tokenize\n\n# POS tagging tests\nuv run python -m unittest discover tests.pipeline.pos_tag\n\n# NER tests\nuv run python -m unittest tests.pipeline.ner.test_ner\n\n# Classification tests\nuv run python -m unittest tests.pipeline.classification.test_bank\n\n# Translation tests\nuv run python -m unittest discover tests.pipeline.translate\n</code></pre>"},{"location":"developer/contributing/#writing-tests","title":"Writing Tests","text":"<ul> <li>Place tests in the <code>tests/</code> directory</li> <li>Mirror the source structure</li> <li>Use Python's <code>unittest</code> framework</li> <li>Include both positive and edge case tests</li> </ul> <pre><code>import unittest\nfrom underthesea import word_tokenize\n\nclass TestWordTokenize(unittest.TestCase):\n    def test_basic(self):\n        result = word_tokenize(\"Xin ch\u00e0o Vi\u1ec7t Nam\")\n        self.assertEqual(result, ['Xin', 'ch\u00e0o', 'Vi\u1ec7t Nam'])\n\n    def test_empty_string(self):\n        result = word_tokenize(\"\")\n        self.assertEqual(result, [])\n\nif __name__ == '__main__':\n    unittest.main()\n</code></pre>"},{"location":"developer/contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"developer/contributing/#before-submitting","title":"Before Submitting","text":"<ol> <li>Update your branch: Rebase on latest <code>main</code></li> <li>Run linting: <code>ruff check underthesea/</code></li> <li>Run tests: <code>tox -e core</code></li> <li>Update docs: If adding features</li> </ol>"},{"location":"developer/contributing/#pr-guidelines","title":"PR Guidelines","text":"<ul> <li>Use clear, descriptive titles</li> <li>Reference related issues</li> <li>Describe changes and motivation</li> <li>Include test results</li> <li>Add screenshots for UI changes</li> </ul>"},{"location":"developer/contributing/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes\n\n## Related Issues\nFixes #123\n\n## Changes\n- Added X feature\n- Fixed Y bug\n- Updated Z documentation\n\n## Testing\n- [ ] Linting passes\n- [ ] Unit tests pass\n- [ ] Manual testing done\n\n## Documentation\n- [ ] Updated relevant docs\n- [ ] Added docstrings\n</code></pre>"},{"location":"developer/contributing/#project-structure","title":"Project Structure","text":"<pre><code>underthesea/\n\u251c\u2500\u2500 underthesea/           # Main package\n\u2502   \u251c\u2500\u2500 pipeline/          # NLP modules\n\u2502   \u251c\u2500\u2500 models/            # Model implementations\n\u2502   \u251c\u2500\u2500 datasets/          # Built-in datasets\n\u2502   \u251c\u2500\u2500 corpus/            # Corpus handling\n\u2502   \u2514\u2500\u2500 cli.py             # CLI commands\n\u251c\u2500\u2500 tests/                 # Test files\n\u251c\u2500\u2500 docs/                  # Documentation\n\u251c\u2500\u2500 extensions/            # Rust extension, apps\n\u2514\u2500\u2500 pyproject.toml         # Project configuration\n</code></pre>"},{"location":"developer/contributing/#cli-commands","title":"CLI Commands","text":"<pre><code># List available data\nunderthesea list-data\n\n# List available models\nunderthesea list-model\n\n# Download data\nunderthesea download-data VNTC\n</code></pre>"},{"location":"developer/contributing/#getting-help","title":"Getting Help","text":"<ul> <li>GitHub Issues</li> <li>Facebook Community</li> </ul>"},{"location":"developer/contributing/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Focus on constructive feedback</li> <li>Help newcomers feel welcome</li> </ul>"},{"location":"developer/releasing/","title":"Releasing","text":"<p>This document describes the release process for Underthesea.</p>"},{"location":"developer/releasing/#version-scheme","title":"Version Scheme","text":"<p>Underthesea follows Semantic Versioning:</p> <ul> <li>MAJOR.MINOR.PATCH (e.g., 9.0.0)</li> <li>MAJOR: Breaking changes</li> <li>MINOR: New features, backward compatible</li> <li>PATCH: Bug fixes, backward compatible</li> </ul>"},{"location":"developer/releasing/#release-checklist","title":"Release Checklist","text":""},{"location":"developer/releasing/#pre-release","title":"Pre-release","text":"<ul> <li>[ ] All tests passing</li> <li>[ ] Documentation updated</li> <li>[ ] CHANGELOG updated</li> <li>[ ] Version bumped in <code>pyproject.toml</code></li> <li>[ ] Version bumped in <code>__init__.py</code></li> </ul>"},{"location":"developer/releasing/#release-steps","title":"Release Steps","text":"<ol> <li>Update version</li> </ol> <pre><code># underthesea/__init__.py\n__version__ = \"9.1.0\"\n</code></pre> <pre><code># pyproject.toml\n[project]\nversion = \"9.1.0\"\n</code></pre> <ol> <li>Update CHANGELOG</li> </ol> <p>Add entry to <code>docs/history.md</code>:</p> <pre><code>## 9.1.0 (2024-XX-XX)\n\n### New Features\n- Added X feature\n\n### Bug Fixes\n- Fixed Y issue\n\n### Documentation\n- Updated Z docs\n</code></pre> <ol> <li>Run tests</li> </ol> <pre><code>tox -e lint\ntox -e core\n</code></pre> <ol> <li>Create release commit</li> </ol> <pre><code>git add -A\ngit commit -m \"Release version 9.1.0\"\ngit tag v9.1.0\n</code></pre> <ol> <li>Push to GitHub</li> </ol> <pre><code>git push origin main\ngit push origin v9.1.0\n</code></pre> <ol> <li>Publish to PyPI</li> </ol> <p>GitHub Actions will automatically publish when a tag is pushed.</p> <p>Or manually:</p> <pre><code>uv pip install build twine\npython -m build\ntwine upload dist/*\n</code></pre> <ol> <li> <p>Create GitHub Release</p> </li> <li> <p>Go to Releases</p> </li> <li>Click \"Draft a new release\"</li> <li>Select the tag</li> <li>Add release notes</li> <li>Publish</li> </ol>"},{"location":"developer/releasing/#versioning-guidelines","title":"Versioning Guidelines","text":""},{"location":"developer/releasing/#when-to-bump-major","title":"When to bump MAJOR","text":"<ul> <li>Removing a public function</li> <li>Changing function signatures</li> <li>Dropping Python version support</li> <li>Breaking changes to output format</li> </ul>"},{"location":"developer/releasing/#when-to-bump-minor","title":"When to bump MINOR","text":"<ul> <li>Adding new functions</li> <li>Adding new parameters (with defaults)</li> <li>New model support</li> <li>New optional features</li> </ul>"},{"location":"developer/releasing/#when-to-bump-patch","title":"When to bump PATCH","text":"<ul> <li>Bug fixes</li> <li>Performance improvements</li> <li>Documentation updates</li> <li>Dependency updates</li> </ul>"},{"location":"developer/releasing/#hotfix-process","title":"Hotfix Process","text":"<p>For urgent bug fixes:</p> <ol> <li> <p>Create branch from latest release tag:    <pre><code>git checkout -b hotfix/9.0.1 v9.0.0\n</code></pre></p> </li> <li> <p>Fix the bug and add tests</p> </li> <li> <p>Bump PATCH version</p> </li> <li> <p>Merge to main and tag:    <pre><code>git checkout main\ngit merge hotfix/9.0.1\ngit tag v9.0.1\ngit push origin main v9.0.1\n</code></pre></p> </li> </ol>"},{"location":"developer/releasing/#release-automation","title":"Release Automation","text":"<p>GitHub Actions workflow (<code>.github/workflows/publish.yml</code>):</p> <pre><code>name: Publish to PyPI\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  publish:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n      - run: pip install build twine\n      - run: python -m build\n      - run: twine upload dist/*\n        env:\n          TWINE_USERNAME: __token__\n          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}\n</code></pre>"},{"location":"developer/releasing/#post-release","title":"Post-release","text":"<ul> <li>[ ] Verify package on PyPI</li> <li>[ ] Test installation: <code>pip install underthesea==9.1.0</code></li> <li>[ ] Update ReadTheDocs if needed</li> <li>[ ] Announce on social media</li> <li>[ ] Close related GitHub issues</li> </ul>"},{"location":"technical_reports/voice/","title":"Voice Module: Technical Report","text":"<p>This document provides a technical overview of the AI models used in the underthesea voice (text-to-speech) module.</p>"},{"location":"technical_reports/voice/#overview","title":"Overview","text":"<p>The voice module implements a neural text-to-speech (TTS) system for Vietnamese. It is based on VietTTS by NTT123 and uses a two-stage architecture:</p> <ol> <li>Text-to-Mel: Converts text/phonemes to mel-spectrogram</li> <li>Mel-to-Wave (Vocoder): Converts mel-spectrogram to audio waveform</li> </ol> <pre><code>Text \u2192 [Text Normalization] \u2192 [Duration Model] \u2192 [Acoustic Model] \u2192 Mel \u2192 [HiFi-GAN] \u2192 Audio\n</code></pre>"},{"location":"technical_reports/voice/#installation","title":"Installation","text":"<pre><code>pip install \"underthesea[voice]\"\nunderthesea download-model VIET_TTS_V0_4_1\n</code></pre>"},{"location":"technical_reports/voice/#model-architecture","title":"Model Architecture","text":""},{"location":"technical_reports/voice/#1-duration-model","title":"1. Duration Model","text":"<p>The Duration Model predicts the duration (in seconds) for each phoneme in the input sequence.</p> <p>Architecture:</p> Component Description Token Encoder Embedding + 3\u00d7 Conv1D + Bidirectional LSTM Projection Linear \u2192 GELU \u2192 Linear \u2192 Softplus <p>Parameters:</p> Parameter Value Vocabulary Size 256 LSTM Dimension 256 Dropout Rate 0.5 <p>Input: Phoneme sequence with lengths Output: Duration for each phoneme (in seconds)</p>"},{"location":"technical_reports/voice/#2-acoustic-model","title":"2. Acoustic Model","text":"<p>The Acoustic Model generates mel-spectrograms from phonemes and their predicted durations.</p> <p>Architecture:</p> Component Description Token Encoder Embedding + 3\u00d7 Conv1D + Bidirectional LSTM Upsampling Gaussian attention-based upsampling PreNet 2\u00d7 Linear (256 dim) with dropout Decoder 2\u00d7 LSTM with skip connections PostNet 5\u00d7 Conv1D with batch normalization Projection Linear to mel dimension <p>Parameters:</p> Parameter Value Encoder Dimension 256 Decoder Dimension 512 PostNet Dimension 512 Mel Dimension 80 <p>Key Features:</p> <ul> <li>Gaussian Upsampling: Uses soft attention to upsample encoder outputs to match target frame length</li> <li>Autoregressive Decoder: Generates mel frames sequentially with teacher forcing during training</li> <li>Zoneout Regularization: Applies zoneout to LSTM states during training for better generalization</li> <li>PostNet Refinement: Residual convolutional network refines the predicted mel-spectrogram</li> </ul>"},{"location":"technical_reports/voice/#3-hifi-gan-vocoder","title":"3. HiFi-GAN Vocoder","text":"<p>The vocoder converts mel-spectrograms to raw audio waveforms using the HiFi-GAN architecture.</p> <p>Architecture:</p> Component Description Conv Pre Conv1D (7 kernel) Upsampling Multiple Conv1DTranspose layers Multi-Receptive Field Fusion (MRF) ResBlocks with varying kernel sizes and dilations Conv Post Conv1D (7 kernel) + Tanh <p>Key Features:</p> <ul> <li>Multi-Scale Upsampling: Progressive upsampling from mel frame rate to audio sample rate</li> <li>Multi-Receptive Field Fusion: Combines outputs from residual blocks with different receptive fields</li> <li>Leaky ReLU Activation: Uses leaky ReLU with slope 0.1 throughout</li> </ul> <p>ResBlock Types:</p> <ul> <li>ResBlock1: 3 dilated convolutions (dilation: 1, 3, 5) with residual connections</li> <li>ResBlock2: 2 dilated convolutions (dilation: 1, 3) with residual connections</li> </ul>"},{"location":"technical_reports/voice/#audio-configuration","title":"Audio Configuration","text":"Parameter Value Sample Rate 16,000 Hz FFT Size 1,024 Mel Channels 80 Frequency Range 0 - 8,000 Hz"},{"location":"technical_reports/voice/#text-processing-pipeline","title":"Text Processing Pipeline","text":""},{"location":"technical_reports/voice/#1-text-normalization","title":"1. Text Normalization","text":"<p>The input text is normalized before synthesis:</p> <pre><code># Normalization steps:\n1. Unicode NFKC normalization\n2. Lowercase conversion\n3. Punctuation \u2192 silence markers\n4. Multiple spaces \u2192 single space\n</code></pre>"},{"location":"technical_reports/voice/#2-phoneme-conversion","title":"2. Phoneme Conversion","text":"<p>Text is converted to phonemes using a lexicon lookup:</p> <ul> <li>Vietnamese characters are mapped to phoneme sequences</li> <li>Special tokens: <code>sil</code> (silence), <code>sp</code> (short pause), <code></code> (word boundary)</li> <li>Unknown words are processed character-by-character</li> </ul>"},{"location":"technical_reports/voice/#model-files","title":"Model Files","text":"<p>The <code>VIET_TTS_V0_4_1</code> model package includes:</p> File Description <code>lexicon.txt</code> Word-to-phoneme mapping <code>duration_latest_ckpt.pickle</code> Duration model weights <code>acoustic_latest_ckpt.pickle</code> Acoustic model weights <code>hk_hifi.pickle</code> HiFi-GAN vocoder weights <code>config.json</code> HiFi-GAN configuration"},{"location":"technical_reports/voice/#framework-dependencies","title":"Framework Dependencies","text":"<p>The voice module uses JAX ecosystem:</p> Library Purpose JAX Numerical computation and automatic differentiation JAXlib JAX backend (CPU/GPU/TPU support) dm-haiku Neural network library for JAX Optax Gradient processing and optimization"},{"location":"technical_reports/voice/#usage-example","title":"Usage Example","text":"<pre><code>from underthesea.pipeline.tts import tts\n\n# Basic usage\ntts(\"Xin ch\u00e0o Vi\u1ec7t Nam\")  # Creates sound.wav\n\n# Custom output file\ntts(\"H\u00e0 N\u1ed9i l\u00e0 th\u1ee7 \u0111\u00f4\", outfile=\"output.wav\")\n\n# With playback\ntts(\"\u0110\u00e2y l\u00e0 m\u1ed9t v\u00ed d\u1ee5\", play=True)\n</code></pre>"},{"location":"technical_reports/voice/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>First Call Latency: Model loading on first call may take several seconds</li> <li>JAX Compilation: JIT compilation occurs on first inference, subsequent calls are faster</li> <li>Text Length: Maximum recommended text length is 500 characters</li> <li>Memory Usage: GPU memory usage depends on input text length</li> </ul>"},{"location":"technical_reports/voice/#limitations","title":"Limitations","text":"<ul> <li>Single Speaker: Current model supports only one voice</li> <li>Vietnamese Only: Designed specifically for Vietnamese language</li> <li>Prosody: Limited control over prosody and emotion</li> <li>Real-time: Not optimized for real-time streaming</li> </ul>"},{"location":"technical_reports/voice/#references","title":"References","text":"<ul> <li>VietTTS - Original implementation by NTT123</li> <li>HiFi-GAN - Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</li> <li>Non-Attentive Tacotron - Robust and Controllable Neural TTS Synthesis</li> <li>dm-haiku - JAX neural network library by DeepMind</li> </ul>"}]}