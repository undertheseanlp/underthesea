"use strict";(globalThis.webpackChunkunderthesea_docs=globalThis.webpackChunkunderthesea_docs||[]).push([[5749],{7735(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"rust-text-classifier","metadata":{"permalink":"/blog/rust-text-classifier","editUrl":"https://github.com/undertheseanlp/underthesea/tree/main/docusaurus/blog/2026-02-03-rust-text-classifier.md","source":"@site/blog/2026-02-03-rust-text-classifier.md","title":"Rust-Powered Text Classification - 273x Faster Inference","description":"In underthesea v9.2.9, we\'ve completely rewritten the text classification pipeline using our Rust-based TextClassifier. This delivers up to 273x faster inference compared to the previous sklearn-based implementation.","date":"2026-02-03T00:00:00.000Z","tags":[{"inline":true,"label":"rust","permalink":"/blog/tags/rust"},{"inline":true,"label":"performance","permalink":"/blog/tags/performance"},{"inline":true,"label":"classification","permalink":"/blog/tags/classification"},{"inline":true,"label":"nlp","permalink":"/blog/tags/nlp"}],"readingTime":2.5,"hasTruncateMarker":true,"authors":[{"name":"Vu Anh","title":"Creator of Underthesea","url":"https://github.com/rain1024","imageURL":"https://github.com/rain1024.png","key":"rain1024","page":null}],"frontMatter":{"slug":"rust-text-classifier","title":"Rust-Powered Text Classification - 273x Faster Inference","authors":["rain1024"],"tags":["rust","performance","classification","nlp"]},"unlisted":false,"nextItem":{"title":"Rewriting CRF Model in Rust","permalink":"/blog/rewrite-rust-crf-model"}},"content":"In underthesea v9.2.9, we\'ve completely rewritten the text classification pipeline using our Rust-based `TextClassifier`. This delivers up to **273x faster inference** compared to the previous sklearn-based implementation.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Background\\n\\nText classification in underthesea supports two domains:\\n- **General**: News categorization (10 categories)\\n- **Bank**: Banking intent classification (14 categories)\\n\\nPreviously, we used scikit-learn\'s `TfidfVectorizer` + `LinearSVC` loaded via joblib. While accurate, this approach had significant overhead.\\n\\n## The Architecture Change\\n\\n### Before (sklearn-based)\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                        Python                               \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502  \u2502    Input     \u2502\u2500\u2500\u2500\u25b6\u2502TfidfVectorizer\u2500\u2500\u2500\u25b6\u2502  LinearSVC   \u2502  \u2502\\n\u2502  \u2502    Text      \u2502    \u2502  (sklearn)   \u2502    \u2502  (sklearn)   \u2502  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2502                              \u2502                   \u2502          \u2502\\n\u2502                      joblib.load()        joblib.load()     \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nLoading two separate pickle files, with Python-based vectorization and inference.\\n\\n### After (Rust-based)\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                        Python                               \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502  \u2502    Input     \u2502\u2500\u2500\u2500\u25b6\u2502         TextClassifier           \u2502  \u2502\\n\u2502  \u2502    Text      \u2502    \u2502  TF-IDF + LinearSVC (Rust)       \u2502  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2502                              \u2502                              \u2502\\n\u2502                      single .bin file                       \u2502\\n\u2502                      underthesea-core                       \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nSingle binary model file, vectorization and inference fused in Rust.\\n\\n## Code Changes\\n\\nThe API remains unchanged:\\n\\n```python\\nfrom underthesea import classify\\n\\n# General classification\\nclassify(\\"Vi\u1ec7t Nam v\xf4 \u0111\u1ecbch AFF Cup\\")\\n# \\"The thao\\"\\n\\n# Bank domain\\nclassify(\\"L\xe3i su\u1ea5t ti\u1ebft ki\u1ec7m bao nhi\xeau?\\", domain=\\"bank\\")\\n# [\'INTEREST_RATE\']\\n```\\n\\nInternally, the implementation is much simpler:\\n\\n**Before:**\\n```python\\nimport joblib\\nfrom underthesea.pipeline.classification import bank\\n\\nvectorizer = joblib.load(\\"vectorizer.pkl\\")\\nclassifier = joblib.load(\\"classifier.pkl\\")\\nfeatures = vectorizer.transform([text])\\nprediction = classifier.predict(features)\\n```\\n\\n**After:**\\n```python\\nfrom underthesea_core import TextClassifier\\n\\nclassifier = TextClassifier.load(\\"model.bin\\")\\nprediction = classifier.predict(text)\\n```\\n\\n## Benchmark Results\\n\\nTested on the same hardware with batch inference:\\n\\n| Domain | sklearn | Rust | Speedup |\\n|--------|---------|------|---------|\\n| General | 1,228 samples/sec | 66,678 samples/sec | **54x** |\\n| Bank | 244 samples/sec | 66,678 samples/sec | **273x** |\\n\\nSingle sample latency: **4ms \u2192 0.465ms**\\n\\n## Why Is It Faster?\\n\\n### 1. Fused Pipeline\\n\\nTF-IDF vectorization and SVM inference run in a single Rust function call, eliminating Python overhead between stages.\\n\\n### 2. Optimized Sparse Operations\\n\\n```rust\\npub fn predict(&self, text: &str) -> String {\\n    // Tokenize and hash features in one pass\\n    let features = self.vectorizer.transform(text);\\n\\n    // Sparse dot product with pre-sorted indices\\n    let scores = self.svm.decision_function(&features);\\n\\n    self.classes[scores.argmax()].clone()\\n}\\n```\\n\\n### 3. Single File Model\\n\\nOne `.bin` file instead of multiple pickle files:\\n- Faster loading\\n- Atomic deployment\\n- Smaller size (JSON-based, not pickle)\\n\\n### 4. No Python GIL Contention\\n\\nRust code releases the GIL during computation, enabling true parallelism.\\n\\n## Model Accuracy\\n\\nThe new models maintain high accuracy:\\n\\n| Dataset | Categories | Accuracy |\\n|---------|------------|----------|\\n| VNTC | 10 news topics | 92.49% |\\n| Bank | 14 banking intents | 75.76% |\\n\\n## Label Format Change\\n\\nLabels now use Title case with spaces:\\n\\n| Old | New |\\n|-----|-----|\\n| `the_thao` | `The thao` |\\n| `kinh_doanh` | `Kinh doanh` |\\n| `vi_tinh` | `Vi tinh` |\\n\\nBank domain labels remain uppercase: `INTEREST_RATE`, `MONEY_TRANSFER`, etc.\\n\\n## Simplified Codebase\\n\\nWe consolidated three separate modules into one:\\n\\n**Before:**\\n```\\nclassification/\\n\u251c\u2500\u2500 bank/\\n\u2502   \u2514\u2500\u2500 __init__.py\\n\u251c\u2500\u2500 sonar_core_1/\\n\u2502   \u2514\u2500\u2500 __init__.py\\n\u251c\u2500\u2500 vntc/\\n\u2502   \u2514\u2500\u2500 __init__.py\\n\u2514\u2500\u2500 __init__.py\\n```\\n\\n**After:**\\n```\\nclassification/\\n\u251c\u2500\u2500 __init__.py      # Everything here\\n\u2514\u2500\u2500 classification_prompt.py\\n```\\n\\n~190 lines removed, single source of truth for model URLs and loading logic.\\n\\n## Try It Out\\n\\n```bash\\npip install underthesea==9.2.9\\n```\\n\\n```python\\nfrom underthesea import classify\\n\\n# 273x faster!\\nclassify(\\"Th\u1ecb tr\u01b0\u1eddng ch\u1ee9ng kho\xe1n t\u0103ng \u0111i\u1ec3m m\u1ea1nh\\")\\n# \\"Kinh doanh\\"\\n\\nclassify.labels\\n# [\'Chinh tri Xa hoi\', \'Doi song\', \'Khoa hoc\', \'Kinh doanh\', ...]\\n\\nclassify(\\"M\u1edf th\u1ebb t\xedn d\u1ee5ng\\", domain=\\"bank\\")\\n# [\'CARD\']\\n\\nclassify.bank.labels\\n# [\'ACCOUNT\', \'CARD\', \'CUSTOMER_SUPPORT\', ...]\\n```\\n\\n## Links\\n\\n- [PR #935](https://github.com/undertheseanlp/underthesea/pull/935) - Classification pipeline refactor\\n- [Sen-1](https://github.com/undertheseanlp/sen-1) - Training code and technical report\\n- [underthesea-core](https://pypi.org/project/underthesea-core/) - Rust extension on PyPI"},{"id":"rewrite-rust-crf-model","metadata":{"permalink":"/blog/rewrite-rust-crf-model","editUrl":"https://github.com/undertheseanlp/underthesea/tree/main/docusaurus/blog/2026-02-02-rewrite-rust-crf-model.md","source":"@site/blog/2026-02-02-rewrite-rust-crf-model.md","title":"Rewriting CRF Model in Rust","description":"In underthesea v9.2.5, we completed the migration from python-crfsuite to our native Rust implementation underthesea-core. This change resulted in a 20% performance improvement across all CRF-based NLP tasks.","date":"2026-02-02T00:00:00.000Z","tags":[{"inline":true,"label":"rust","permalink":"/blog/tags/rust"},{"inline":true,"label":"performance","permalink":"/blog/tags/performance"},{"inline":true,"label":"crf","permalink":"/blog/tags/crf"},{"inline":true,"label":"nlp","permalink":"/blog/tags/nlp"}],"readingTime":2.67,"hasTruncateMarker":true,"authors":[{"name":"Vu Anh","title":"Creator of Underthesea","url":"https://github.com/rain1024","imageURL":"https://github.com/rain1024.png","key":"rain1024","page":null}],"frontMatter":{"slug":"rewrite-rust-crf-model","title":"Rewriting CRF Model in Rust","authors":["rain1024"],"tags":["rust","performance","crf","nlp"]},"unlisted":false,"prevItem":{"title":"Rust-Powered Text Classification - 273x Faster Inference","permalink":"/blog/rust-text-classifier"}},"content":"In underthesea v9.2.5, we completed the migration from `python-crfsuite` to our native Rust implementation `underthesea-core`. This change resulted in a **20% performance improvement** across all CRF-based NLP tasks.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Background\\n\\nUnderthesea uses Conditional Random Fields (CRF) for several core NLP tasks:\\n- Word tokenization\\n- POS tagging\\n- Named Entity Recognition (NER)\\n- Chunking\\n\\nPreviously, we relied on `python-crfsuite`, a Python wrapper for the CRFsuite C++ library. While functional, this introduced overhead from multiple language boundaries.\\n\\n## The Architecture Change\\n\\n### Before (v9.2.1)\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                        Python                                \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502  \u2502    Input     \u2502\u2500\u2500\u2500\u25b6\u2502 CRFFeaturizer\u2502\u2500\u2500\u2500\u25b6\u2502   Python     \u2502  \u2502\\n\u2502  \u2502   Tokens     \u2502    \u2502    (Rust)    \u2502    \u2502    List      \u2502  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2502                                                  \u2502          \u2502\\n\u2502                                                  \u25bc          \u2502\\n\u2502                                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502                                          \u2502  pycrfsuite  \u2502  \u2502\\n\u2502                                          \u2502    (C++)     \u2502  \u2502\\n\u2502                                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nThe data flow crossed multiple language boundaries:\\n1. Python \u2192 Rust (CRFFeaturizer)\\n2. Rust \u2192 Python (feature list)\\n3. Python \u2192 C++ (pycrfsuite)\\n4. C++ \u2192 Python (tags)\\n\\n### After (v9.2.5)\\n\\n```\\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\\n\u2502                        Python                                \u2502\\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\\n\u2502  \u2502    Input     \u2502\u2500\u2500\u2500\u25b6\u2502 CRFFeaturizer\u2502\u2500\u2500\u2500\u25b6\u2502  CRFTagger   \u2502  \u2502\\n\u2502  \u2502   Tokens     \u2502    \u2502    (Rust)    \u2502    \u2502    (Rust)    \u2502  \u2502\\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\\n\u2502                              \u2502                   \u2502          \u2502\\n\u2502                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\\n\u2502                               underthesea-core              \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n```\\n\\nNow both preprocessing and inference are in Rust within the same module, eliminating the C++ dependency entirely.\\n\\n## Code Changes\\n\\nThe change was minimal from the API perspective:\\n\\n**Before:**\\n```python\\nimport pycrfsuite\\nfrom underthesea_core import CRFFeaturizer\\n\\nclass FastCRFSequenceTagger:\\n    def load(self, base_path):\\n        estimator = pycrfsuite.Tagger()\\n        estimator.open(model_path)\\n        # ...\\n```\\n\\n**After:**\\n```python\\nfrom underthesea_core import CRFFeaturizer, CRFTagger\\n\\nclass FastCRFSequenceTagger:\\n    def load(self, base_path):\\n        estimator = CRFTagger()\\n        estimator.load(model_path)\\n        # ...\\n```\\n\\n## Benchmark Results\\n\\nWe benchmarked both versions on the same hardware with 100 iterations:\\n\\n| Function | v9.2.1 (pycrfsuite) | v9.2.5 (Rust) | Improvement |\\n|----------|---------------------|---------------|-------------|\\n| word_tokenize | 1.45ms | 1.18ms | **-19%** |\\n| pos_tag | 3.58ms | 2.93ms | **-18%** |\\n| ner | 9.61ms | 8.49ms | **-12%** |\\n| chunk | 6.19ms | 5.65ms | **-9%** |\\n\\n## Why Is It Faster?\\n\\n### 1. Unified Runtime\\n\\nBoth `CRFFeaturizer` and `CRFTagger` are now in the same Rust module. This allows:\\n- Shared memory management\\n- No intermediate Python object creation\\n- Potential for future optimizations (e.g., fusing operations)\\n\\n### 2. Optimized Viterbi Implementation\\n\\nOur Rust implementation uses pre-allocated vectors and cache-friendly memory layouts:\\n\\n```rust\\nfn viterbi(&self, attr_ids: &[Vec<u32>]) -> TaggingResult {\\n    let n = attr_ids.len();\\n    let num_labels = self.model.num_labels;\\n\\n    // Pre-allocated score matrix\\n    let mut score = vec![vec![f64::NEG_INFINITY; num_labels]; n];\\n    let mut back = vec![vec![0u32; num_labels]; n];\\n\\n    // Cache emission scores per position\\n    let emission_t = self.model.emission_scores(&attr_ids[t]);\\n\\n    // Direct memory access in inner loop\\n    for y in 0..num_labels {\\n        for y_prev in 0..num_labels {\\n            let trans = self.model.get_transition(y_prev as u32, y as u32);\\n            // ...\\n        }\\n    }\\n}\\n```\\n\\n### 3. Zero-Copy Where Possible\\n\\nPyO3 bindings allow efficient data transfer between Python and Rust without unnecessary copying.\\n\\n### 4. Removed Dependency\\n\\nRemoving `python-crfsuite` also means:\\n- Simpler installation (no C++ compiler needed)\\n- Smaller package size\\n- Fewer potential compatibility issues\\n\\n## Migration Path\\n\\nThe migration was done incrementally across 4 releases:\\n\\n| Version | Changes |\\n|---------|---------|\\n| v9.2.2 | word_tokenize migrated |\\n| v9.2.3 | pos_tag, ner, chunking migrated |\\n| v9.2.4 | CRFTrainer migrated, removed unused files |\\n| v9.2.5 | Removed python-crfsuite dependency |\\n\\n## Model Compatibility\\n\\nThe Rust implementation can load existing `.crfsuite` model files trained by python-crfsuite. No retraining is required.\\n\\n```python\\n# Works with both old and new models\\nfrom underthesea import word_tokenize\\nword_tokenize(\\"H\xe0 N\u1ed9i l\xe0 th\u1ee7 \u0111\xf4 c\u1ee7a Vi\u1ec7t Nam\\")\\n# [\'H\xe0 N\u1ed9i\', \'l\xe0\', \'th\u1ee7 \u0111\xf4\', \'c\u1ee7a\', \'Vi\u1ec7t Nam\']\\n```\\n\\n## Conclusion\\n\\nBy rewriting our CRF inference in Rust and unifying the preprocessing pipeline, we achieved:\\n\\n- **20% faster inference** across all CRF-based tasks\\n- **Simpler dependency tree** (no python-crfsuite)\\n- **Better maintainability** with a single codebase\\n\\nThe full implementation is available in [underthesea-core](https://github.com/undertheseanlp/underthesea/tree/main/extensions/underthesea_core).\\n\\n## Try It Out\\n\\n```bash\\npip install underthesea==9.2.5\\n```\\n\\n```python\\nfrom underthesea import word_tokenize, pos_tag, ner, chunk\\n\\nword_tokenize(\\"Vi\u1ec7t Nam\\")  # 20% faster!\\n```"}]}}')}}]);