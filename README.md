<p align="center">
  <br>
  <img src="https://raw.githubusercontent.com/undertheseanlp/underthesea/master/logo.png"/>
  <br/>
</p>

<p align="center">
  <a href="https://pypi.python.org/pypi/underthesea">
    <img src="https://img.shields.io/pypi/v/underthesea.svg">
  </a>
  <a href="https://pypi.python.org/pypi/underthesea">
    <img src="https://img.shields.io/badge/python-3.6%20%7C%203.7%20%7C%203.8%20%7C%203.9%20%7C%203.10-blue">
  </a>
  <a href="http://undertheseanlp.com/">
    <img src="https://img.shields.io/badge/demo-live-brightgreen">
  </a>
  <a href="https://underthesea.readthedocs.io/en/latest/">
    <img src="https://img.shields.io/badge/docs-live-brightgreen">
  </a>
  <a href="https://colab.research.google.com/drive/1gD8dSMSE_uNacW4qJ-NSnvRT85xo9ZY2">
    <img src="https://img.shields.io/badge/latest-ff9f01?logo=google-colab&logoColor=white">
  </a>
  <a href="https://colab.research.google.com/drive/1U6EWY7ewNUtCXGsa5uZtDEz4I5exO_fo">
    <img src="https://img.shields.io/badge/stable-ff9f01?logo=google-colab&logoColor=white">
  </a>
  <a href="https://www.facebook.com/undertheseanlp/">
    <img src="https://img.shields.io/badge/Facebook-1877F2?logo=facebook&logoColor=white">
  </a>
  <a href="https://www.youtube.com/channel/UC9Jv1Qg49uprg6SjkyAqs9A">
    <img src="https://img.shields.io/badge/YouTube-FF0000?logo=youtube&logoColor=white">
  </a>
</p>

<h3 align="center">
Open-source Vietnamese Natural Language Process Toolkit
</h3>

`Underthesea` is:

üåä **A Vietnamese NLP toolkit.** Underthesea is a suite of open source Python modules data sets and tutorials supporting research and development in [Vietnamese Natural Language Processing](https://github.com/undertheseanlp/underthesea). We provides extremely easy API to quickly apply pretrained NLP models to your Vietnamese text, such as word segmentation, part-of-speech tagging (PoS), named entity recognition (NER), text classification and dependency parsing.

üåä **A Pytorch library.** Underthesea is backed by one of most popular deep learning libraries, [Pytorch](https://pytorch.org/), make it easy to train your deep learning models and experiment with new approaches using Underthesea modules and classes.

üåä **An open-source software.** Underthesea is published under the [GNU General Public License v3.0](https://github.com/undertheseanlp/underthesea/blob/master/LICENSE) license. Permissions of this strong copyleft license are conditioned on making available complete source code of licensed works and modifications, which include larger works using a licensed work, under the same license.

üíù [**Support Us!**](#-support-us)

## Installation


To install underthesea, simply:

```bash
$ pip install underthesea
‚ú®üç∞‚ú®
```

Satisfaction, guaranteed.

## Tutorials

* [1. Sentence Segmentation](#1-sentence-segmentation)
* [2. Text Normalization](#2-text-normalization)
* [3. Word Segmentation](#3-word-segmentation)
* [4. POS Tagging](#4-pos-tagging)
* [5. Chunking](#5-chunking)
* [6. Dependency Parsing](#6-dependency-parsing)
* [7. Named Entity Recognition](#7-named-entity-recognition)
* [8. Text Classification](#8-text-classification)
* [9. Sentiment Analysis](#9-sentiment-analysis)
* [10. Vietnamese NLP Resources](#10-vietnamese-nlp-resources)

### 1. Sentence Segmentation

Usage

```python
>>> from underthesea import sent_tokenize
>>> text = 'Taylor cho bi·∫øt l√∫c ƒë·∫ßu c√¥ c·∫£m th·∫•y ng·∫°i v·ªõi c√¥ b·∫°n th√¢n Amanda nh∆∞ng r·ªìi m·ªçi th·ª© tr√¥i qua nhanh ch√≥ng. Amanda c≈©ng tho·∫£i m√°i v·ªõi m·ªëi quan h·ªá n√†y.'

>>> sent_tokenize(text)
[
  "Taylor cho bi·∫øt l√∫c ƒë·∫ßu c√¥ c·∫£m th·∫•y ng·∫°i v·ªõi c√¥ b·∫°n th√¢n Amanda nh∆∞ng r·ªìi m·ªçi th·ª© tr√¥i qua nhanh ch√≥ng.",
  "Amanda c≈©ng tho·∫£i m√°i v·ªõi m·ªëi quan h·ªá n√†y."
]
```

### 2. Text Normalization

Usage

```python
>>> from underthesea import text_normalize
>>> text_normalize('√ê·∫£m ba·ªè ch·∫•t l·ª±∆°ng ph√≤ng th√≠ ngh·ªã√™m ho√° h·ªçc')
'ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng ph√≤ng th√≠ nghi·ªám h√≥a h·ªçc'
```

### 3. Word Segmentation

Usage

```python
>>> from underthesea import word_tokenize
>>> sentence = 'Ch√†ng trai 9X Qu·∫£ng Tr·ªã kh·ªüi nghi·ªáp t·ª´ n·∫•m s√≤'

>>> word_tokenize(sentence)
['Ch√†ng trai', '9X', 'Qu·∫£ng Tr·ªã', 'kh·ªüi nghi·ªáp', 't·ª´', 'n·∫•m', 's√≤']

>>> word_tokenize(sentence, format="text")
'Ch√†ng_trai 9X Qu·∫£ng_Tr·ªã kh·ªüi_nghi·ªáp t·ª´ n·∫•m s√≤'
```

### 4. POS Tagging

Usage

```python
>>> from underthesea import pos_tag
>>> pos_tag('Ch·ª£ th·ªãt ch√≥ n·ªïi ti·∫øng ·ªü S√†i G√≤n b·ªã truy qu√©t')
[('Ch·ª£', 'N'),
 ('th·ªãt', 'N'),
 ('ch√≥', 'N'),
 ('n·ªïi ti·∫øng', 'A'),
 ('·ªü', 'E'),
 ('S√†i G√≤n', 'Np'),
 ('b·ªã', 'V'),
 ('truy qu√©t', 'V')]
```


### 5. Chunking

Usage

```python
>>> from underthesea import chunk
>>> text = 'B√°c sƒ© b√¢y gi·ªù c√≥ th·ªÉ th·∫£n nhi√™n b√°o tin b·ªánh nh√¢n b·ªã ung th∆∞?'
>>> chunk(text)
[('B√°c sƒ©', 'N', 'B-NP'),
 ('b√¢y gi·ªù', 'P', 'I-NP'),
 ('c√≥ th·ªÉ', 'R', 'B-VP'),
 ('th·∫£n nhi√™n', 'V', 'I-VP'),
 ('b√°o tin', 'N', 'B-NP'),
 ('b·ªánh nh√¢n', 'N', 'I-NP'),
 ('b·ªã', 'V', 'B-VP'),
 ('ung th∆∞', 'N', 'I-VP'),
 ('?', 'CH', 'O')]
```


### 6. Dependency Parsing

Install dependencies for deep learning

```bash
$ pip install underthesea[deep]
```

Usage

```python
>>> from underthesea import dependency_parse
>>> text = 'T·ªëi 29/11, Vi·ªát Nam th√™m 2 ca m·∫Øc Covid-19'
>>> dependency_parse(text)
[('T·ªëi', 5, 'obl:tmod'),
 ('29/11', 1, 'flat:date'),
 (',', 1, 'punct'),
 ('Vi·ªát Nam', 5, 'nsubj'),
 ('th√™m', 0, 'root'),
 ('2', 7, 'nummod'),
 ('ca', 5, 'obj'),
 ('m·∫Øc', 7, 'nmod'),
 ('Covid-19', 8, 'nummod')]
```

### 7. Named Entity Recognition

Usage

```python
>>> from underthesea import ner
>>> text = 'Ch∆∞a ti·∫øt l·ªô l·ªãch tr√¨nh t·ªõi Vi·ªát Nam c·ªßa T·ªïng th·ªëng M·ªπ Donald Trump'
>>> ner(text)
[('Ch∆∞a', 'R', 'O', 'O'),
 ('ti·∫øt l·ªô', 'V', 'B-VP', 'O'),
 ('l·ªãch tr√¨nh', 'V', 'B-VP', 'O'),
 ('t·ªõi', 'E', 'B-PP', 'O'),
 ('Vi·ªát Nam', 'Np', 'B-NP', 'B-LOC'),
 ('c·ªßa', 'E', 'B-PP', 'O'),
 ('T·ªïng th·ªëng', 'N', 'B-NP', 'O'),
 ('M·ªπ', 'Np', 'B-NP', 'B-LOC'),
 ('Donald', 'Np', 'B-NP', 'B-PER'),
 ('Trump', 'Np', 'B-NP', 'I-PER')]
```

With Deep Learning

```bash
$ pip install underthesea[deep]
```

```python
>>> from underthesea import ner
>>> text = "B·ªô C√¥ng Th∆∞∆°ng x√≥a m·ªôt t·ªïng c·ª•c, gi·∫£m nhi·ªÅu ƒë·∫ßu m·ªëi"
>>> ner(text, deep=True)
[
  {'entity': 'B-ORG', 'word': 'B·ªô'},
  {'entity': 'I-ORG', 'word': 'C√¥ng'},
  {'entity': 'I-ORG', 'word': 'Th∆∞∆°ng'}
]
```

### 8. Text Classification

Usage

```python
>>> from underthesea import classify

>>> classify('HLV ƒë·∫ßu ti√™n ·ªü Premier League b·ªã sa th·∫£i sau 4 v√≤ng ƒë·∫•u')
['The thao']

>>> classify('H·ªôi ƒë·ªìng t∆∞ v·∫•n kinh doanh Asean vinh danh gi·∫£i th∆∞·ªüng qu·ªëc t·∫ø')
['Kinh doanh']

>> classify('L√£i su·∫•t t·ª´ BIDV r·∫•t ∆∞u ƒë√£i', domain='bank')
['INTEREST_RATE']
```

### 9. Sentiment Analysis

Usage

```python
>>> from underthesea import sentiment

>>> sentiment('h√†ng k√©m ch·∫•t lg,chƒÉn ƒë·∫Øp l√™n d√≠nh l√¥ng l√° kh·∫Øp ng∆∞·ªùi. th·∫•t v·ªçng')
'negative'
>>> sentiment('S·∫£n ph·∫©m h∆°i nh·ªè so v·ªõi t∆∞·ªüng t∆∞·ª£ng nh∆∞ng ch·∫•t l∆∞·ª£ng t·ªët, ƒë√≥ng g√≥i c·∫©n th·∫≠n.')
'positive'

>>> sentiment('ƒêky qua ƒë∆∞·ªùng link ·ªü b√†i vi·∫øt n√†y t·ª´ th·ª© 6 m√† gi·ªù ch∆∞a th·∫•y ai lhe h·∫øt', domain='bank')
['CUSTOMER_SUPPORT#negative']
>>> sentiment('Xem l·∫°i v·∫´n th·∫•y x√∫c ƒë·ªông v√† t·ª± h√†o v·ªÅ BIDV c·ªßa m√¨nh', domain='bank')
['TRADEMARK#positive']
```

### 10. Vietnamese NLP Resources

List resources

```bash
$ underthesea list-data
| Name                | Type        | License | Year | Directory                    |
|---------------------+-------------+---------+------+------------------------------|
| UIT_ABSA_RESTAURANT | Sentiment   | Open    | 2021 | datasets/UIT_ABSA_RESTAURANT |
| UIT_ABSA_HOTEL      | Sentiment   | Open    | 2021 | datasets/UIT_ABSA_HOTEL      |
| SE_Vietnamese-UBS   | Sentiment   | Open    | 2020 | datasets/SE_Vietnamese-UBS   |
| CP_Vietnamese-UNC   | Plaintext   | Open    | 2020 | datasets/CP_Vietnamese-UNC   |
| DI_Vietnamese-UVD   | Dictionary  | Open    | 2020 | datasets/DI_Vietnamese-UVD   |
| UTS2017-BANK        | Categorized | Open    | 2017 | datasets/UTS2017-BANK        |
| VNTQ_SMALL          | Plaintext   | Open    | 2012 | datasets/LTA                 |
| VNTQ_BIG            | Plaintext   | Open    | 2012 | datasets/LTA                 |
| VNESES              | Plaintext   | Open    | 2012 | datasets/LTA                 |
| VNTC                | Categorized | Open    | 2007 | datasets/VNTC                |

$ underthesea list-data --all
```

Download resources

```bash
$ underthesea download-data VNTC
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74846806/74846806 [00:09<00:00, 8243779.16B/s]
Resource VNTC is downloaded in ~/.underthesea/datasets/VNTC folder
```

### Up Coming Features

* Machine Translation
* Text to Speech
* Automatic Speech Recognition

## Contributing

Do you want to contribute with underthesea development? Great! Please read more details at [CONTRIBUTING.rst](https://github.com/undertheseanlp/underthesea/blob/master/CONTRIBUTING.rst)

## üíù Support Us

If you found this project helpful and would like to support our work, you can just buy us a coffee ‚òï.

Your support is our biggest encouragement üéÅ!


<img src="https://raw.githubusercontent.com/undertheseanlp/underthesea/master/img/support.png"/>
