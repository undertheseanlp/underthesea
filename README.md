<p align="center">
  <br>
  <img src="https://raw.githubusercontent.com/undertheseanlp/underthesea/main/docs/static/img/logo.png"/>
  <br/>
</p>

<p align="center">
  <a href="https://pypi.python.org/pypi/underthesea">
    <img src="https://img.shields.io/pypi/v/underthesea.svg">
  </a>
  <a href="https://pypi.python.org/pypi/underthesea">
    <img src="https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12%20%7C%203.13%20%7C%203.14-blue">
  </a>
  <a href="http://undertheseanlp.com/">
    <img src="https://img.shields.io/badge/demo-live-brightgreen">
  </a>
  <a href="https://undertheseanlp.github.io/underthesea/">
    <img src="https://img.shields.io/badge/docs-live-brightgreen">
  </a>
  <a href="https://colab.research.google.com/drive/1gD8dSMSE_uNacW4qJ-NSnvRT85xo9ZY2">
    <img src="https://img.shields.io/badge/colab-ff9f01?logo=google-colab&logoColor=white">
  </a>
  <a href="https://www.facebook.com/undertheseanlp/">
    <img src="https://img.shields.io/badge/Facebook-1877F2?logo=facebook&logoColor=white">
  </a>
  <a href="https://www.youtube.com/channel/UC9Jv1Qg49uprg6SjkyAqs9A">
    <img src="https://img.shields.io/badge/YouTube-FF0000?logo=youtube&logoColor=white">
  </a>
</p>

<br/>

<p align="center">
  <a href="https://github.com/undertheseanlp/underthesea/blob/main/docs/contribute/SPONSORS.md">
    <img src="https://img.shields.io/badge/sponsors-6-red?style=social&logo=GithubSponsors">
  </a>
</p>

<h3 align="center">
Open-source Vietnamese Natural Language Process Toolkit
</h3>

`Underthesea` is:

üåä **A Vietnamese NLP toolkit.** Underthesea is a suite of open source Python modules data sets and tutorials supporting research and development in [Vietnamese Natural Language Processing](https://github.com/undertheseanlp/underthesea). We provides extremely easy API to quickly apply pretrained NLP models to your Vietnamese text, such as word segmentation, part-of-speech tagging (PoS), named entity recognition (NER), text classification and dependency parsing.

üéÅ [**Support Us!**](#-support-us) Every bit of support helps us achieve our goals. Thank you so much. üíùüíùüíù

üéâ **New in v9.1.5!** Conversational AI Agent is here! Use `agent("Xin ch√†o")` to chat with an AI assistant specialized in Vietnamese NLP. Supports OpenAI and Azure OpenAI. üöÄ‚ú®

## Installation


To install underthesea, simply:

```bash
$ pip install underthesea
‚ú®üç∞‚ú®
```

Satisfaction, guaranteed.

Install with extras (note: use quotes in zsh):

```bash
$ pip install "underthesea[deep]"    # Deep learning support
$ pip install "underthesea[voice]"   # Text-to-Speech support
$ pip install "underthesea[agent]"   # Conversational AI agent
```

## Tutorials

### Natural Language Processing

<details>
<summary><b><a href="">Sentence Segmentation</a></b> - Breaking text into individual sentences
</summary>

- Usage

    ```python
    >>> from underthesea import sent_tokenize
    >>> text = 'Taylor cho bi·∫øt l√∫c ƒë·∫ßu c√¥ c·∫£m th·∫•y ng·∫°i v·ªõi c√¥ b·∫°n th√¢n Amanda nh∆∞ng r·ªìi m·ªçi th·ª© tr√¥i qua nhanh ch√≥ng. Amanda c≈©ng tho·∫£i m√°i v·ªõi m·ªëi quan h·ªá n√†y.'

    >>> sent_tokenize(text)
    [
      "Taylor cho bi·∫øt l√∫c ƒë·∫ßu c√¥ c·∫£m th·∫•y ng·∫°i v·ªõi c√¥ b·∫°n th√¢n Amanda nh∆∞ng r·ªìi m·ªçi th·ª© tr√¥i qua nhanh ch√≥ng.",
      "Amanda c≈©ng tho·∫£i m√°i v·ªõi m·ªëi quan h·ªá n√†y."
    ]
    ```
</details>

<details>
<summary><b><a href="">Text Normalization</a></b> - Standardizing textual data representation
</summary>

- Usage

    ```python
    >>> from underthesea import text_normalize
    >>> text_normalize("√ê·∫£m ba·ªè ch·∫•t l·ª±∆°ng ph√≤ng th√≠ ngh·ªã√™m ho√° h·ªçc")
    "ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng ph√≤ng th√≠ nghi·ªám h√≥a h·ªçc"
    ```
</details>

<details>
<summary><b><a href="">Tagging</a></b> - Word segmentation, POS tagging, chunking, dependency parsing
</summary>
<br/>

- **Word Segmentation**

    ```python
    >>> from underthesea import word_tokenize
    >>> word_tokenize("Ch√†ng trai 9X Qu·∫£ng Tr·ªã kh·ªüi nghi·ªáp t·ª´ n·∫•m s√≤")
    ["Ch√†ng trai", "9X", "Qu·∫£ng Tr·ªã", "kh·ªüi nghi·ªáp", "t·ª´", "n·∫•m", "s√≤"]

    >>> word_tokenize("Ch√†ng trai 9X Qu·∫£ng Tr·ªã kh·ªüi nghi·ªáp t·ª´ n·∫•m s√≤", format="text")
    "Ch√†ng_trai 9X Qu·∫£ng_Tr·ªã kh·ªüi_nghi·ªáp t·ª´ n·∫•m s√≤"
    ```

- **POS Tagging**

    ```python
    >>> from underthesea import pos_tag
    >>> pos_tag('Ch·ª£ th·ªãt ch√≥ n·ªïi ti·∫øng ·ªü S√†i G√≤n b·ªã truy qu√©t')
    [('Ch·ª£', 'N'),
     ('th·ªãt', 'N'),
     ('ch√≥', 'N'),
     ('n·ªïi ti·∫øng', 'A'),
     ('·ªü', 'E'),
     ('S√†i G√≤n', 'Np'),
     ('b·ªã', 'V'),
     ('truy qu√©t', 'V')]
    ```

- **Chunking**

    ```python
    >>> from underthesea import chunk
    >>> chunk('B√°c sƒ© b√¢y gi·ªù c√≥ th·ªÉ th·∫£n nhi√™n b√°o tin b·ªánh nh√¢n b·ªã ung th∆∞?')
    [('B√°c sƒ©', 'N', 'B-NP'),
     ('b√¢y gi·ªù', 'P', 'B-NP'),
     ('c√≥ th·ªÉ', 'R', 'O'),
     ('th·∫£n nhi√™n', 'A', 'B-AP'),
     ('b√°o', 'V', 'B-VP'),
     ('tin', 'N', 'B-NP'),
     ('b·ªánh nh√¢n', 'N', 'B-NP'),
     ('b·ªã', 'V', 'B-VP'),
     ('ung th∆∞', 'N', 'B-NP'),
     ('?', 'CH', 'O')]
    ```

- **Dependency Parsing**

    ```bash
    $ pip install underthesea[deep]
    ```

    ```python
    >>> from underthesea import dependency_parse
    >>> dependency_parse('T·ªëi 29/11, Vi·ªát Nam th√™m 2 ca m·∫Øc Covid-19')
    [('T·ªëi', 5, 'obl:tmod'),
     ('29/11', 1, 'flat:date'),
     (',', 1, 'punct'),
     ('Vi·ªát Nam', 5, 'nsubj'),
     ('th√™m', 0, 'root'),
     ('2', 7, 'nummod'),
     ('ca', 5, 'obj'),
     ('m·∫Øc', 7, 'nmod'),
     ('Covid-19', 8, 'nummod')]
    ```
</details>

<details>
<summary><b><a href="">Named Entity Recognition</a></b> - Identifying named entities (e.g., names, locations)
</summary>
<br/>

- Usage

    ```python
    >>> from underthesea import ner
    >>> text = 'Ch∆∞a ti·∫øt l·ªô l·ªãch tr√¨nh t·ªõi Vi·ªát Nam c·ªßa T·ªïng th·ªëng M·ªπ Donald Trump'
    >>> ner(text)
    [('Ch∆∞a', 'R', 'O', 'O'),
     ('ti·∫øt l·ªô', 'V', 'B-VP', 'O'),
     ('l·ªãch tr√¨nh', 'V', 'B-VP', 'O'),
     ('t·ªõi', 'E', 'B-PP', 'O'),
     ('Vi·ªát Nam', 'Np', 'B-NP', 'B-LOC'),
     ('c·ªßa', 'E', 'B-PP', 'O'),
     ('T·ªïng th·ªëng', 'N', 'B-NP', 'O'),
     ('M·ªπ', 'Np', 'B-NP', 'B-LOC'),
     ('Donald', 'Np', 'B-NP', 'B-PER'),
     ('Trump', 'Np', 'B-NP', 'I-PER')]
    ```

- Deep Learning Model

    ```bash
    $ pip install underthesea[deep]
    ```

    ```python
    >>> from underthesea import ner
    >>> text = "B·ªô C√¥ng Th∆∞∆°ng x√≥a m·ªôt t·ªïng c·ª•c, gi·∫£m nhi·ªÅu ƒë·∫ßu m·ªëi"
    >>> ner(text, deep=True)
    [
      {'entity': 'B-ORG', 'word': 'B·ªô'},
      {'entity': 'I-ORG', 'word': 'C√¥ng'},
      {'entity': 'I-ORG', 'word': 'Th∆∞∆°ng'}
    ]
    ```
</details>

<details>
<summary><b><a href="">Classification</a></b> - Text classification and sentiment analysis
</summary>
<br/>

- **Text Classification**

    ```python
    >>> from underthesea import classify

    >>> classify('HLV ƒë·∫ßu ti√™n ·ªü Premier League b·ªã sa th·∫£i sau 4 v√≤ng ƒë·∫•u')
    ['The thao']

    >>> classify('H·ªôi ƒë·ªìng t∆∞ v·∫•n kinh doanh Asean vinh danh gi·∫£i th∆∞·ªüng qu·ªëc t·∫ø')
    ['Kinh doanh']

    >> classify('L√£i su·∫•t t·ª´ BIDV r·∫•t ∆∞u ƒë√£i', domain='bank')
    ['INTEREST_RATE']
    ```

- **Sentiment Analysis**

    ```python
    >>> from underthesea import sentiment

    >>> sentiment('h√†ng k√©m ch·∫•t lg,chƒÉn ƒë·∫Øp l√™n d√≠nh l√¥ng l√° kh·∫Øp ng∆∞·ªùi. th·∫•t v·ªçng')
    'negative'
    >>> sentiment('S·∫£n ph·∫©m h∆°i nh·ªè so v·ªõi t∆∞·ªüng t∆∞·ª£ng nh∆∞ng ch·∫•t l∆∞·ª£ng t·ªët, ƒë√≥ng g√≥i c·∫©n th·∫≠n.')
    'positive'

    >>> sentiment('ƒêky qua ƒë∆∞·ªùng link ·ªü b√†i vi·∫øt n√†y t·ª´ th·ª© 6 m√† gi·ªù ch∆∞a th·∫•y ai lhe h·∫øt', domain='bank')
    ['CUSTOMER_SUPPORT#negative']
    >>> sentiment('Xem l·∫°i v·∫´n th·∫•y x√∫c ƒë·ªông v√† t·ª± h√†o v·ªÅ BIDV c·ªßa m√¨nh', domain='bank')
    ['TRADEMARK#positive']
    ```

- **Prompt-based Classification**

    ```bash
    $ pip install underthesea[prompt]
    $ export OPENAI_API_KEY=YOUR_KEY
    ```

    ```python
    >>> from underthesea import classify
    >>> classify("HLV ngo·∫°i ƒë√≤i g·∫ßn t·ª∑ m·ªói th√°ng d·∫´n d·∫Øt tuy·ªÉn Vi·ªát Nam", model='prompt')
    Th·ªÉ thao
    ```
</details>

<details>
<summary><b><a href="">Translation</a></b> - Translating Vietnamese text to English
</summary>
<br/>

- Deep Learning Model

    ```bash
    $ pip install underthesea[deep]
    ```

    ```python
    >>> from underthesea import translate

    >>> translate("H√† N·ªôi l√† th·ªß ƒë√¥ c·ªßa Vi·ªát Nam")
    'Hanoi is the capital of Vietnam'

    >>> translate("·∫®m th·ª±c Vi·ªát Nam n·ªïi ti·∫øng tr√™n th·∫ø gi·ªõi")
    'Vietnamese cuisine is famous around the world'

    >>> translate("I love Vietnamese food", source_lang='en', target_lang='vi')
    'T√¥i y√™u ·∫©m th·ª±c Vi·ªát Nam'
    ```
</details>

<details>
<summary><b><a href="">Lang Detect</a></b> - Identifying the Language of Text
</summary>

<br/>

Lang Detect API. Powered by [FastText](https://fasttext.cc/docs/en/language-identification.html) language identification model, using pure Rust inference via `underthesea_core`.

Usage examples in script

    ```python
    >>> from underthesea import lang_detect

    >>> lang_detect("C·ª±u binh M·ªπ tr·∫£ nh·∫≠t k√Ω nh·∫π l√≤ng khi th·∫•y cu·ªôc s·ªëng h√≤a b√¨nh t·∫°i Vi·ªát Nam")
    vi
    ```
</details>

### Voice

<details>
<summary><b><a href="">Text-to-Speech</a></b> - Converting written text into spoken audio
</summary>

<br/>

Text to Speech API. Thanks to awesome work from [NTT123/vietTTS](https://github.com/ntt123/vietTTS)

Install extend dependencies and models

    ```bash
    $ pip install "underthesea[voice]"
    $ underthesea download-model VIET_TTS_V0_4_1
    ```

Usage examples in script

    ```python
    >>> from underthesea.pipeline.tts import tts

    >>> tts("C·ª±u binh M·ªπ tr·∫£ nh·∫≠t k√Ω nh·∫π l√≤ng khi th·∫•y cu·ªôc s·ªëng h√≤a b√¨nh t·∫°i Vi·ªát Nam")
    A new audio file named `sound.wav` will be generated.
    ```

Usage examples in command line

    ```sh
    $ underthesea tts "C·ª±u binh M·ªπ tr·∫£ nh·∫≠t k√Ω nh·∫π l√≤ng khi th·∫•y cu·ªôc s·ªëng h√≤a b√¨nh t·∫°i Vi·ªát Nam"
    ```
</details>

### Agents

<details>
<summary><b><a href="">Conversational AI Agent</a></b> - Chat with AI for Vietnamese NLP tasks
</summary>

<br/>

Conversational AI Agent with OpenAI and Azure OpenAI support.

Install extend dependencies

    ```bash
    $ pip install "underthesea[agent]"
    $ export OPENAI_API_KEY=your_api_key
    # Or for Azure OpenAI:
    # export AZURE_OPENAI_API_KEY=your_key
    # export AZURE_OPENAI_ENDPOINT=https://xxx.openai.azure.com
    ```

Usage examples in script

    ```python
    >>> from underthesea import agent

    >>> agent("Xin ch√†o!")
    'Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?'

    >>> agent("NLP l√† g√¨?")
    'NLP (Natural Language Processing) l√† x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n...'

    >>> agent("Cho v√≠ d·ª• v·ªÅ word tokenization ti·∫øng Vi·ªát")
    'Word tokenization trong ti·∫øng Vi·ªát l√† qu√° tr√¨nh...'

    # Reset conversation
    >>> agent.reset()
    ```

Supports Azure OpenAI

    ```python
    >>> agent("Hello", provider="azure", model="my-gpt4-deployment")
    ```

Agent with Custom Tools (Function Calling)

    ```python
    >>> from underthesea.agent import Agent, Tool

    # Define tools as functions
    >>> def get_weather(location: str) -> dict:
    ...     """Get current weather for a location."""
    ...     return {"location": location, "temp": 25, "condition": "sunny"}

    >>> def search_news(query: str) -> str:
    ...     """Search Vietnamese news."""
    ...     return f"Results for: {query}"

    # Create agent with tools
    >>> my_agent = Agent(
    ...     name="assistant",
    ...     tools=[
    ...         Tool(get_weather, description="Get weather for a city"),
    ...         Tool(search_news, description="Search Vietnamese news"),
    ...     ],
    ...     instruction="You are a helpful Vietnamese assistant."
    ... )

    # Agent automatically calls tools when needed
    >>> my_agent("Th·ªùi ti·∫øt ·ªü H√† N·ªôi th·∫ø n√†o?")
    'Th·ªùi ti·∫øt ·ªü H√† N·ªôi hi·ªán t·∫°i l√† 25¬∞C v√† n·∫Øng.'

    >>> my_agent.reset()  # Clear conversation history
    ```

Using Default Tools (like LangChain/OpenAI tools)

    ```python
    >>> from underthesea.agent import Agent, default_tools

    # Create agent with built-in tools:
    # calculator, datetime, web_search, wikipedia, shell, python, file ops...
    >>> my_agent = Agent(
    ...     name="assistant",
    ...     tools=default_tools,
    ... )

    >>> my_agent("What time is it?")           # Uses datetime tool
    >>> my_agent("Calculate sqrt(144) + 10")   # Uses calculator tool
    >>> my_agent("Search for Python tutorials") # Uses web_search tool
    ```
</details>

### Resources

<details>
<summary><b><a href="">Vietnamese NLP Resources</a></b></summary>

<br/>

List resources

```bash
$ underthesea list-data
| Name                      | Type        | License | Year | Directory                          |
|---------------------------+-------------+---------+------+------------------------------------|
| CP_Vietnamese_VLC_v2_2022 | Plaintext   | Open    | 2023 | datasets/CP_Vietnamese_VLC_v2_2022 |
| UIT_ABSA_RESTAURANT       | Sentiment   | Open    | 2021 | datasets/UIT_ABSA_RESTAURANT       |
| UIT_ABSA_HOTEL            | Sentiment   | Open    | 2021 | datasets/UIT_ABSA_HOTEL            |
| SE_Vietnamese-UBS         | Sentiment   | Open    | 2020 | datasets/SE_Vietnamese-UBS         |
| CP_Vietnamese-UNC         | Plaintext   | Open    | 2020 | datasets/CP_Vietnamese-UNC         |
| DI_Vietnamese-UVD         | Dictionary  | Open    | 2020 | datasets/DI_Vietnamese-UVD         |
| UTS2017-BANK              | Categorized | Open    | 2017 | datasets/UTS2017-BANK              |
| VNTQ_SMALL                | Plaintext   | Open    | 2012 | datasets/LTA                       |
| VNTQ_BIG                  | Plaintext   | Open    | 2012 | datasets/LTA                       |
| VNESES                    | Plaintext   | Open    | 2012 | datasets/LTA                       |
| VNTC                      | Categorized | Open    | 2007 | datasets/VNTC                      |

$ underthesea list-data --all
```

Download resources

```bash
$ underthesea download-data CP_Vietnamese_VLC_v2_2022
Resource CP_Vietnamese_VLC_v2_2022 is downloaded in ~/.underthesea/datasets/CP_Vietnamese_VLC_v2_2022 folder
```

</details>

### Up Coming Features

* Automatic Speech Recognition

## Contributing

Do you want to contribute with underthesea development? Great! Please read more details at [Contributing Guide](https://undertheseanlp.github.io/underthesea/docs/developer/contributing)

## üíù Support Us

If you found this project helpful and would like to support our work, you can just buy us a coffee ‚òï.

Your support is our biggest encouragement üéÅ!

<img src="https://raw.githubusercontent.com/undertheseanlp/underthesea/main/docs/static/img/support.png"/>
