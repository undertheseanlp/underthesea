"use strict";(globalThis.webpackChunkunderthesea_docs=globalThis.webpackChunkunderthesea_docs||[]).push([[8517],{3704(e,n,t){t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>s,default:()=>p,frontMatter:()=>d,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"developer/architecture","title":"Architecture","description":"This document describes the internal architecture of Underthesea.","source":"@site/versioned_docs/version-9.2.11/developer/architecture.md","sourceDirName":"developer","slug":"/developer/architecture","permalink":"/underthesea/docs/developer/architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/undertheseanlp/underthesea/tree/main/docusaurus/versioned_docs/version-9.2.11/developer/architecture.md","tags":[],"version":"9.2.11","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Contributing Guide","permalink":"/underthesea/docs/developer/contributing"},"next":{"title":"Releasing","permalink":"/underthesea/docs/developer/releasing"}}');var l=t(4848),r=t(8453);const d={},s="Architecture",o={},a=[{value:"Overview",id:"overview",level:2},{value:"Pipeline Module Structure",id:"pipeline-module-structure",level:2},{value:"Main API (<code>__init__.py</code>)",id:"main-api-__init__py",level:3},{value:"Model Implementation",id:"model-implementation",level:3},{value:"Lazy Loading",id:"lazy-loading",level:2},{value:"Model Types",id:"model-types",level:2},{value:"CRF Models",id:"crf-models",level:3},{value:"Deep Learning Models",id:"deep-learning-models",level:3},{value:"FastText Models",id:"fasttext-models",level:3},{value:"Feature Extraction",id:"feature-extraction",level:2},{value:"Resource Management",id:"resource-management",level:2},{value:"Model Storage",id:"model-storage",level:3},{value:"Model Download",id:"model-download",level:3},{value:"Rust Extension",id:"rust-extension",level:2},{value:"CLI Architecture",id:"cli-architecture",level:2},{value:"Optional Dependencies",id:"optional-dependencies",level:2},{value:"Testing Architecture",id:"testing-architecture",level:2},{value:"Extending Underthesea",id:"extending-underthesea",level:2},{value:"Adding a New Pipeline",id:"adding-a-new-pipeline",level:3},{value:"Adding a New Model",id:"adding-a-new-model",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"architecture",children:"Architecture"})}),"\n",(0,l.jsx)(n.p,{children:"This document describes the internal architecture of Underthesea."}),"\n",(0,l.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,l.jsx)(n.p,{children:"Underthesea is organized as a collection of NLP pipelines, each handling a specific task."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"underthesea/\n\u251c\u2500\u2500 pipeline/              # Main NLP modules\n\u2502   \u251c\u2500\u2500 sent_tokenize/     # Sentence segmentation\n\u2502   \u251c\u2500\u2500 text_normalize/    # Text normalization\n\u2502   \u251c\u2500\u2500 word_tokenize/     # Word segmentation\n\u2502   \u251c\u2500\u2500 pos_tag/           # POS tagging\n\u2502   \u251c\u2500\u2500 chunking/          # Phrase chunking\n\u2502   \u251c\u2500\u2500 dependency_parse/  # Dependency parsing\n\u2502   \u251c\u2500\u2500 ner/               # Named entity recognition\n\u2502   \u251c\u2500\u2500 classification/    # Text classification\n\u2502   \u251c\u2500\u2500 sentiment/         # Sentiment analysis\n\u2502   \u251c\u2500\u2500 translate/         # Translation\n\u2502   \u251c\u2500\u2500 lang_detect/       # Language detection\n\u2502   \u2514\u2500\u2500 tts/               # Text-to-speech\n\u251c\u2500\u2500 models/                # Model implementations\n\u251c\u2500\u2500 datasets/              # Built-in datasets\n\u251c\u2500\u2500 corpus/                # Corpus handling\n\u251c\u2500\u2500 resources/             # Static resources\n\u2514\u2500\u2500 cli.py                 # CLI interface\n"})}),"\n",(0,l.jsx)(n.h2,{id:"pipeline-module-structure",children:"Pipeline Module Structure"}),"\n",(0,l.jsx)(n.p,{children:"Each pipeline module follows a consistent pattern:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"pipeline/word_tokenize/\n\u251c\u2500\u2500 __init__.py            # Main API function\n\u251c\u2500\u2500 model.py               # Model implementation\n\u251c\u2500\u2500 feature.py             # Feature extraction\n\u2514\u2500\u2500 default_model/         # Default model files\n"})}),"\n",(0,l.jsxs)(n.h3,{id:"main-api-__init__py",children:["Main API (",(0,l.jsx)(n.code,{children:"__init__.py"}),")"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# Lazy loading pattern\n_model = None\n\ndef word_tokenize(sentence, format=None):\n    global _model\n    if _model is None:\n        _model = load_model()\n    return _model.predict(sentence, format)\n"})}),"\n",(0,l.jsx)(n.h3,{id:"model-implementation",children:"Model Implementation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"class CRFModel:\n    def __init__(self, model_path):\n        self.model = load_crf(model_path)\n\n    def predict(self, text):\n        features = extract_features(text)\n        return self.model.tag(features)\n"})}),"\n",(0,l.jsx)(n.h2,{id:"lazy-loading",children:"Lazy Loading"}),"\n",(0,l.jsx)(n.p,{children:"Models are loaded on first use to minimize startup time:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# At import time - no model loaded\nfrom underthesea import word_tokenize\n\n# First call - model loaded and cached\nresult = word_tokenize("text")\n\n# Subsequent calls - uses cached model\nresult = word_tokenize("more text")\n'})}),"\n",(0,l.jsx)(n.p,{children:"Benefits:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Fast import time"}),"\n",(0,l.jsx)(n.li,{children:"Memory efficiency (only used models loaded)"}),"\n",(0,l.jsx)(n.li,{children:"Simple API"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"model-types",children:"Model Types"}),"\n",(0,l.jsx)(n.h3,{id:"crf-models",children:"CRF Models"}),"\n",(0,l.jsx)(n.p,{children:"Used for: word segmentation, POS tagging, chunking, NER, classification, sentiment"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# Uses python-crfsuite\nimport pycrfsuite\n\nclass CRFTagger:\n    def __init__(self, model_path):\n        self.tagger = pycrfsuite.Tagger()\n        self.tagger.open(model_path)\n\n    def tag(self, features):\n        return self.tagger.tag(features)\n"})}),"\n",(0,l.jsx)(n.h3,{id:"deep-learning-models",children:"Deep Learning Models"}),"\n",(0,l.jsx)(n.p,{children:"Used for: dependency parsing, deep NER, translation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# Uses transformers\nfrom transformers import AutoModel, AutoTokenizer\n\nclass TransformerModel:\n    def __init__(self, model_name):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name)\n"})}),"\n",(0,l.jsx)(n.h3,{id:"fasttext-models",children:"FastText Models"}),"\n",(0,l.jsx)(n.p,{children:"Used for: language detection"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"import fasttext\n\nclass LangDetector:\n    def __init__(self, model_path):\n        self.model = fasttext.load_model(model_path)\n\n    def detect(self, text):\n        prediction = self.model.predict(text)\n        return prediction[0][0].replace('__label__', '')\n"})}),"\n",(0,l.jsx)(n.h2,{id:"feature-extraction",children:"Feature Extraction"}),"\n",(0,l.jsx)(n.p,{children:"Features are extracted for CRF models:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def extract_features(sentence):\n    features = []\n    for i, word in enumerate(sentence):\n        word_features = {\n            'word': word,\n            'is_upper': word.isupper(),\n            'is_title': word.istitle(),\n            'prev_word': sentence[i-1] if i > 0 else 'BOS',\n            'next_word': sentence[i+1] if i < len(sentence)-1 else 'EOS',\n        }\n        features.append(word_features)\n    return features\n"})}),"\n",(0,l.jsx)(n.h2,{id:"resource-management",children:"Resource Management"}),"\n",(0,l.jsx)(n.h3,{id:"model-storage",children:"Model Storage"}),"\n",(0,l.jsxs)(n.p,{children:["Models are stored in ",(0,l.jsx)(n.code,{children:"~/.underthesea/models/"}),":"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"~/.underthesea/\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 WS_VLSP2013_CRF/\n\u2502   \u251c\u2500\u2500 POS_VLSP2013_CRF/\n\u2502   \u2514\u2500\u2500 NER_VLSP2016_BERT/\n\u2514\u2500\u2500 datasets/\n    \u251c\u2500\u2500 VNTC/\n    \u2514\u2500\u2500 UTS2017-BANK/\n"})}),"\n",(0,l.jsx)(n.h3,{id:"model-download",children:"Model Download"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"def download_model(model_name):\n    url = get_model_url(model_name)\n    local_path = get_local_path(model_name)\n\n    if not os.path.exists(local_path):\n        download_file(url, local_path)\n        extract_archive(local_path)\n\n    return local_path\n"})}),"\n",(0,l.jsx)(n.h2,{id:"rust-extension",children:"Rust Extension"}),"\n",(0,l.jsx)(n.p,{children:"Performance-critical code uses the Rust extension:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"extensions/underthesea_core/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 lib.rs             # Rust implementation\n\u251c\u2500\u2500 Cargo.toml             # Rust dependencies\n\u2514\u2500\u2500 pyproject.toml         # Python binding config\n"})}),"\n",(0,l.jsx)(n.p,{children:"Built with maturin:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"cd extensions/underthesea_core\nmaturin develop\n"})}),"\n",(0,l.jsx)(n.h2,{id:"cli-architecture",children:"CLI Architecture"}),"\n",(0,l.jsx)(n.p,{children:"The CLI uses Click:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# cli.py\nimport click\n\n@click.group()\ndef cli():\n    pass\n\n@cli.command()\ndef list_data():\n    """List available datasets."""\n    for dataset in get_datasets():\n        print(dataset)\n\n@cli.command()\n@click.argument(\'text\')\ndef tts(text):\n    """Convert text to speech."""\n    from underthesea.pipeline.tts import tts\n    tts(text)\n'})}),"\n",(0,l.jsx)(n.h2,{id:"optional-dependencies",children:"Optional Dependencies"}),"\n",(0,l.jsx)(n.p,{children:"Optional features are guarded:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'def translate(text):\n    try:\n        from transformers import AutoModel\n    except ImportError:\n        raise ImportError(\n            "Translation requires deep learning dependencies. "\n            "Install with: pip install \'underthesea[deep]\'"\n        )\n    # ... translation logic\n'})}),"\n",(0,l.jsx)(n.h2,{id:"testing-architecture",children:"Testing Architecture"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"tests/\n\u251c\u2500\u2500 pipeline/\n\u2502   \u251c\u2500\u2500 word_tokenize/\n\u2502   \u2502   \u2514\u2500\u2500 test_word_tokenize.py\n\u2502   \u251c\u2500\u2500 pos_tag/\n\u2502   \u2502   \u2514\u2500\u2500 test_pos_tag.py\n\u2502   \u2514\u2500\u2500 ner/\n\u2502       \u2514\u2500\u2500 test_ner.py\n\u2514\u2500\u2500 conftest.py            # Pytest fixtures\n"})}),"\n",(0,l.jsx)(n.h2,{id:"extending-underthesea",children:"Extending Underthesea"}),"\n",(0,l.jsx)(n.h3,{id:"adding-a-new-pipeline",children:"Adding a New Pipeline"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Create directory: ",(0,l.jsx)(n.code,{children:"underthesea/pipeline/new_task/"})]}),"\n",(0,l.jsxs)(n.li,{children:["Implement ",(0,l.jsx)(n.code,{children:"__init__.py"})," with main API"]}),"\n",(0,l.jsx)(n.li,{children:"Add model implementation"}),"\n",(0,l.jsxs)(n.li,{children:["Export from ",(0,l.jsx)(n.code,{children:"underthesea/__init__.py"})]}),"\n",(0,l.jsxs)(n.li,{children:["Add tests in ",(0,l.jsx)(n.code,{children:"tests/pipeline/new_task/"})]}),"\n",(0,l.jsx)(n.li,{children:"Add documentation"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"adding-a-new-model",children:"Adding a New Model"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsx)(n.li,{children:"Train the model using appropriate toolkit"}),"\n",(0,l.jsx)(n.li,{children:"Save model files"}),"\n",(0,l.jsx)(n.li,{children:"Update model registry"}),"\n",(0,l.jsx)(n.li,{children:"Add download logic"}),"\n",(0,l.jsx)(n.li,{children:"Test with existing pipeline"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},8453(e,n,t){t.d(n,{R:()=>d,x:()=>s});var i=t(6540);const l={},r=i.createContext(l);function d(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:d(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);