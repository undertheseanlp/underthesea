"use strict";(globalThis.webpackChunkunderthesea_docs=globalThis.webpackChunkunderthesea_docs||[]).push([[6542],{8680(e,n,t){t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>o});var s=t(4730),i=t(4848),r=t(8453);const a={slug:"rewrite-fasttext-in-rust",title:"Rewriting FastText in Rust",authors:["rain1024"],tags:["rust","performance","fasttext","nlp","language-detection"]},l="Rewriting FastText in Rust: 1,149 Lines to Replace a C++ Dependency",d={authorsImageUrls:[void 0]},o=[{value:"Why Replace FastText?",id:"why-replace-fasttext",level:2},{value:"What We Built",id:"what-we-built",level:2},{value:"The Architecture Change",id:"the-architecture-change",level:2},{value:"Before",id:"before",level:3},{value:"After",id:"after",level:3},{value:"Code Change",id:"code-change",level:3},{value:"Implementation Deep Dive",id:"implementation-deep-dive",level:2},{value:"1. Binary Format Parsing",id:"1-binary-format-parsing",level:3},{value:"2. The Hash Function: A Subtle Trap",id:"2-the-hash-function-a-subtle-trap",level:3},{value:"3. Dictionary and N-gram Features",id:"3-dictionary-and-n-gram-features",level:3},{value:"4. Two Inference Paths",id:"4-two-inference-paths",level:3},{value:"5. Dense and Quantized Matrices",id:"5-dense-and-quantized-matrices",level:3},{value:"6. PyO3 Bindings",id:"6-pyo3-bindings",level:3},{value:"What We Gained",id:"what-we-gained",level:2},{value:"Simpler Installation",id:"simpler-installation",level:3},{value:"Fewer Dependencies",id:"fewer-dependencies",level:3},{value:"Model Compatibility",id:"model-compatibility",level:3},{value:"The Bigger Picture: Replacing C++ with Rust",id:"the-bigger-picture-replacing-c-with-rust",level:2},{value:"Lines of Rust replacing each dependency:",id:"lines-of-rust-replacing-each-dependency",level:3},{value:"Lessons Learned",id:"lessons-learned",level:2},{value:"1. Byte-level compatibility is non-negotiable",id:"1-byte-level-compatibility-is-non-negotiable",level:3},{value:"2. Inference-only is the sweet spot",id:"2-inference-only-is-the-sweet-spot",level:3},{value:"3. Product quantization support is essential",id:"3-product-quantization-support-is-essential",level:3},{value:"4. PyO3 makes Rust-Python integration painless",id:"4-pyo3-makes-rust-python-integration-painless",level:3},{value:"Try It Out",id:"try-it-out",level:2},{value:"Links",id:"links",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:["In underthesea v9.2.9, we replaced the ",(0,i.jsx)(n.code,{children:"fasttext"})," Python package (a wrapper around Facebook's C++ library) with a ",(0,i.jsx)(n.strong,{children:"pure Rust implementation"})," inside ",(0,i.jsx)(n.code,{children:"underthesea-core"}),". The result: identical predictions, simpler installation, and one fewer C++ dependency in our stack."]}),"\n",(0,i.jsx)(n.h2,{id:"why-replace-fasttext",children:"Why Replace FastText?"}),"\n",(0,i.jsxs)(n.p,{children:["FastText is used in underthesea for ",(0,i.jsx)(n.strong,{children:"language detection"})," \u2014 identifying whether input text is Vietnamese, English, French, etc. The original setup worked, but had friction:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"C++ compilation required"})," \u2014 ",(0,i.jsx)(n.code,{children:"pip install fasttext"})," needs a C++ compiler, which fails on minimal Docker images and Windows environments"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Heavy dependency"})," \u2014 pulls in the entire FastText C++ library (~50MB) just for inference"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multiple language boundaries"})," \u2014 Python \u2192 C++ FFI \u2192 Python, with overhead at each crossing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Maintenance burden"})," \u2014 the ",(0,i.jsx)(n.code,{children:"fasttext"})," package has had compatibility issues with newer Python versions"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Since we already had ",(0,i.jsx)(n.code,{children:"underthesea-core"})," (our Rust extension via PyO3), adding FastText inference there was a natural fit."]}),"\n",(0,i.jsx)(n.h2,{id:"what-we-built",children:"What We Built"}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.strong,{children:"pure Rust FastText inference engine"})," in 1,149 lines across 6 files:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"extensions/underthesea_core/src/fasttext/\n\u251c\u2500\u2500 mod.rs          # FastTextModel: load + predict (126 lines)\n\u251c\u2500\u2500 args.rs         # Model hyperparameters deserialization (127 lines)\n\u251c\u2500\u2500 dictionary.rs   # Vocabulary + n-gram hashing (285 lines)\n\u251c\u2500\u2500 inference.rs    # Hierarchical softmax + softmax prediction (303 lines)\n\u251c\u2500\u2500 matrix.rs       # Dense + quantized matrix operations (256 lines)\n\u2514\u2500\u2500 hash.rs         # FNV-1a hash (52 lines)\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This is inference-only \u2014 we load existing FastText ",(0,i.jsx)(n.code,{children:".bin"})," and ",(0,i.jsx)(n.code,{children:".ftz"})," models trained by the original C++ library. No retraining needed."]}),"\n",(0,i.jsx)(n.h2,{id:"the-architecture-change",children:"The Architecture Change"}),"\n",(0,i.jsx)(n.h3,{id:"before",children:"Before"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Python\n  \u2502\n  \u251c\u2500\u2500 import fasttext           # C++ FFI wrapper\n  \u2502     \u2514\u2500\u2500 libfasttext.so      # Facebook's C++ library\n  \u2502           \u2514\u2500\u2500 model.bin     # FastText binary model\n  \u2502\n  \u2514\u2500\u2500 predictions\n"})}),"\n",(0,i.jsx)(n.p,{children:"Three language boundaries: Python \u2192 C++ wrapper \u2192 C++ library."}),"\n",(0,i.jsx)(n.h3,{id:"after",children:"After"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Python\n  \u2502\n  \u251c\u2500\u2500 from underthesea_core import FastText   # PyO3 Rust binding\n  \u2502     \u2514\u2500\u2500 fasttext::FastTextModel           # Pure Rust\n  \u2502           \u2514\u2500\u2500 model.bin                   # Same binary format\n  \u2502\n  \u2514\u2500\u2500 predictions\n"})}),"\n",(0,i.jsx)(n.p,{children:"One clean boundary: Python \u2192 Rust via PyO3."}),"\n",(0,i.jsx)(n.h3,{id:"code-change",children:"Code Change"}),"\n",(0,i.jsx)(n.p,{children:"The API is almost identical:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Before:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import fasttext\n\nmodel = fasttext.load_model("lid.176.ftz")\npredictions = model.predict("Xin ch\xe0o th\u1ebf gi\u1edbi")\n# ((\'__label__vi\',), array([0.98]))\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"After:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from underthesea_core import FastText\n\nmodel = FastText.load("lid.176.ftz")\npredictions = model.predict("Xin ch\xe0o th\u1ebf gi\u1edbi")\n# [(\'vi\', 0.98)]\n'})}),"\n",(0,i.jsxs)(n.p,{children:["In underthesea's ",(0,i.jsx)(n.code,{children:"lang_detect"})," pipeline, the switch was a one-line import change:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Before: import fasttext\n# After:\nfrom underthesea_core import FastText\n\nlang_detect_model = FastText.load(str(model_path))\npredictions = lang_detect_model.predict(text, k=1)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"implementation-deep-dive",children:"Implementation Deep Dive"}),"\n",(0,i.jsx)(n.h3,{id:"1-binary-format-parsing",children:"1. Binary Format Parsing"}),"\n",(0,i.jsx)(n.p,{children:"FastText models use a custom binary format. We must parse it byte-for-byte to match the C++ implementation:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'pub fn load(path: &str) -> io::Result<Self> {\n    let file = File::open(path)?;\n    let mut reader = BufReader::new(file);\n\n    let quant = path.ends_with(".ftz");\n\n    check_header(&mut reader)?;          // Magic number + version\n    let args = Args::load(&mut reader)?;  // Hyperparameters\n    let dictionary = Dictionary::load(&mut reader, &args)?;  // Vocabulary\n\n    let file_quant = read_bool(&mut reader)?;\n    let input_matrix = FastTextMatrix::load(&mut reader, quant && file_quant)?;\n\n    let output_quant = read_bool(&mut reader)?;\n    let output_matrix = FastTextMatrix::load(&mut reader, quant && output_quant)?;\n\n    // Build Huffman tree for hierarchical softmax\n    let hs_tree = if args.loss == LossName::HierarchicalSoftmax {\n        let counts = dictionary.get_label_counts();\n        Some(HSTree::build(&counts))\n    } else {\n        None\n    };\n\n    Ok(FastTextModel { args, dictionary, input_matrix, output_matrix, hs_tree })\n}\n'})}),"\n",(0,i.jsxs)(n.p,{children:["The magic number ",(0,i.jsx)(n.code,{children:"0x2F4F16BA"})," and version ",(0,i.jsx)(n.code,{children:"12"})," must match exactly, or the model is rejected."]}),"\n",(0,i.jsx)(n.h3,{id:"2-the-hash-function-a-subtle-trap",children:"2. The Hash Function: A Subtle Trap"}),"\n",(0,i.jsxs)(n.p,{children:["FastText uses FNV-1a hashing for word and n-gram lookups. The critical detail: ",(0,i.jsx)(n.strong,{children:"non-ASCII bytes are sign-extended"}),", matching C++'s signed ",(0,i.jsx)(n.code,{children:"char"})," behavior:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"pub fn fasttext_hash(s: &[u8]) -> u32 {\n    let mut h: u32 = 2166136261;\n    for &byte in s {\n        // Sign-extend: cast to i8 first (like C++ int8_t), then to u32\n        h ^= byte as i8 as u32;\n        h = h.wrapping_mul(16777619);\n    }\n    h\n}\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Without the ",(0,i.jsx)(n.code,{children:"byte as i8 as u32"})," cast, Vietnamese characters (which use multi-byte UTF-8 with high bytes like ",(0,i.jsx)(n.code,{children:"0xC3"}),", ",(0,i.jsx)(n.code,{children:"0xE1"}),") would hash to different values than the C++ implementation, producing wrong predictions. This was the trickiest part to get right."]}),"\n",(0,i.jsx)(n.h3,{id:"3-dictionary-and-n-gram-features",children:"3. Dictionary and N-gram Features"}),"\n",(0,i.jsx)(n.p,{children:"The dictionary handles vocabulary lookup with an open-addressing hash table (30M slots, matching C++):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"pub struct Dictionary {\n    entries: Vec<Entry>,\n    word2int: Vec<i32>,    // 30M-slot hash table\n    nwords: i32,\n    nlabels: i32,\n    pruneidx: HashMap<i32, i32>,  // For quantized models\n    // N-gram parameters\n    bucket: i32,\n    minn: i32,\n    maxn: i32,\n    word_ngrams: i32,\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:"For each input token, we generate three types of features:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Word ID"})," \u2014 direct vocabulary lookup"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Character n-grams"})," \u2014 subword features like ",(0,i.jsx)(n.code,{children:"<xin"}),", ",(0,i.jsx)(n.code,{children:"xin>"}),", ",(0,i.jsx)(n.code,{children:"<xi"}),", ",(0,i.jsx)(n.code,{children:"in>"}),' for the word "xin"']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Word n-grams"})," \u2014 bigrams/trigrams of word IDs"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Character n-grams are bounded by ",(0,i.jsx)(n.code,{children:"<"})," and ",(0,i.jsx)(n.code,{children:">"})," markers and hashed into buckets:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'fn compute_char_ngrams(&self, word: &str, features: &mut Vec<i32>) {\n    let bounded = format!("<{}>", word);\n    let bytes = bounded.as_bytes();\n\n    // Walk character boundaries (not bytes \u2014 Vietnamese is multi-byte UTF-8)\n    let char_boundaries = compute_utf8_boundaries(bytes);\n\n    for n in self.minn..=self.maxn {\n        for start_char in 0..=(nchars - n) {\n            let ngram = &bytes[char_boundaries[start_char]..char_boundaries[start_char + n]];\n            let h = fasttext_hash(ngram);\n            let bucket_hash = (h as i64 % self.bucket as i64) as i32;\n            self.push_hash(features, bucket_hash);\n        }\n    }\n}\n'})}),"\n",(0,i.jsx)(n.p,{children:"This is where FastText's power comes from \u2014 even unknown words get meaningful features from their character substrings."}),"\n",(0,i.jsx)(n.h3,{id:"4-two-inference-paths",children:"4. Two Inference Paths"}),"\n",(0,i.jsx)(n.p,{children:"FastText models use different loss functions. We implement both:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Hierarchical Softmax"})," (for models with many labels like language detection with 176 languages):"]}),"\n",(0,i.jsx)(n.p,{children:"The key insight: instead of computing scores for all 176 labels (O(n)), we traverse a Huffman tree via DFS, pruning branches that can't beat the current top-k (O(k log n)):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"fn dfs(&self, k: usize, threshold: f32, node: usize, score: f32,\n       hidden: &[f32], output: &FastTextMatrix,\n       heap: &mut BinaryHeap<Reverse<(FloatOrd, usize)>>) {\n    // Prune: if this branch can't beat threshold, skip\n    if score < std_log(threshold) { return; }\n    // Prune: if heap is full and this can't beat worst result, skip\n    if heap.len() == k && score < heap.peek().unwrap().0.0.0 { return; }\n\n    let n = &self.tree[node];\n    if n.left == -1 && n.right == -1 {\n        // Leaf node = label\n        heap.push(Reverse((FloatOrd(score), node)));\n        if heap.len() > k { heap.pop(); }\n        return;\n    }\n\n    let f = sigmoid(output.dot_row(hidden, node - self.osz));\n\n    // Recurse into both children with accumulated log-probabilities\n    self.dfs(k, threshold, n.left as usize,  score + std_log(1.0 - f), hidden, output, heap);\n    self.dfs(k, threshold, n.right as usize, score + std_log(f),       hidden, output, heap);\n}\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Standard Softmax"})," (for models with fewer labels):"]}),"\n",(0,i.jsx)(n.p,{children:"Direct computation \u2014 one dot product per label, then partial sort to find top-k:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"fn predict_softmax(k: usize, hidden: &[f32], output: &FastTextMatrix, nlabels: usize)\n    -> Vec<(f32, usize)>\n{\n    let mut logits: Vec<f32> = (0..nlabels)\n        .map(|i| output.dot_row(hidden, i))\n        .collect();\n    softmax(&mut logits);\n\n    // Partial sort: O(n) instead of O(n log n) full sort\n    let mut indices: Vec<usize> = (0..nlabels).collect();\n    indices.select_nth_unstable_by(k - 1, |&a, &b|\n        logits[b].partial_cmp(&logits[a]).unwrap_or(Ordering::Equal)\n    );\n    indices.truncate(k);\n    // ...\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"5-dense-and-quantized-matrices",children:"5. Dense and Quantized Matrices"}),"\n",(0,i.jsx)(n.p,{children:"FastText models come in two flavors:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:".bin"})})," \u2014 dense float32 matrices (large but fast)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:".ftz"})})," \u2014 product-quantized matrices (4-10x smaller, slightly slower)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"We handle both through a trait:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"pub trait Matrix {\n    fn rows(&self) -> usize;\n    fn cols(&self) -> usize;\n    fn add_row_to(&self, row: usize, output: &mut [f32]);\n    fn dot_row(&self, vec: &[f32], row: usize) -> f32;\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:"Dense is straightforward \u2014 row-major float array with SIMD-friendly dot products:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"fn dot_row(&self, vec: &[f32], row: usize) -> f32 {\n    let start = row * self.cols;\n    let row_data = &self.data[start..start + self.cols];\n    vec.iter().zip(row_data.iter()).map(|(&a, &b)| a * b).sum()\n}\n"})}),"\n",(0,i.jsx)(n.p,{children:"Quantized uses product quantization \u2014 each vector is split into sub-spaces, each quantized to one of 256 centroids (8-bit codes):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:"fn dot_row(&self, vec: &[f32], row: usize) -> f32 {\n    let norm = self.get_norm(row);\n    let mut sum = 0.0f32;\n    let mut dim_offset = 0;\n    for subq in 0..self.pq.nsubq {\n        let code = self.codes[row * self.pq.nsubq + subq];\n        let centroid = self.pq.get_centroid(subq, code);\n        for (i, &c) in centroid.iter().enumerate() {\n            sum += vec[dim_offset + i] * c;\n        }\n        dim_offset += self.pq.dsub;\n    }\n    sum * norm\n}\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This lets us load Facebook's compressed ",(0,i.jsx)(n.code,{children:"lid.176.ftz"})," (917KB) instead of the dense ",(0,i.jsx)(n.code,{children:"lid.176.bin"})," (~130MB)."]}),"\n",(0,i.jsx)(n.h3,{id:"6-pyo3-bindings",children:"6. PyO3 Bindings"}),"\n",(0,i.jsx)(n.p,{children:"The Python interface is minimal \u2014 PyO3 makes it trivial:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-rust",children:'#[pyclass(name = "FastText")]\npub struct PyFastText {\n    model: fasttext::FastTextModel,\n}\n\n#[pymethods]\nimpl PyFastText {\n    #[staticmethod]\n    pub fn load(path: &str) -> PyResult<Self> {\n        let model = fasttext::FastTextModel::load(path)\n            .map_err(pyo3::exceptions::PyIOError::new_err)?;\n        Ok(Self { model })\n    }\n\n    #[pyo3(signature = (text, k=1))]\n    pub fn predict(&self, text: &str, k: usize) -> Vec<(String, f32)> {\n        self.model.predict(text, k)\n    }\n\n    pub fn get_labels(&self) -> Vec<String> {\n        self.model.get_labels()\n    }\n\n    #[getter]\n    pub fn dim(&self) -> i32 { self.model.dim() }\n\n    #[getter]\n    pub fn nwords(&self) -> i32 { self.model.nwords() }\n\n    #[getter]\n    pub fn nlabels(&self) -> i32 { self.model.nlabels() }\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"what-we-gained",children:"What We Gained"}),"\n",(0,i.jsx)(n.h3,{id:"simpler-installation",children:"Simpler Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"# Before: needs C++ compiler, can fail on many platforms\npip install fasttext  # Often fails: \"error: command 'gcc' failed\"\n\n# After: pre-built wheels, just works\npip install underthesea  # Includes Rust-compiled underthesea-core\n"})}),"\n",(0,i.jsx)(n.h3,{id:"fewer-dependencies",children:"Fewer Dependencies"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"# Before: underthesea required\nfasttext>=0.9.2      # C++ FastText wrapper\npython-crfsuite      # C++ CRFsuite wrapper\nscikit-learn         # For TfidfVectorizer + LinearSVC\njoblib               # For pickle serialization\n\n# After: just one Rust extension\nunderthesea-core     # Everything in Rust\n"})}),"\n",(0,i.jsxs)(n.p,{children:["All four dependencies \u2014 ",(0,i.jsx)(n.code,{children:"fasttext"}),", ",(0,i.jsx)(n.code,{children:"python-crfsuite"}),", ",(0,i.jsx)(n.code,{children:"scikit-learn"})," (for classification), and ",(0,i.jsx)(n.code,{children:"joblib"})," \u2014 have been replaced by a single ",(0,i.jsx)(n.code,{children:"underthesea-core"})," package."]}),"\n",(0,i.jsx)(n.h3,{id:"model-compatibility",children:"Model Compatibility"}),"\n",(0,i.jsxs)(n.p,{children:["The Rust implementation reads the ",(0,i.jsx)(n.strong,{children:"exact same binary format"})," as Facebook's C++ code. Any ",(0,i.jsx)(n.code,{children:".bin"})," or ",(0,i.jsx)(n.code,{children:".ftz"})," model trained by the original FastText works unchanged:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from underthesea_core import FastText\n\n# Facebook's pre-trained language identification model \u2014 just works\nmodel = FastText.load(\"lid.176.ftz\")\nmodel.predict(\"H\xe0 N\u1ed9i l\xe0 th\u1ee7 \u0111\xf4 c\u1ee7a Vi\u1ec7t Nam\", k=3)\n# [('vi', 0.97), ('id', 0.01), ('ms', 0.005)]\n"})}),"\n",(0,i.jsx)(n.h2,{id:"the-bigger-picture-replacing-c-with-rust",children:"The Bigger Picture: Replacing C++ with Rust"}),"\n",(0,i.jsx)(n.p,{children:"This FastText rewrite is part of a broader effort to consolidate underthesea's backend into a single Rust extension. Here's the full migration timeline:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Version"}),(0,i.jsx)(n.th,{children:"What Changed"}),(0,i.jsx)(n.th,{children:"C++ Dependency Removed"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"v9.2.2-v9.2.5"}),(0,i.jsx)(n.td,{children:"CRF tagger rewritten in Rust"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"python-crfsuite"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"v9.2.9"}),(0,i.jsx)(n.td,{children:"Text classifier rewritten in Rust"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"scikit-learn"})," + ",(0,i.jsx)(n.code,{children:"joblib"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"v9.2.9"}),(0,i.jsx)(n.td,{children:"FastText inference rewritten in Rust"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"fasttext"})})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"lines-of-rust-replacing-each-dependency",children:"Lines of Rust replacing each dependency:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Rust Lines"}),(0,i.jsx)(n.th,{children:"Replaces"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"FastText inference"}),(0,i.jsx)(n.td,{children:"1,149"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"fasttext"})," (C++ FFI)"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"TF-IDF + Linear SVM"}),(0,i.jsx)(n.td,{children:"2,024"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"scikit-learn"})," + ",(0,i.jsx)(n.code,{children:"joblib"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"CRF tagger + trainer"}),(0,i.jsx)(n.td,{children:"~3,000"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"python-crfsuite"})," (C++ FFI)"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Vietnamese preprocessor"}),(0,i.jsx)(n.td,{children:"620"}),(0,i.jsx)(n.td,{children:"Custom Python code"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"PyO3 bindings"}),(0,i.jsx)(n.td,{children:"918"}),(0,i.jsx)(n.td,{children:"N/A"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Total"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"~7,700"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"4 C/C++ dependencies"})})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"Under 8,000 lines of Rust replaced four separate C/C++ dependencies, unifying everything into a single compiled extension with:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pre-built wheels for Linux, macOS (Intel + ARM), and Windows"}),"\n",(0,i.jsx)(n.li,{children:"No C/C++ compiler needed for installation"}),"\n",(0,i.jsx)(n.li,{children:"One coherent codebase instead of four upstream projects"}),"\n",(0,i.jsx)(n.li,{children:"Consistent binary serialization (bincode) instead of mixed pickle/joblib/custom formats"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"lessons-learned",children:"Lessons Learned"}),"\n",(0,i.jsx)(n.h3,{id:"1-byte-level-compatibility-is-non-negotiable",children:"1. Byte-level compatibility is non-negotiable"}),"\n",(0,i.jsxs)(n.p,{children:["The hash function sign-extension bug (",(0,i.jsx)(n.code,{children:"byte as i8 as u32"}),") took the longest to find. Without it, predictions for any non-ASCII text (i.e., all Vietnamese) were wrong. When reimplementing binary formats, every byte matters."]}),"\n",(0,i.jsx)(n.h3,{id:"2-inference-only-is-the-sweet-spot",children:"2. Inference-only is the sweet spot"}),"\n",(0,i.jsxs)(n.p,{children:["We deliberately chose not to implement FastText training in Rust. Training happens once; inference happens millions of times. By supporting the existing ",(0,i.jsx)(n.code,{children:".bin"}),"/",(0,i.jsx)(n.code,{children:".ftz"})," format, we get the benefits of Rust for the hot path while still using Facebook's battle-tested training code when needed."]}),"\n",(0,i.jsx)(n.h3,{id:"3-product-quantization-support-is-essential",children:"3. Product quantization support is essential"}),"\n",(0,i.jsxs)(n.p,{children:["Many production FastText models use ",(0,i.jsx)(n.code,{children:".ftz"})," (quantized) format for 4-10x size reduction. Skipping quantization support would have made the rewrite impractical for real deployments."]}),"\n",(0,i.jsx)(n.h3,{id:"4-pyo3-makes-rust-python-integration-painless",children:"4. PyO3 makes Rust-Python integration painless"}),"\n",(0,i.jsx)(n.p,{children:"The binding layer is under 50 lines. PyO3 handles type conversion, error propagation, GIL management, and memory cleanup automatically. The cognitive overhead of maintaining a Rust extension is surprisingly low."}),"\n",(0,i.jsx)(n.h2,{id:"try-it-out",children:"Try It Out"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install underthesea>=9.2.9\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from underthesea import lang_detect\n\n# Uses Rust FastText under the hood\nlang_detect(\"Xin ch\xe0o th\u1ebf gi\u1edbi\")  # 'vi'\nlang_detect(\"Hello world\")        # 'en'\nlang_detect(\"Bonjour le monde\")   # 'fr'\n"})}),"\n",(0,i.jsx)(n.p,{children:"Or use the Rust FastText directly:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from underthesea_core import FastText\n\nmodel = FastText.load("your_model.bin")\nmodel.predict("your text here", k=5)\nmodel.get_labels()   # All available labels\nmodel.dim            # Embedding dimension\nmodel.nwords         # Vocabulary size\nmodel.nlabels        # Number of labels\n'})}),"\n",(0,i.jsx)(n.h2,{id:"links",children:"Links"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://github.com/undertheseanlp/underthesea/pull/953",children:"PR #953"})," \u2014 Remove fasttext dependency"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://github.com/undertheseanlp/underthesea/pull/947",children:"PR #947"})," \u2014 Add pure Rust FastText inference"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://github.com/undertheseanlp/underthesea/tree/main/extensions/underthesea_core",children:"underthesea-core source"})," \u2014 Full Rust implementation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://pypi.org/project/underthesea-core/",children:"underthesea-core on PyPI"})," \u2014 Pre-built wheels"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453(e,n,t){t.d(n,{R:()=>a,x:()=>l});var s=t(6540);const i={},r=s.createContext(i);function a(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(r.Provider,{value:n},e.children)}},4730(e){e.exports=JSON.parse('{"permalink":"/underthesea/blog/rewrite-fasttext-in-rust","editUrl":"https://github.com/undertheseanlp/underthesea/tree/main/docusaurus/blog/2026-02-08-rewrite-fasttext-in-rust.md","source":"@site/blog/2026-02-08-rewrite-fasttext-in-rust.md","title":"Rewriting FastText in Rust","description":"In underthesea v9.2.9, we replaced the fasttext Python package (a wrapper around Facebook\'s C++ library) with a pure Rust implementation inside underthesea-core. The result: identical predictions, simpler installation, and one fewer C++ dependency in our stack.","date":"2026-02-08T00:00:00.000Z","tags":[{"inline":true,"label":"rust","permalink":"/underthesea/blog/tags/rust"},{"inline":true,"label":"performance","permalink":"/underthesea/blog/tags/performance"},{"inline":true,"label":"fasttext","permalink":"/underthesea/blog/tags/fasttext"},{"inline":true,"label":"nlp","permalink":"/underthesea/blog/tags/nlp"},{"inline":true,"label":"language-detection","permalink":"/underthesea/blog/tags/language-detection"}],"readingTime":9.74,"hasTruncateMarker":true,"authors":[{"name":"Vu Anh","title":"Creator of Underthesea","url":"https://github.com/rain1024","imageURL":"https://github.com/rain1024.png","key":"rain1024","page":null}],"frontMatter":{"slug":"rewrite-fasttext-in-rust","title":"Rewriting FastText in Rust","authors":["rain1024"],"tags":["rust","performance","fasttext","nlp","language-detection"]},"unlisted":false,"nextItem":{"title":"Rust-Powered Text Classification","permalink":"/underthesea/blog/rust-text-classifier"}}')}}]);